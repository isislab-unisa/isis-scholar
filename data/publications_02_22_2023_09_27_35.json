{"columns":["year","owner","title","abstract","keywords","source","type","doi","eid"],"data":[["2023-06-01","Delfina Malandrino","Touchscreen gestures as images. A transfer learning approach for soft biometric traits recognition","Mobile devices are nowadays ubiquitous. They are equipped with a variety of sensors, each designed for capturing specific signals which can be exploited to acquire discriminating user's traits, thus allowing to recognize, for instance, the authorized users. In this regard, we focus on capturing soft biometric traits from smartphones. Soft biometric information extracted from a human body (e.g., gender and age) is ancillary information proved to improve the performance of biometric authentication systems, and it has drawn a great deal of attention for its applications in healthcare, smart spaces and digital world as a whole. This paper presents an approach to gender and age-group recognition, namely TGSB, leveraging a transfer learning strategy applied to state-of-the-art Convolutional Neural Networks (CNNs) fed with image-based representations of touch gestures performed by users on mobile devices. We perform experiments considering, one at a time, touch gestures of the same kind, and combinations thereof, with intermediate and late fusion learning strategies. Experiments prove that TGSB is a promising approach, with up to 94% accuracy for the gender recognition and up to 99% for the age-group recognition. We highlight the most useful touch gesture for gender and age-group recognition, that is Scroll with 81% and 96% accuracy, respectively. We show that combining multiple touch gestures (intermediate fusion) with a joint latent subspace learning mechanism in CNNs improves the TGSB performance, up to 99% accuracy when considering a combination of two Scroll. Compared to previous works, TGSB exhibits much better performance in both gender and age-group recognition.","Age recognition | Gender recognition | Mobile information processing systems | Neural networks | Soft biometrics","Expert Systems with Applications","Article","https:\/\/www.doi.org\/10.1016\/j.eswa.2023.119614","2-s2.0-85147607504"],["2023-01-01","Carmine Spagnuolo","Experimenting with Agent-Based Model Simulation Tools","Agent-based models (ABMs) are one of the most effective and successful methods for analyzing real-world complex systems by investigating how modeling interactions on the individual level (i.e., micro-level) leads to the understanding of emergent phenomena on the system level (i.e., macro-level). ABMs represent an interdisciplinary approach to examining complex systems, and the heterogeneous background of ABM users demands comprehensive, easy-to-use, and efficient environments to develop ABM simulations. Currently, many tools, frameworks, and libraries exist, each with its characteristics and objectives. This article aims to guide newcomers in the jungle of ABM tools toward choosing the right tool for their skills and needs. This work proposes a thorough overview of open-source general-purpose ABM tools and offers a comparison from a two-fold perspective. We first describe an off-the-shelf evaluation by considering each ABM tool\u2019s features, ease of use, and efficiency according to its authors. Then, we provide a hands-on evaluation of some ABM tools by judging the effort required in developing and running four ABM models and the obtained performance.","agent-based model | agent-based simulations | agent-based tools | open-source software","Applied Sciences (Switzerland)","Review","https:\/\/www.doi.org\/10.3390\/app13010013","2-s2.0-85145846177"],["2022-12-15","Delfina Malandrino","Adaptive talent journey: Optimization of talents\u2019 growth path within a company via Deep Q-Learning","In enterprise context, companies constantly aim to optimize their human resources and acquire new ones. Employees, also called talents, are required to achieve new skills for the company to stay competitive in the business. The talents\u2019 ability to productively improve is a crucial factor for the success of a company. We propose Adaptive Talent Journey, a novel method for optimizing the growth path of talents within a company. The ultimate goal of Adaptive Talent Journey is to hold talent back inside the company. It exploits the notion of \u201cdigital twin\u201d to define a digital representation of the talent, namely Talent Digital Twin, built on the basis of skills level and personal traits. Given a target company's role, Adaptive Talent Journey proposes the most suitable path of work experiences (journey) to improve the skills of a talent so to achieve the target role requirements. Such a mechanism resonates with the Reinforcement Learning paradigm, and specifically with Deep Q-Learning. Specifically, the proposed method exploits: (i) two double Deep Q-Networks (DDQNs) for selecting the work experiences to be made; (ii) a transition module to support the DDQNs training and ensure good performance despite the limited availability of data. We implemented and deployed Adaptive Talent Journey in an intuitive Web application, namely ATJWeb. We evaluated both the effectiveness and efficiency of our proposal and the users\u2019 satisfaction in using it, adopting, as a testbed, an IT company with its employees. Results proved that the Adaptive Talent Journey can optimize the growth path of talents, and that ATJWeb is pleasant and useful.","Deep Q-Learning | Digital Twin | Talent journey | User evaluation","Expert Systems with Applications","Article","https:\/\/www.doi.org\/10.1016\/j.eswa.2022.118302","2-s2.0-85135922166"],["2022-11-01","Delfina Malandrino","Induced Emotion-Based Music Recommendation through Reinforcement Learning","Music is widely used for mood and emotion regulation in our daily life. As a result, many research works on music information retrieval and affective human-computer interaction have been proposed to model the relationships between emotion and music. However, most of these works focus on applications in a context-sensitive recommendation that considers the listener\u2019s emotional state, but few results have been obtained in studying systems for inducing future emotional states. This paper proposes Moodify, a novel music recommendation system based on reinforcement learning (RL) capable of inducing emotions in the user to support the interaction process in several usage scenarios (e.g., games, movies, smart spaces). Given a target emotional state, and starting from the assumption that an emotional state is entirely determined by a sequence of recently played music tracks, the proposed RL method is designed to learn how to select the list of music pieces that better \u201cmatch\u201d the target emotional state. Differently from previous works in the literature, the system is conceived to induce an emotional state starting from a current emotion instead of capturing the current emotion and suggesting certain songs that are thought to be suitable for that mood. We have deployed Moodify as a prototype web application, named MoodifyWeb. Finally, we enrolled 40 people to experiment MoodifyWeb, employing one million music playlists from the Spotify platform. This preliminary evaluation study aimed to analyze MoodifyWeb\u2019s effectiveness and overall user satisfaction. The results showed a highly rated user satisfaction, system responsiveness, and appropriateness of the recommendation (up to 4.30, 4.45, and 4.75 on a 5-point Likert, respectively) and that such recommendations were better than they thought before using MoodifyWeb (6.45 on a 7-point Likert).","affective computing | emotional state | musical emotion | reinforcement learning | user evaluation","Applied Sciences (Switzerland)","Article","https:\/\/www.doi.org\/10.3390\/app122111209","2-s2.0-85141886077"],["2022-11-01","Delfina Malandrino","Adam or Eve? Automatic users\u2019 gender classification via gestures analysis on touch devices","Gender classification of mobile devices\u2019 users has drawn a great deal of attention for its applications in healthcare, smart spaces, biometric-based access control systems and customization of user interface (UI). Previous works have shown that authentication systems can be more effective when considering soft biometric traits such as the gender, while others highlighted the significance of this trait for enhancing UIs. This paper presents a novel machine learning-based approach to gender classification leveraging the only touch gestures information derived from smartphones\u2019 APIs. To identify the most useful gesture and combination thereof for gender classification, we have considered two strategies: single-view learning, analyzing, one at a time, datasets relating to a single type of gesture, and multi-view learning, analyzing together datasets describing different types of gestures. This is one of the first works to apply such a strategy for gender recognition via gestures analysis on mobile devices. The methods have been evaluated on a large dataset of gestures collected through a mobile application, which includes not only scrolls, swipes, and taps but also pinch-to-zooms and drag-and-drops which are mostly overlooked in the literature. Conversely to the previous literature, we have also provided experiments of the solution in different scenarios, thus proposing a more comprehensive evaluation. The experimental results show that scroll down is the most useful gesture and random forest is the most convenient classifier for gender classification. Based on the (combination of) gestures taken into account, we have obtained F1-score up to 0.89 in validation and 0.85 in testing phase. Furthermore, the multi-view approach is recommended when dealing with unknown devices and combinations of gestures can be effectively adopted, building on the requirements of the system our solution is built-into. Solutions proposed turn out to be both an opportunity for gender-aware technologies and a potential risk deriving from unwanted gender classification.","Authentication systems | Automatic gender classification | Machine learning | Mobile devices | Touch gesture","Neural Computing and Applications","Article","https:\/\/www.doi.org\/10.1007\/s00521-022-07454-4","2-s2.0-85132184661"],["2022-09-01","Gennaro Cordasco","Dual domination problems in graphs","We introduce a novel domination problem, which we call Dual Domination (DD). We assume that the nodes in a network are partitioned into two categories: Positive nodes (V+) and negative nodes (V\u2212). We study the Maximum Bounded Dual Domination, where, given a bound k, the problem is to find a set D\u2286V+, which maximizes the number of nodes dominated in V+, dominating at most k nodes in V\u2212. We show that such problem is hard to approximate to a factor better than (1\u22121\/e). We give a polynomial time algorithm with approximation guaranteed (1\u2212e\u22121\/\u0394), where \u0394 represents the maximum number of neighbors in V+ of any node in V\u2212, and an O(|V|k2) time algorithm to solve the problem on trees. We also study two related problems named Maximum Dual Domination and minimum Negative Dual Domination. For both problems, we show hardness results and provide O(|V|) time algorithms on trees.","Domination | Optimization | Polynomial-time approximation","Journal of Computer and System Sciences","Article","https:\/\/www.doi.org\/10.1016\/j.jcss.2022.03.003","2-s2.0-85127516615"],["2022-08-29","Carmine Spagnuolo","Move cultural heritage knowledge graphs in everyone's pocket","Last years witnessed a shift from the potential utility in digitisation to a crucial need to enjoy activities virtually. In fact, before 2019, data curators recognised the utility of performing data digitisation, while during the lockdown caused by the COVID-19, investing in virtual and remote activities to make culture survive became crucial as no one could enjoy Cultural Heritage in person. The Cultural Heritage community heavily invested in digitisation campaigns, mainly modelling data as Knowledge Graphs by becoming one of the most successful Semantic Web technologies application domains. Despite the vast investment in Cultural Heritage Knowledge Graphs, the syntactic complexity of RDF query languages, e.g., SPARQL, negatively affects and threatens data exploitation, risking leaving this enormous potential untapped. Thus, we aim to support the Cultural Heritage community (and everyone interested in Cultural Heritage) in querying Knowledge Graphs without requiring technical competencies in Semantic Web technologies. We propose an engaging exploitation tool accessible to all without losing sight of developers' technological challenges. Engagement is achieved by letting the Cultural Heritage community leave the passive position of the visitor and actively create their Virtual Assistant extensions to exploit proprietary or public Knowledge Graphs in question-answering. By accessible to all, we mean that the proposed software framework is freely available on GitHub and Zenodo with an open-source license. We do not lose sight of developers' technical challenges, which are carefully considered in the design and evaluation phases. This article first analyses the effort invested in publishing Cultural Heritage Knowledge Graphs to quantify data developers can rely on in designing and implementing data exploitation tools in this domain. Moreover, we point out challenges developers may face in exploiting them in automatic approaches. Second, it presents a domain-agnostic Knowledge Graph exploitation approach based on virtual assistants as they naturally enable question-answering features where users formulate questions in natural language directly by their smartphones. Then, we discuss the design and implementation of this approach within an automatic community-shared software framework (a.k.a. generator) of virtual assistant extensions and its evaluation in terms of performance and perceived utility according to end-users. Finally, according to a taxonomy of the Cultural Heritage field, we present a use case for each category to show the applicability of the proposed approach in the Cultural Heritage domain. In overviewing our analysis and the proposed approach, we point out challenges that a developer may face in designing virtual assistant extensions to query Knowledge Graphs, and we show the effect of these challenges in practice.","Community-shared software framework | knowledge graph | question-answering | SPARQL | virtual assistant","Semantic Web","Article","https:\/\/www.doi.org\/10.3233\/SW-223117","2-s2.0-85145942403"],["2022-08-01","Gennaro Cordasco","Age and gender effects on the human\u2019s ability to decode posed and naturalistic emotional faces","This paper proposes a systematic approach to investigate the impact of factors such as the gender and age of participants and gender, and age of faces on the decoding accuracy of emotional expressions of disgust, anger, sadness, fear, happiness, and neutrality. The emotional stimuli consisted of 76 posed and 76 naturalistic faces, differently aged (young, middle-aged, and older) selected from FACES and SFEW databases. Either a posed or naturalistic faces\u2019 decoding task was administered. The posed faces\u2019 decoding task involved three differently aged groups (young, middle-aged, and older adults). The naturalistic faces\u2019 decoding task involved two groups of older adults. For the posed decoding task, older adults were found significantly less accurate than middle-aged and young participants, and middle-aged significantly less accurate than young participants. Old faces were significantly less accurately decoded than young and middle-aged faces of disgust, and anger, and young faces of fear, and neutrality. Female faces were significantly more accurately decoded than male faces of anger and sadness, significantly less accurately decoded than male faces of neutrality. For the naturalistic decoding task, older adults were significantly less accurate in decoding naturalistic rather than posed faces of disgust, fear, and neutrality, contradicting an older adults\u2019 emended support from a prior naturalistic emotional experience. Young faces were more accurately decoded than old and middle-aged faces of disgust and anger and old faces of neutrality. Female faces were significantly more accurately decoded than male faces of fear, and significantly less accurately decoded than male faces of anger. Significant effects and significant interdependencies were observed among the age of participants, emotional categories, age, and gender of faces, and type of stimuli (naturalistic vs. posed), not allowing to distinctly isolate the effects of each involved variable. Nevertheless, the data collected in this paper weakens both the assumptions on women enhanced ability to display and decode emotions and participants enhanced ability to decode faces closer to their own age (\u201cown age bias\u201d theory). Considerations are made on how these data would guide the development of assessment tools and preventive interventions and the design of emotionally and socially believable virtual agents and robots to assists and coach emotionally vulnerable people in their daily routines.","Age differences | And older) | Differently aged emotional faces | Differently aged participants (young | Faces decoding | Gender differences | Middle-aged | Naturalistic and posed emotional faces","Pattern Analysis and Applications","Article","https:\/\/www.doi.org\/10.1007\/s10044-021-01049-w","2-s2.0-85123237412"],["2022-07-01","Delfina Malandrino","An adaptive meta-heuristic for music plagiarism detection based on text similarity and clustering","Plagiarism is a controversial and debated topic in different fields, especially in the Music one, where the commercial market generates a huge amount of money. The lack of objective metrics to decide whether a song is a plagiarism, makes music plagiarism detection a very complex task: often decisions have to be based on subjective argumentations. Automated music analysis methods that identify music similarities can be of help. In this work, we first propose two novel such methods: a text similarity-based method and a clustering-based method. Then, we show how to combine them to get an improved (hybrid) method. The result is a novel adaptive meta-heuristic for music plagiarism detection. To assess the effectiveness of the proposed methods, considered both singularly and in the combined meta-heuristic, we performed tests on a large dataset of ascertained plagiarism and non-plagiarism cases. Results show that the meta-heuristic outperforms existing methods. Finally, we deployed the meta-heuristic into a tool, accessible as a Web application, and assessed the effectiveness, usefulness, and overall user acceptance of the tool by means of a study involving 20 people, divided into two groups, one of which with access to the tool. The study consisted in having people decide which pair of songs, in a predefined set of pairs, should be considered plagiarisms and which not. The study shows that the group supported by our tool successfully identified all plagiarism cases, performing all tasks with no errors. The whole sample agreed about the usefulness of an automatic tool that provides a measure of similarity between two songs.","Clustering | Evaluation study | Multi-objective optimization | Music plagiarism detection | Text similarity","Data Mining and Knowledge Discovery","Article","https:\/\/www.doi.org\/10.1007\/s10618-022-00835-2","2-s2.0-85129792229"],["2022-06-01","Gennaro Cordasco","Synthetic vs Human Emotional Faces: What Changes in Humans' Decoding Accuracy","Considered the increasing use of assistive technologies in the shape of virtual agents, it is necessary to investigate those factors which characterize and affect the interaction between the user and the agent, among these emerges the way in which people interpret and decode synthetic emotions, i.e., emotional expressions conveyed by virtual agents. For these reasons, an article is proposed, which involved 278 participants split in differently aged groups (young, middle-aged, and elders). Within each age group, some participants were administered a 'naturalistic decoding task,' a recognition task of human emotional faces, while others were administered a 'synthetic decoding task' namely emotional expressions conveyed by virtual agents. Participants were required to label pictures of female and male humans or virtual agents of different ages (young, middle-aged, and old) displaying static expressions of disgust, anger, sadness, fear, happiness, surprise, and neutrality. Results showed that young participants showed better recognition performances (compared to older groups) of anger, sadness, and neutrality, while female participants showed better recognition performances (compared to males) of sadness, fear, and neutrality; sadness and fear were better recognized when conveyed by real human faces, while happiness, surprise, and neutrality were better recognized when represented by virtual agents. Young faces were better decoded when expressing anger and surprise, middle-aged faces were better decoded when expressing sadness, fear, and happiness, while old faces were better decoded in the case of disgust; on average, female faces where better decoded compared to male ones.","Assistive technology | emotion recognition | emotional virtual agents | human-computer interaction","IEEE Transactions on Human-Machine Systems","Article","https:\/\/www.doi.org\/10.1109\/THMS.2021.3129714","2-s2.0-85121401350"],["2022-05-17","Biagio Cosenza","FLEXDP: Flexible Frequency Scaling for Energy-Delay Product Optimization of GPU Applications","Dynamic frequency scaling is broadly available among different modern computer architectures, making it possible to improve the performance and energy efficiency of an application by carefully setting the core frequency. However, while an exhaustive tuning is feasible on simple single-kernel applications, in real-world applications comprised of multiple tasks, the set of possible frequency setting combinations is too large to be exhaustively evaluated. This work deals with the problem of optimizing a multi-task GPU application with frequency scaling. We focus on different scalarizations of the problem by optimizing for performance, energy consumption, as well as energy-delay product (EDP) and energy-delay-two product (ED2P). We propose FLEXDP, a new flexible framework that finds the optimal core-frequency configuration over multiple kernels, allowing multiple frequency changes between kernel executions, and taking change overheads into account. The proposed approaches are evaluated on an NVIDIA Titan X. Experimental results on five applications demonstrate that FLEXDP outperforms the default and autoboost configurations with respect to performance, energy efficiency, EDP, and ED2P.","energy-delay product | frequency scaling | GPUs | multi-task | optimization","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3528416.3530241","2-s2.0-85130745756"],["2022-05-10","Biagio Cosenza","Celerity: How (Well) Does the SYCL API Translate to Distributed Clusters?",null,"cluster computing | distributed memory clusters | MPI | SYCL","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3529538.3530004","2-s2.0-85130337097"],["2022-04-01","Vittorio Scarano","Regio, stereo and chemoselectivity of 2nd generation Grubbs ruthenium-catalyzed olefin metathesis","The examination of cross metathesis reactions leading to the desired product has been conducted to uncover computationally the origin of the chemo-, regio- and stereoselectivity. The comparison between the relative stabilities of all involved intermediates and products, together with the transition states, links to the probability for the respective pathway. Particularly, the respective transition states for each reaction tune the regio- and stereoselectivity because they define the energy barriers needed to be overcome to form the new olefin as final product. The broad range of studied reactions with the 2nd generation Grubbs catalysts allows concluding in detail the points to pay attention and thus helps to understand the chemo-, regio- and stereoselectivity in new olefin metathesis reactions. Here, a web-server joins all these mechanistic insights which is intended to support future predictive olefin metathesis catalysis.","Mechanism | N-heterocyclic carbene | Olefin metathesis | Predictive catalysis | Ruthenium","Catalysis Today","Article","https:\/\/www.doi.org\/10.1016\/j.cattod.2020.04.071","2-s2.0-85086658669"],["2022-02-01","Gennaro Cordasco","Mood State Detection in Handwritten Tasks Using PCA\u2013mFCBF and Automated Machine Learning","In this research, we analyse data obtained from sensors when a user handwrites or draws on a tablet to detect whether the user is in a specific mood state. First, we calculated the features based on the temporal, kinematic, statistical, spectral and cepstral domains for the tablet pressure, the horizontal and vertical pen displacements and the azimuth of the pen\u2019s position. Next, we selected features using a principal component analysis (PCA) pipeline, followed by modified fast correlation\u2013based filtering (mFCBF). PCA was used to calculate the orthogonal transformation of the features, and mFCBF was used to select the best PCA features. The EMOTHAW database was used for depression, anxiety and stress scale (DASS) assessment. The process involved the augmentation of the training data by first augmenting the mood states such that all the data were the same size. Then, 80% of the training data was randomly selected, and a small random Gaussian noise was added to the extracted features. Automated machine learning was employed to train and test more than ten plain and ensembled classifiers. For all three moods, we obtained 100% accuracy results when detecting two possible grades of mood severities using this architecture. The results obtained were superior to the results obtained by using state-of-the-art methods, which enabled us to define the three mood states and provide precise information to the clinical psychologist. The accuracy results obtained when detecting these three possible mood states using this architecture were 82.5%, 72.8% and 74.56% for depression, anxiety and stress, respectively.","AutoML | Data augmentation | Feature extraction | Negative mood states recognition | SVM","Sensors","Article","https:\/\/www.doi.org\/10.3390\/s22041686","2-s2.0-85124871842"],["2022-01-15","Delfina Malandrino","An automatic mechanism to provide privacy awareness and control over unwittingly dissemination of online private information","Given the increasing popularity of social media and other Internet-related technologies, individuals spend a lot of time across different online activities, such as doing Google searches or credit card purchases, enjoying social networks interactions, performing job finding or travel plannings activities. Unfortunately, very often, individuals unwittingly disseminate a huge amount of personal and sensitive information that fundamentally represents an essential part of their private life. A large part of this information is embedded into text messages typed during online activities. Therefore, there is an increasing need for mechanisms to assist individuals during such activities, raising their awareness about potential violation of privacy at the time of disclosure; however, it is also essential to give them full control on whether and how to manage their data, thereby empowering them to make heedful decisions. The awareness can be realized through simple alert\/highlight mechanisms, while the full control can be ensured by allowing users to make the final choice, that is, ignore warnings, or conversely accept them and thus (a) think twice before disseminating data (to avoid future regrets), or (b) anyway send data, but only after their anonymization. In this paper, we propose a novel approach based on machine learning and sentence embedding techniques with the primary goal of providing privacy awareness to users and, as a consequence, full control over their data during online activities. Our approach relies on the definition of four modules: (i) the Keyword module, which identifies personal and sensitive data in a text (from the syntactic point of view); (ii) the Topic module, which is devoted to understand the topic treated in text messages; (iii) the Sensitiveness module, which identifies sensitive information (from the semantic point of view) into text messages; lastly, (iv) the Personalization module, which goal is to learn the personal attitude of a user towards his\/her own privacy (through opportune feedback) and therefore report the correct alert messages. We provided an implementation of such an approach, named Knoxly, as a prototype of a Google Chrome extension. The tool has undergone a preliminary experimental study to assess its effectiveness in terms of sensitive information identification accuracy, and its efficiency in terms of impact on user experience.","Experimental study | Machine learning | Privacy awareness and information leakage","Computer Networks","Article","https:\/\/www.doi.org\/10.1016\/j.comnet.2021.108614","2-s2.0-85119660458"],["2022-01-01","Gennaro Cordasco","A cross-cultural survey to identify Seniors' preferences towards the Empathic Virtual Coach","The present investigation is part of the EMPATHIC project aiming at develop an Empathic Virtual Coach (VC) able to promote seniors' healthy lifestyle and independent aging. To this end, it is fundamental to investigate users' preferences towards the implemented automatic system refined on the basis of users' preferences derived from previous field trials with Wizard of Oz (WoZ) experimental sessions. Data collection has been carried out involving three different countries (France, Norway and Spain) and a total of 71 volunteers was enrolled in the planned field trials. Five Virtual Agents (VAs) named Natalie, Alice, Lena, Christian and Adam were purposely designed and users' preferences were assessed using the shortened version of the Virtual Agent Acceptance Questionnaire (VAAQ). This specific tool, developed by members of the EMPATHIC project, includes 7 different sections, and the present work aims to disseminate results of four of the seven sections administered to participants, devoted at assessing respectively: users' willingness to interact (section II); pragmatic, hedonic (Identity and Feeling) and attractiveness qualities (section III); the type of task participants entrusted to the proposed agents among healthcare, housework, protection\/security, and front office jobs (section V) and agents voice' quality (section VI). Results reveal seniors' appreciation of agents' pleasantness, originality, voice' quality and ability to engage users in a long lasting interaction with them.","assistive technologies | users' acceptance | virtual coach","Proceedings of the 2022 IEEE International Conference on Dependable, Autonomic and Secure Computing, International Conference on Pervasive Intelligence and Computing, International Conference on Cloud and Big Data Computing, International Conference on Cyber Science and Technology Congress, DASC\/PiCom\/CBDCom\/CyberSciTech 2022","Conference Paper","https:\/\/www.doi.org\/10.1109\/DASC\/PiCom\/CBDCom\/Cy55231.2022.9927961","2-s2.0-85145346371"],["2022-01-01","Gennaro Cordasco","Android Robots vs Virtual Agents: which system differently aged users prefer?","The growing presence of robots in our daily life brings out the need to develop systems that are ever more user-friendly, considering users' needs and preferences. This is necessary in particular when robots are developed to be introduced into welfare settings. For this reason, a study is proposed with the aim to investigate differently aged (young, middle-aged, and seniors) potential users' assessment of male android robots as opposed to male virtual agents, in order to compare interactive systems characterized by different levels of embodiment. 180 participants joined the experiment, which consisted of watching video clips depicting android robots and virtual agents, and subsequently fulfilling the RAQ (Robot Acceptance Questionnaire) and the VAAQ (Virtual Agent Acceptance Questionnaire). Results highlighted substantial differences in robots and agents' assessment, differences which seem to be affected by participants' age, as well.",null,"RO-MAN 2022 - 31st IEEE International Conference on Robot and Human Interactive Communication: Social, Asocial, and Antisocial Robots","Conference Paper","https:\/\/www.doi.org\/10.1109\/RO-MAN53752.2022.9900850","2-s2.0-85140789794"],["2022-01-01","Carmine Spagnuolo","Towards a collaborative taxonomy of Tools, Languages and Environments in K-12 Computing Education","In this Work-in-Progress paper we present a preliminary study and the design of a taxonomy of Tools, Languages and Environments (TLE) employed in K-12 Computing Education, in schools and outreach programs. The research provides an analytical classification model based on a survey of TLEs and on previous related works. It also outlines the collaborative protocol that will allow researchers to share the results of the taxonomy on a public repository. An analysis of the most common platforms where contributors can work collaboratively is presented to show the qualitative process of identification and choice of GitHub as the most reliable one.","Bloom's taxonomy | Computer Science | Course assessment | K-12 | Learning environment | Online repositories | Outreach | Rubric | User centered design","Proceedings - Frontiers in Education Conference, FIE","Conference Paper","https:\/\/www.doi.org\/10.1109\/FIE56618.2022.9962683","2-s2.0-85143803715"],["2022-01-01","Gennaro Cordasco","Reciprocity versus Self-Interest in a Competitive Interaction Context: An Experimental Study","In social interactions, the reciprocity norm implies to adjust one\u2019s behavior to that of the other agents. Conversely, behaving according to self-interest involves taking into account the reciprocity principle only if it does not hinder the achievement of one\u2019s goals. However, reciprocity and self-interest may conflict with each other, as when returning a kind action involves sacrificing the possibility to achieve a personal objective. The conflict could be exacerbated by some contextual factors, such as competitive pressures. This study investigated, in a competitive interaction context, which principle prevails when the two conflict. To this end, 276 unpaid participants (M = 138) took part in a two-stage experiment entailing a simulated interaction with a fictitious opponent, which behaved selfishly, fairly or altruistically toward them during the first stage. Participants had to decide whether or not to reciprocate the opponent\u2019s previous behavior, which in the critical experimental conditions conflicted with the goal to successfully complete the experiment. So, they were faced with a moral dilemma. Competition degree was manipulated to make the conflict between reciprocity and self-interest more or less harsh. Moreover, we tested whether the putative effect of experimental manipulation was mediated by changes in context-related affective states and personal beliefs about morality. Results showed that decision-making was principally influenced by reciprocity. Regardless of the competition degree, participants preferred to engage in reciprocal behavior even when this compromised their personal interest. Affective states and beliefs changed in response to the experimental manipulation, but they did not mediate the effect of the independent variable on decision-making.","affective states | competition | moral beliefs | moral decision-making | Reciprocity | self-interest","Psychological Reports","Article","https:\/\/www.doi.org\/10.1177\/00332941221129137","2-s2.0-85139144208"],["2022-01-01","Gennaro Cordasco","Pervasive Domination","Inspired by the implicit or explicit persuasion scenario, which characterizes social media platforms, we analyze a novel domination problem named Pervasive Partial Domination (PPD). We consider a social network modeled by a digraph G= (V, E) where an arc (u, v) \u2208 E represents the capability of an individual u to persuade an individual v. We are looking for a set S\u2282 V of social change individuals, of minimum cost, who combined enable to reach the desired behavior. The impact of S is measured by a set function f(S) that is the sum of the degree of belief of all the individuals in the network and p is the desired target. We show that the natural greedy algorithm, for the PPD problem, provides an approximation guarantee, (lnp-f(\u2205)\u03b2+2) where \u03b2&gt; 0 represents the minimum gain on the function f one can attain by bribing an additional individual when the target p is (almost) reached. The proposed solution can be generalized to the weighted partial sumbmodular cover problem providing a better approximation with respect to the state of the art.","Domination","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-031-18530-4_21","2-s2.0-85145261547"],["2022-01-01","Gennaro Cordasco","The Role of Language in Building Automatic Models for Depression Detection","The increase in cases of depression in recent years makes necessary to develop new objective and reliable tools and instruments for the early identification of this condition. In this context, one of the most efficacious and efficient approaches seems to be the acoustic analysis of the speech characteristics of depressed patients. The present study analyzes how depressive states affects the spontaneous speech of 68 depressed patients of two different languages (Italian and English), divided into 3 groups (English, Italians with mild\/moderate severity and Italians with severe severity). We consider 21 acoustic features, all of them good and usual indicators of emotional states in speech, obtained from 5 acoustic low-level descriptors (LLD, i.e. Fundamental frequency, Jitter, Shimmer, Voice breaks, and Intensity). The main results showed, in a novel way, that fundamental frequency and number of pauses allowed to discriminate between English and Italian patients, while no significant differences were observed regarding the severity degree of the depressive symptoms. The aim of this study, corroborated by the results obtained, is to highlight the need to take into consideration the language variable when developing an automated speech analysis for detecting depressive states.","Acoustic low level descriptors | Acoustic speech feature | Culture and Language differences | Depression detection | Spontaneous speech | Voice analysis","Proceedings of the 2022 IEEE International Conference on Dependable, Autonomic and Secure Computing, International Conference on Pervasive Intelligence and Computing, International Conference on Cloud and Big Data Computing, International Conference on Cyber Science and Technology Congress, DASC\/PiCom\/CBDCom\/CyberSciTech 2022","Conference Paper","https:\/\/www.doi.org\/10.1109\/DASC\/PiCom\/CBDCom\/Cy55231.2022.9927925","2-s2.0-85145348965"],["2022-01-01","Gennaro Cordasco","Using Eye Tracking to Investigate Interaction between Humans and Virtual Agents","Situation Awareness (SA) and Internet of Things (IoT) can successfully be adopted with the aim of developing 'smart' assistive technologies able to understand and interact with users' actions, adapting to several situations. A peculiar type of assistive technology is meant to promote seniors' active aging, providing assistance, companionship, and entertainment. The study presented in this work was carried out in the context of a European project named 'EMPATHIC' aimed at developing virtual coaches for senior users. More specifically, the study analysed seniors' gaze behaviour while interacting with a virtual agent, to investigate whether users' attentional engagement would have changed over the interaction and accordingly to the conversational topics. Results highlight senior users' considerable engagement during the interaction and an overall positive attitude toward the proposed virtual agents.","assistive virtual agents | eye tracking | gaze data | users' attention","Proceedings - 2022 IEEE International Conference on Cognitive and Computational Aspects of Situation Management, CogSIMA 2022","Conference Paper","https:\/\/www.doi.org\/10.1109\/CogSIMA54611.2022.9830686","2-s2.0-85136194831"],["2022-01-01","Vittorio Scarano","COLTRANE \u2013 Towards a\u00a0Methodology and\u00a0Platform Supported Educational Basis for\u00a0Cybersecurity Education","Based on an analysis of current cybersecurity education in Europe and findings from a series of workshops conducted with selected groups of educators and learners in several European HEIs, this paper describes a methodology that is aimed at integrating the teaching of applied skills with the prevailing teaching, which is more focused on theoretical knowledge. The resulting COLTRANE Methodology aims at achieving this goal through providing a scenario-based and problem-oriented learning environment. A first case study is described and analyzed.","Awareness | Collaboration | Cybersecurity education | Learning","IFIP Advances in Information and Communication Technology","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-031-12172-2_6","2-s2.0-85135035447"],["2022-01-01","Vittorio Scarano","Outreach in K-12 Programming: A Systematic Literature Review on Audience and Purpose","Outreach Programs are informal educational initiatives that schools and universities, as well as companies and associations, promote: they represent a significant variety of courses and camps for learners, whether students or teachers. In this paper we provide an overview of the publications on Outreach Programs in K-12 Programming, in the last decade 2011-2021. The survey methodology adopted is the Systematic Literature Review: we classified the papers around two different axis, the audience and purpose of the Outreach Programs.","Computing Education | CS Education | K-12 | Novices | Outreach | Outreach Programs | Programming | Teachers Professional Development","International Conference on Computer Supported Education, CSEDU - Proceedings","Conference Paper","https:\/\/www.doi.org\/10.5220\/0011063400003182","2-s2.0-85140898873"],["2022-01-01","Vittorio Scarano","Linked open data in authoring virtual exhibitions","In the last years, virtual exhibitions have been widely adopted to enhance traditional museums and enable active interaction with culture without posing any physical constraints. Nevertheless, people interested in cultural heritage still behave as visitors. To fully engage them, we propose to let cultural heritage lovers play the role of exhibition curators. In authoring virtual exhibitions, users have to perform a data selection phase that poses several challenges, including finding data sources and extracting data of interest. We aim to take advantage of data published as Knowledge Graphs in the Linked Open Data format. Users can query geographically distributed artworks thanks to their linking nature, manipulate heterogeneous data, and easily customise their exhibitions by exploiting the wide range of available cultural heritage knowledge graphs. However, the complexity of linked open data query languages (such as SPARQL) threatens their exploitation. Consequently, we need to mask SPARQL technical challenges and guide users in naturally posing questions to unlock the potentialities of linked open data to a broader audience. We propose a virtual exhibition authoring tool that guides users from knowledge graphs querying to the automatic generation of virtual experiences. The Knowledge Graph query phase relies on ELODIE, a natural language interface to scaffold users in retrieving data of interest without asking for technical skills in query languages. We introduce our prototype by describing its operating mechanism and by detailing its components. We present a Van Gogh's experience as a use case by collecting all the artist's artworks published on DBpedia (a well-known and general purpose knowledge graph) and organise them in a virtual reality-based virtual exhibition. Finally, we conclude by overviewing advantages and technical challenges posed by linked open data in designing and developing knowledge graph exploitation tools.","Knowledge graph | Linked open data | Natural language interface | Query builder | Virtual exhibitions | Virtual reality","Journal of Cultural Heritage","Article","https:\/\/www.doi.org\/10.1016\/j.culher.2021.11.002","2-s2.0-85120965834"],["2022-01-01","Gennaro Cordasco","Humanoid and android robots in the imaginary of adolescents, young adults and seniors","This paper investigates effects of participants\u2019 gender and age (adolescents, young adults, and seniors), robots\u2019 gender (male and female robots) and appearance (humanoid vs android) on robots\u2019 acceptance dimensions. The study involved 6 differently aged groups of participants (two adolescents, two young adults and two seniors\u2019 groups, for a total of 240 participants) requested to express their willingness to interact and their perception of robots\u2019 usefulness, pleasantness, appeal, and engagement for two different sets of females (Pepper, Erica, and Sophia) and male (Romeo, Albert, and Yuri) humanoid and android robots. Participants were also requested to express their preferred and attributed age ranges and occupations they entrusted to robots among healthcare, housework, protection and security and front office. Results show that neither the age nor participants and robots\u2019 gender, nor robots\u2019 human likeness univocally affected robots\u2019 acceptance by these differently aged users. Robots\u2019 acceptance appeared to be a nonlinear combination of all these factors.","adolescents | Humanoid vs android robots | Male and female robots | Robots preferred and attributed age ranges | Robots\u2019 acceptance | Robots\u2019 entrusted occupations | Seniors | Young adults","Journal of Ambient Intelligence and Humanized Computing","Article","https:\/\/www.doi.org\/10.1007\/s12652-022-03806-z","2-s2.0-85127373131"],["2022-01-01","Gennaro Cordasco","Comparing Middle-Aged and Seniors\u2019 Preferences Toward Virtual Agents and Android Robots: Is There a Generational Shift in Assistive Technologies\u2019 Preferences?","The present research aims at investigating effects of participants\u2019 age (middle-aged and seniors) and type of assistive device (female virtual agents vs female android robots) on users\u2019 acceptance. The study involved 4 groups of two middle-aged and two seniors (for a total of 181) participants asked to ex- press their potential acceptance to be assisted in their daily routines by two female android robots\/virtual agents. Acceptance was assessed in terms of scores assigned by participants to their willingness to interact with the female agents\/robots and pragmatic (PQ), hedonic - identity (HQI), hedonic - feeling (HQF) and attractiveness (ATT) qualities. Video clips of the proposed agents or robots were randomly presented, and after each presentation, participants scored the proposed assistive device by filling either the VAAQ (Virtual Agent Acceptance) or the RAQ (Robot Acceptance) questionnaire. Repeated measures ANOVA were utilized to statistically assess participants\u2019 preferences. Seniors were significantly more open to interact with virtual agents rather than robots, while middle-aged participants were showed slightly more open to interact with robots rather than agents. Participants\u2019 gender significantly affected the evaluation of robots rather than agents\u2019 one, and the appearance of the proposed de- vices (younger toward mature agents, or haired toward hairless robots), strongly affected users\u2019 acceptance.","Android robots | Assistive technologies | Middle-aged | Seniors | Users\u2019 acceptance | Virtual agents","Lecture Notes in Electrical Engineering","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-031-08838-4_6","2-s2.0-85135774036"],["2022-01-01","Gennaro Cordasco","Is On-Line Handwriting Gender-Sensitive? What Tells us a\u00a0Combination of\u00a0Statistical and\u00a0Machine Learning Approaches","Handwriting is an everyday life human activity. It can be collected off-line by scanning sheets of paper. The resulting images can then be processed by a computer-based system. Thanks to digitizing tablets, handwriting can also be collected on-line. From the collected raw signals (pen position, pressure over time), the dynamics of the writing can be recovered. Since handwriting is unique for each individual, it can be considered as a biometric modality. Biometric systems predicting gender from off-line handwriting, have thus been recently proposed. However we observe that, in contrast to other modalities such as speech, it is not straightforward for a human being (even expert) to predict gender. In this study we explore the limits of automatic gender prediction from on-line handwriting collected from a young adults population, homogeneous in terms of age and education. Statistical analysis of on-line dynamic features can highlight differences between male and female groups [6]. In the present study, we focus on a sentence copying task, and provide statistically significant features to a classifier, based on a machine learning approach (SVMs). Since the dataset is relatively small (240 subjects), several evaluation frameworks are explored: cross validation (CV), bootstrap, and fixed train\/test partitions. Accuracies obtained from fixed partitions range from 37% to 79%, while those estimated by CV and bootstrap are around 65%. This shows to our opinion the limits of the gender recognition task for our young adult population dataset.","Gender recognition | Handwriting | Statistical analysis","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-031-09037-0_24","2-s2.0-85131963173"],["2022-01-01","Gennaro Cordasco","Parameterized Complexity of\u00a0Immunization in\u00a0the\u00a0Threshold Model","We consider the problem of controlling the spread of harmful items in networks, such as the contagion proliferation of diseases or the diffusion of fake news. We assume the linear threshold model of diffusion where each node has a threshold that measures the node\u2019s resistance to the contagion. We study the parameterized complexity of the problem: Given a network, a set of initially contaminated nodes, and two integers k and \u2113, is it possible to limit the diffusion to at most k other nodes of the network by immunizing at most \u2113 nodes? We consider several parameters associated with the input, including the bounds k and \u2113, the maximum node degree \u0394, the treewidth, and the neighborhood diversity of the network. We first give W[1] or W[2]-hardness results for each of the considered parameters. Then we give fixed-parameter algorithms for some parameter combinations.","Contamination minimization | Parameterized complexity | Threshold model","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-96731-4_23","2-s2.0-85127870135"],["2022-01-01","Carmine Spagnuolo","A Volunteer Computing Architecture for Computational Workflows on Decentralized Web","The amount of accessible computational devices over the Internet offers an enormous but latent computational power. Nonetheless, the complexity of orchestrating and managing such devices requires dedicated architectures and tools and hinders the exploitation of this vast processing capacity. Over the last years, the paradigm of (Browser-based) Volunteer Computing emerged as a unique approach to harnessing such computational capabilities, leveraging the idea of voluntarily offering resources. This article proposes VFuse, a groundbreaking architecture to exploit the Browser-based Volunteer Computing paradigm via a ready-to-access volunteer network. VFuse offers a modern multi-language programming environment for developing scientific workflows using WebAssembly technology without requiring the user any local installation or configuration. We equipped our architecture with a secure and transparent rewarding mechanism based on blockchain technology (Ethereum) and distributed P2P file system (IPFS). Further, the use of Non-Fungible Tokens provides a unique, secure, and transparent methodology for recognizing the users' participation in the network. We developed a prototype of the proposed architecture and four example applications implemented with our system. All code and examples are publicly available on GitHub.","browser-based volunteer computing | decentralized web | distributed computing | P2P | parallel computing | Scientific computing | volunteer computing | Web 3.0 | WebAssembly","IEEE Access","Article","https:\/\/www.doi.org\/10.1109\/ACCESS.2022.3207167","2-s2.0-85139226212"],["2022-01-01","Delfina Malandrino","Knowledge mining and social dangerousness assessment in criminal justice: metaheuristic integration of machine learning and graph-based inference","One of the main challenges for computational legal research is drawing up innovative heuristics to derive actionable knowledge from legal documents. While a large part of the research has been so far devoted to the extraction of purely legal information, less attention has been paid to seeking out in the texts the clues of more complex entities: legally relevant facts whose detection requires to link and interpret, as a unified whole, legal information and results of empirical analyses. This paper presents an ongoing research that points in this direction, trying to devise new ways to\u00a0support public prosecutors in assessing the dangerousness of individuals and groups under investigation, an activity that precisely\u00a0relies on the cross-sectional evaluation of legal and empirical data. A knowledge mining strategy will be outlined that lines up, into a single metaheuristic model, information extraction, network-based inference, machine learning and visual analytics. We will focus, in particular, on the integration of graph-based inference and machine learning methods used both to support classification tasks and to explore new forms of man-machine cooperation. Experiments made involving public prosecutors from the Italian Anti-Mafia Investigation Directorate and using data from real investigations have not only shown the potentialities of our approach but also offered an opportunity to reflect on the role we could assign to AI when thinking about the future of legal science and practice.",null,"Artificial Intelligence and Law","Article","https:\/\/www.doi.org\/10.1007\/s10506-022-09334-7","2-s2.0-85140304815"],["2022-01-01","Delfina Malandrino","How originality looks like. Integrating visualization and meta-heuristics to dissect music plagiarism","Plagiarism is a debated and controversial topic in different fields. For example, in Law, where the subjectivity of the judges that have to pronounce a suspicious case usually lead to long and often unsolved cases, and in Music, where huge amounts of money are invested every year to face and try to solve suspicious cases. In this scenario, the automatic detection of music plagiarism is fundamental by representing useful support for judges during their pronouncements and an important result to avoid musicians spending more time in court than on composing music. This paper shows how the combination of visual analytics and the employment of adaptive meta-heuristics can assist domain experts in judging suspicious cases. Solutions will be presented as part of PlagiarismDetection, a cross-platform tool that leverages text-similarity algorithms, computational intelligence, optimization methods, and visualization techniques to enable new critical approaches to music plagiarism analysis.","Meta-heuristics | Music analysis platforms | Music plagiarism detection | Visual analytics","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV56949.2022.00052","2-s2.0-85147329906"],["2022-01-01","Delfina Malandrino","The Eye of the Rider. Visualization and data-driven heuristics for the critical analysis of gig economy","The digital evolution of economies and markets brings changes that go largely beyond growth and efficiency. In the gig economy, also fueled by algorithmic management solutions, digital labour platforms (DPLs) raise significant issues that include power asymmetries, new forms of workers' abuse and discrimination, algorithms' opacity and over-control. In such a scenario, while normative frameworks evolve novel safeguards, a crucial challenge is that of feeding public (social, institutional) oversight on the dynamics that, at various levels, affect the gig work world. In this paper, we show how the combination of visual analytics and data-driven heuristics can be used to offer new insights on and promote higher levels of transparency and awareness about the fairness of DPLs' activity seen, in the first place, from the workers' perspective. Solutions will be presented as part of GigAdvisor, an experimental cross-platform application developed within an ongoing research that draws on computational social science methods to enable new critical approaches to the digital economy.","Computational legal studies | Critical data studies | digital labor platforms | Visual analytics","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV56949.2022.00068","2-s2.0-85147331004"],["2022-01-01","Biagio Cosenza","An Analysis of Performance Variability on Dragonfly+topology","Large-scale compute clusters are highly affected by performance variability that originates from different sources. Among these sources, the network plays an essential role as a shared resource between users and their jobs in a supercomputer. In this paper, we analyze the effect of some network-related sources on the performance variability of a modern compute cluster equipped with a Dragonfly+ interconnect. Specifically, we focus on the impacts of job placement, communication patterns, routing strategy, and network background traffic on the performance variability of communication-intensive workloads. To quantify the effect of network congestion (background traffic) on the performance variability, we propose a heuristic that can successfully estimate the amount of communication on the network produced by other jobs running on the cluster simultaneously. Then, we show how this network congestion contributes to the performance variability of different communication patterns and real-world communication-intensive applications.","dragonfly+ | performance variability | topology","Proceedings - IEEE International Conference on Cluster Computing, ICCC","Conference Paper","https:\/\/www.doi.org\/10.1109\/CLUSTER51413.2022.00061","2-s2.0-85140916107"],["2021-12-01","Gennaro Cordasco","A privacy-oriented approach for depression signs detection based on speech analysis","Currently, AI-based assistive technologies, particularly those involving sensitive data, such as systems for detecting mental illness and emotional disorders, are full of confidentiality, integrity, and security compromises. In the aforesaid context, this work proposes an algorithm for detecting depressive states based on only three never utilized speech markers. This reduced number of markers offers a valuable protection of personal (sensitive) data by not allowing for the retrieval of the speaker\u2019s identity. The proposed speech markers are derived from the analysis of pitch variations measured in speech data obtained through a tale reading task performed by typical and depressed subjects. A sample of 22 subjects (11 depressed and 11 healthy, according to both psychiatric diagnosis and BDI classification) were involved. The reading wave files were listened to and split into a sequence of intervals, each lasting two seconds. For each subject\u2019s reading and each reading interval, the average pitch, the pitch variation (T), the average pitch variation (A), and the inversion percentage (also called the oscillation percentage O) were automatically computed. The values of the triplet (Ti, Ai, Oi) for the i-th subject provide, all together, a 100% correct discrimination between the speech produced by typical and depressed individuals, while requiring a very low computational cost and offering a valuable protection of personal data.","Human\u2013computer interaction | speech recognition | Statistical parametric speech analysis","Electronics (Switzerland)","Article","https:\/\/www.doi.org\/10.3390\/electronics10232986","2-s2.0-85120317038"],["2021-12-01","Delfina Malandrino","A machine learning-based approach to identify unlawful practices in online terms of service: analysis, implementation and evaluation","Terms of Service (ToS) are fundamental factors in the creation of physical as well as online legally relevant relationships. They not only define mutual rights and obligations but also inform users about contract key issues that, in online settings, span from liability limitations to data management and processing conditions. Despite their crucial role, however, ToS are often neglected by users that frequently accept without even reading what they agree upon, representing a critical issue when there exist potentially unfair clauses. To enhance users\u2019 awareness and uphold legal safeguards, we first propose a definition of ToS unfairness based on a novel unfairness measure computed counting the unfair clauses contained in a ToS, and therefore, weighted according to their direct impact on the customers concrete interests. Secondly, we introduce a novel machine learning-based approach to classify ToS clauses, represented by using sentence embedding, in different categories classes and fairness levels. Results of a test involving well-known machine learning models show that Support Vector Machine is able to classify clauses into categories with a F1-score of 86% outperforming state-of-the-art methods, while Random Forest is able to classify clauses into fairness levels with a F1-score of 81%. With the final goal of making terms of service more readable and understandable, we embedded this approach into ToSware, a prototype of a Google Chrome extension. An evaluation study was performed to measure ToSware effectiveness, efficiency, and the overall users\u2019 satisfaction when interacting with it.","Fairness awareness | Machine learning | Software | Terms of service","Neural Computing and Applications","Article","https:\/\/www.doi.org\/10.1007\/s00521-021-06343-6","2-s2.0-85111397983"],["2021-10-18","Gennaro Cordasco","The EMPATHIC Virtual Coach: A demo","The main objective of the EMPATHIC project has been the design and development of a virtual coach to engage the healthy-senior user and to enhance well-being through awareness of personal status. The EMPATHIC approach addresses this objective through multimodal interactions supported by the GROW coaching model. The paper summarizes the main components of the EMPATHIC Virtual Coach (EMPATHIC-VC) and introduces a demonstration of the coaching sessions in selected scenarios.","elderly care | empathic communication | interactive virtual coaching","ICMI 2021 - Proceedings of the 2021 International Conference on Multimodal Interaction","Conference Paper","https:\/\/www.doi.org\/10.1145\/3462244.3481574","2-s2.0-85118988636"],["2021-09-25","Gennaro Cordasco","Toward a domain-specific language for scientific workflow-based applications on multicloud system","The cloud computing paradigm has emerged as the backbone of modern price-aware scalable computing systems. Many cloud service models are competing to become the leading doorway to access the computational power of cloud providers. Recently, a novel service model, called function-as-a-service (FaaS), has been proposed, which enables users to exploit the cloud computational scalability, left out the configuration and management of huge computing infrastructures. This article discloses Fly, a domain-specific language, which aims at reconciling cloud and high-performance computing paradigms adopting a multicloud strategy by providing a powerful, effective, and pricing-efficient tool for developing scalable workflow-based scientific applications by exploiting different and at the same time FaaS cloud providers as computational backends in a transparent fashion. We present several improvements of the Fly language, as well as a new enhanced version of a source-to-source compiler, which currently supports Symmetric Multiprocessing, Amazon AWS, and Microsoft Azure backends and translation of functions in Java, JavaScript, and Python programming languages. Furthermore, we discuss a performance evaluation of Fly on a popular benchmark for distributed computing frameworks, along with a collection of case studies with an analysis of their performance results and costs.","distributed computing | domain-specific languages | functions as a service | parallel computing | scientific computing | serverless computing | workflow-based application","Concurrency and Computation: Practice and Experience","Conference Paper","https:\/\/www.doi.org\/10.1002\/cpe.5802","2-s2.0-85084203343"],["2021-09-01","Delfina Malandrino","Providing music service in Ambient Intelligence: experiments with gym users","Ambient Intelligence (AmI) is an interdisciplinary research area of ICT which has evolved since the 90s, taking great advantage from the advent of the Internet of Things (IoT). AmI creates, by using Artificial Intelligence (AI), an intelligent ecosystem in which computers, sensors, lighting, music, personal devices, and distributed services, work together to improve the user experience through the support of natural and intuitive user interfaces. Nowadays, AmI is used in various contexts, e.g., for building smart homes and smart cities, providing healthcare, and creating an adequate atmosphere in retail and public environments. In this paper, we propose a novel AmI system for gym environments, named Gym Intelligence, able to provide adequate music atmosphere, according to the users\u2019 physical effort during the training. The music is taken from Spotify and is classified according to some music features, as provided by Spotify itself. The system is based on a multi-agent computational intelligence model built on two main components: (i) machine learning methods that forecast appropriate values for the Spotify music features, and (ii) a multi-objective dynamic genetic algorithm that selects a specific Spotify music track, according to such values. Gym Intelligence is built by sensing the ambient with a minimal, low-cost, and non-intrusive set of sensors, and it has been designed considering the outcome of a preliminary analysis in real gyms, involving real users. We have considered well-known regression methods and we have validated them using a collected data (i) about the users\u2019 physical effort, through the sensors, and (ii) about the users\u2019 music preferences, through an Android app that the users have used during the training. Among the regression methods considered, the one that provided the best results is the Random Forest, which predicted Spotify music features with a mean absolute error of 0.02 and a root mean squared error of 0.05. We have implemented Gym Intelligence and deployed it in five real gyms. We have evaluated it conducting several experiments. The experiments show how, with the help of Gym Intelligence, the users\u2019 satisfaction about the provided background music, rose from 3.05 to 4.91 (on a scale from 1 to 5, where 5 is the maximum score).","Ambient Intelligence | Background music service | Genetic algorithm | Internet of Things | Machine learning | Multi-agent systems","Expert Systems with Applications","Article","https:\/\/www.doi.org\/10.1016\/j.eswa.2021.114951","2-s2.0-85104365062"],["2021-09-01","Vittorio Scarano","Poster: The need for a collaborative approach to cyber security education","Traditional forms of cyber security education mainly focus on knowledge transmission, which means that knowledge is perceived as a tangible object being transferred from an expert (i.e., the teacher) to a beginner. When practiced well, the learner may acquire such knowledge, but not the resilience to apply it in various contexts [1], [2]. This is especially troubling for the cyber security domain, given the dynamic and constantly changing nature of the field and the environments in which it is required. We therefore need forms of education that aim at understanding the interdisciplinary nature of the field of cyber security as well as at the development of joint action in context: being able to quickly analyse and understand evolving and possibly previously unseen situations and take collaborative action to prevent, detect and recover from incidents.","Collaborative Learning | Computer science education | Cyber Security | Cyber Security Education | Security and Protection","Proceedings - 2021 IEEE European Symposium on Security and Privacy, Euro S and P 2021","Conference Paper","https:\/\/www.doi.org\/10.1109\/EuroSP51992.2021.00058","2-s2.0-85119261898"],["2021-08-17","Vittorio Scarano","Welcome Message from the CS-EDU Workshop Organizers",null,null,"ACM International Conference Proceeding Series","Editorial","https:\/\/www.doi.org\/None","2-s2.0-85113197269"],["2021-07-01","Delfina Malandrino","The sight of Justice. Visual knowledge mining, legal data and computational crime analysis","One of the challenges in the emerging field of computational crime analysis is that of extracting actionable knowledge from heterogeneous (both legal and empirical) information hidden into criminal proceedings. Public prosecutors generally deal with information systems that do not provide advanced information extraction functionalities and that boil down to databases containing complaints, criminal records or police reports. In this paper, we dwell on how information visualization can support knowledge mining in criminal investigations by playing a three-fold role: (a) depicting the structural and qualitative features of both criminal organizations and their members; (b) showing the evolution of criminal networks over time; (c) enhance the interaction between the domain expert and computational heuristics in the knowledge construction process. We present three visualizations designed to support knowledge mining in criminal investigations that have been tested with real data and evaluated by legal scholars and public prosecutors within a computational crime analysis project.","Crime analysis | Legal data | Legal Knowledge mining | Visualization","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV53921.2021.00050","2-s2.0-85118428679"],["2021-07-01","Gennaro Cordasco","Social influence maximization in hypergraphs","This work deals with a generalization of the minimum Target Set Selection (TSS) problem, a key algorithmic question in information diffusion research due to its potential commercial value. Firstly proposed by Kempe et al., the TSS problem is based on a linear threshold diffusion model defined on an input graph with node thresholds, quantifying the hardness to influence each node. The goal is to find the smaller set of items that can influence the whole network according to the diffusion model defined. This study generalizes the TSS problem on networks characterized by many-to-many relationships modeled via hypergraphs. Specifically, we introduce a linear threshold diffusion process on such structures, which evolves as follows. Let H = (V, E) be a hypergraph. At the beginning of the process, the nodes in a given set S \u2286 V are influenced. Then, at each iteration, (i) the influenced hyperedges set is augmented by all edges having a sufficiently large number of influenced nodes; (ii) consequently, the set of influenced nodes is enlarged by all the nodes having a sufficiently large number of already influenced hyperedges. The process ends when no new nodes can be influenced. Exploiting this diffusion model, we define the minimum Target Set Selection problem on hypergraphs (TSSH). Being the problem NP-hard (as it generalizes the TSS problem), we introduce four heuristics and provide an extensive evaluation on real-world networks.","High-order networks | Hypergraphs | Influence diffusion | Social networks | Target set selection","Entropy","Article","https:\/\/www.doi.org\/10.3390\/e23070796","2-s2.0-85118377096"],["2021-07-01","Delfina Malandrino","Graph embedding of music structures for machine learning approaches","Several works on representation learning for graph-structured data have been proposed in recent literature. However, most of such techniques have several downsides. On the one hand, graph kernels which use handcrafted features (e.g., shortest paths) are hampered by poor generalization problems. On the other hand, methods for learning representations of whole graphs deal with unattributed or single-attributed graphs.In this work, we propose a novel technique for graph embedding learning able to take into account multi-attribute graphs (from 1 to an arbitrary number). Given a multi-attribute graph, the proposed method generates an embedding vector as follows: (i) the graph is split into several single-attribute graphs; for each of these, one numeric vector is generated by using state-of-the-art graph embedding techniques; (ii) the obtained vectors are concatenated in one representative vector using a multi-view learning integration technique; (iii) the size of such a vector is reduced through deep autoencoders.Experiments have been conducted on the music style recognition problem. We focus on the corpus of 4-voice J. S. Bach' compositions. First, such a corpus has been decomposed and translated into graph-based structures corresponding to the music scores. Then, the proposed method is applied to generate the embedding vectors from the obtained graphs. Finally, a Random Forest model trained on such obtained vectors is used for generating novels music compositions in the learned style. Results obtained show the effectiveness of the proposed approach.","Graph embedding | Machine learning | Music style recognition","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV53921.2021.00054","2-s2.0-85118447853"],["2021-05-11","Biagio Cosenza","The Italian research on HPC key technologies across EuroHPC","High-Performance Computing (HPC) is one of the strategic priorities for research and innovation worldwide due to its relevance for industrial and scientific applications. We envision HPC as composed of three pillars: infrastructures, applications, and key technologies and tools. While infrastructures are by construction centralized in large-scale HPC centers, and applications are generally within the purview of domain-specific organizations, key technologies fall in an intermediate case where coordination is needed, but design and development are often decentralized. A large group of Italian researchers has started a dedicated laboratory within the National Interuniversity Consortium for Informatics (CINI) to address this challenge. The laboratory, albeit young, has managed to succeed in its first attempts to propose a coordinated approach to HPC research within the EuroHPC Joint Undertaking, participating in the calls 2019 - 20 to five successful proposals for an aggregate total cost of 95M\u20ac. In this paper, we outline the working group's scope and goals and provide an overview of the five funded projects, which become fully operational in March 2021, and cover a selection of key technologies provided by the working group partners, highlighting their usage development within the projects.","high-performance computing | parallel programming","Proceedings of the 18th ACM International Conference on Computing Frontiers 2021, CF 2021","Conference Paper","https:\/\/www.doi.org\/10.1145\/3457388.3458508","2-s2.0-85105980898"],["2021-04-01","Delfina Malandrino","Techno-regulation and intelligent safeguards: Analysis of touch gestures for online child protection","The growth of Internet and the pervasiveness of ICT have led to a radical change in social relationships. One of the drawbacks of this change is the exposure of individuals to threats during online activities. In this context, the techno-regulation paradigm is inspiring new ways to safeguard legally interests by means of tools allowing to hamper breaches of law. In this paper, we focus on the exposure of individuals to specific online threats when interacting with smartphones. We propose a novel techno-regulatory approach exploiting machine learning techniques to provide safeguards against threats online. Specifically, we study a set of touch-based gestures to distinguish between underages or adults who is accessing a smartphone, and so to guarantee protection. To evaluate the proposed approach\u2019s effectiveness, we developed an Android app to build a dataset consisting of more than 9000 touch-gestures from 147 participants. We experimented both single-view and multi-view learning techniques to find the best combination of touch-gestures able of distinguishing between adults and underages. Results show that the multi-view learning combining scrolls, swipes, and pinch-to-zoom gestures, achieves the best ROC AUC (0.92) and accuracy (88%) scores.","Machine learning | Multi-view learning | Online child protection | Techno-regulation | Touch-based gesture analysis","Multimedia Tools and Applications","Article","https:\/\/www.doi.org\/10.1007\/s11042-020-10446-y","2-s2.0-85100542537"],["2021-04-01","Gennaro Cordasco","Elder user\u2019s attitude toward assistive virtual agents: the role of voice and gender","This paper reports on experiments devoted to explore the role of specific attributes of humanoid virtual agents that may influence elderly users\u2019 perception and attitude, determining their acceptance and adoption as assistive devices. In particular, it investigates elderly preference on agents\u2019 gender and the role of the agents\u2019 ability to use voice during the interaction. To this aim two different groups of seniors were involved in the experiments. The first group evaluated talking virtual agents, the second one the same virtual agents, but silenced. The data shows that elderly users, independently from their gender, prefer to interact with female agents, especially when they are able to talk to them, revealing the role played by the voice. Furthermore, it was found a significant effect of the elderly level of experience with technology: when interacting with agents with voice, elderly users with high technological experience were less interested and considered the proposed agents less attractive and appealing, while just the opposite occurred when interacting with silenced agents.",null,"Journal of Ambient Intelligence and Humanized Computing","Article","https:\/\/www.doi.org\/10.1007\/s12652-019-01423-x","2-s2.0-85071294774"],["2021-03-01","Gennaro Cordasco","Easy and efficient agent-based simulations with the OpenABL language and compiler","Agent-based simulations represent an effective scientific tool, with numerous applications from social sciences to biology, which aims to emulate or predict complex phenomena through a set of simple rules performed by multiple agents. To simulate a large number of agents with complex models, practitioners have developed high-performance parallel implementations, often specialized for particular scenarios and target hardware. It is, however, difficult to obtain portable simulations, which achieve high performance and at the same time are easy to write and to reproduce on different hardware. This article gives a complete presentation of OPENABL, a domain-specific language and a compiler for agent-based simulations that enable users to achieve high-performance parallel and distributed agent simulations with a simple and portable programming environment. OPENABL is comprised of (1) an easy-to-program language, which relies on domain abstractions and explicitly exposes agent parallelism, synchronization and locality, (2) a source-to-source compiler, and (3) a set of pluggable compiler backends, which generate target code for multi-core CPUs, GPUs, and cloud-based systems. We evaluate OPENABL on simulations from different fields. In particular, our analysis includes predator\u2013prey and keratinocyte, two complex simulations with multiple step functions, heterogeneous agent types, and dynamic creation and removal of agents. The results show that OPENABL-generated codes are portable to different platforms, perform similarly to manual target-specific implementations, and require significantly fewer lines of codes.","Agent-based simulation | Compilers | Domain specific language | GPU | Parallel and distributed computing","Future Generation Computer Systems","Article","https:\/\/www.doi.org\/10.1016\/j.future.2020.10.014","2-s2.0-85094807912"],["2021-02-01","Gennaro Cordasco","Perfectionism and Burnout During the COVID-19 Crisis: A Two-Wave Cross-Lagged Study","The current study aims at examining the relationship between the perfectionism two-factor model (i.e., concerns and strivings) and burnout dimensions measured by using the BAT (Burnout Assessment Tool) through a longitudinal study. A two-wave cross-lagged study was conducted using path analysis in SEM (Structural Equation Modeling) of 191 workers. Results confirmed the predictive role of perfectionistic concerns on the burnout dimensions, whereas perfectionistic strivings were not significantly related, suggesting that perfectionism should be monitored by employers and clinicians to prevent employee burnout. Limitations and future research directions are envisaged.","burnout | Burnout Assessment Tool | cross-lagged panel study | path analysis | perfectionism","Frontiers in Psychology","Article","https:\/\/www.doi.org\/10.3389\/fpsyg.2020.631994","2-s2.0-85100860971"],["2021-01-01","Vittorio Scarano","Preface",null,null,"Advances in Intelligent Systems and Computing","Editorial","https:\/\/www.doi.org\/None","2-s2.0-85090089195"],["2021-01-01","Gennaro Cordasco","Intelligent Advanced User Interfaces for Monitoring Mental Health Wellbeing","It has become pressing to develop objective and automatic measurements integrated in intelligent diagnostic tools for detecting and monitoring depressive states and enabling an increased precision of diagnoses and clinical decision-makings. The challenge is to exploit behavioral and physiological biomarkers and develop Artificial Intelligent (AI) models able to extract information from a complex combination of signals considered key symptoms. The proposed AI models should be able to help clinicians to rapidly formulate accurate diagnoses and suggest personalized intervention plans ranging from coaching activities (exploiting for example serious games), support networks (via chats, or social networks), and alerts to caregivers, doctors, and care control centers, reducing the considerable burden on national health care institutions in terms of medical, and social costs associated to depression cares.","Artificial intelligence | Biometric data | Customer care | Intelligent human-computer interfaces | Social behavior | Social signal processing","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-68007-7_5","2-s2.0-85102612746"],["2021-01-01","Gennaro Cordasco","Emotional state recognition performance improvement on a handwriting and drawing task","In this work we combine time, spectral and cepstral features of the signal captured in a tablet to characterize depression, anxiety, and stress emotional state recognition on the EMOTHAW database. EMOTHAW contains the emotional states of users represented by capturing signals from sensors on the tablet and pen when the user is performing 3 specific handwriting and 4 drawing tasks, which had been categorized into depressed, anxious, stressed, and typical, according to the Depression, Anxiety and Stress Scale (DASS). Each user was characterized with six time-domain features, and the number of spectral-domain and cepstral-domain features for the horizontal and vertical displacement of the pen, the pressure on the paper, and the time spent on-air and off-air, depended on the configuration of the filterbank. As next step, we select the best features using the Fast Correlation-Based Filtering method. Since our dataset has 129 users, then as next step, we augmented the training data by randomly selecting a percentage of the training data and adding a small random Gaussian noise to the extracted features. We then train a radial basis SVM model using the Leave-One-Out (LOO) methodology. The experimental results show an average accuracy classification improvement ranging of 15%, and an accuracy classification improvement ranging from 4% to 34% compared with baseline (state of the art) for specific emotions such as depression, anxiety, stress, and typical emotional states.","Data augmentation | Emotional state recognition | Emotional states | Feature extraction | SVM","IEEE Access","Article","https:\/\/www.doi.org\/10.1109\/ACCESS.2021.3058443","2-s2.0-85100838687"],["2021-01-01","Carmine Spagnuolo","Modeling and Evaluating Epidemic Control Strategies with High-Order Temporal Networks","Non-Pharmaceutical Interventions (NPIs) are essential measures that reduce and control a severe outbreak or a pandemic, especially in the absence of drug treatments. However, estimating and evaluating their impact on society remains challenging, considering the numerous and closely tied aspects to examine. This article proposes a fine-grain modeling methodology for NPIs, based on high-order relationships between people and environments, mimicking direct and indirect contagion pathways over time. After assessing the ability of each intervention in controlling an epidemic propagation, we devise a multi-objective optimization framework, which, based on the epidemiological data, calculates the NPI combination that should be implemented to minimize the spread of an epidemic as well as the damage due to the intervention. Each intervention is thus evaluated through an agent-based simulation, considering not only the reduction in the fraction of infected but also to what extent its application damages the daily life of the population. We run experiments on three data sets, and the results illustrate how the application of NPIs should be tailored to the specific epidemic situation. They further highlight the critical importance of correctly implementing personal protective (e.g., using face masks) and sanitization measures to slow down a pathogen spreading, especially in crowded places.","Agent-based modeling | complex networks | epidemic | high-order relationships | hypergraphs | non-pharmaceutical interventions","IEEE Access","Article","https:\/\/www.doi.org\/10.1109\/ACCESS.2021.3119459","2-s2.0-85117271030"],["2021-01-01","Carmine Spagnuolo","Automatic Skill Generation for Knowledge Graph Question Answering","Knowledge Graphs are a critical source for Question Answering, but their potential may be threatened due to the complexity of their query languages, such as SPARQL. On the opposite side, Virtual Assistants have witnessed an extraordinary interest as they enable users to pose questions in natural language. Many companies and researchers have combined Knowledge Graphs and Virtual Assistants, but no one has provided end-users with a generic methodology to generate extensions for automatically querying knowledge graphs. Thus, we propose a community shared software framework to create custom extensions to query knowledge graphs by virtual assistants, unlocking the potentialities of the Semantic Web technologies by bringing knowledge graphs in the \u201cpocket\u201d of everyone, accessible from smartphones or smart speakers.","Knowledge Graphs | Question Answering | Software framework | Virtual Assistant","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-80418-3_7","2-s2.0-85115874952"],["2021-01-01","Gennaro Cordasco","Other Advanced Research Initiatives in Elderly Care and Fragility Prevention","Based on the lessons learnt from the co-design, development and integration processes, the research findings and the outputs from the engagement with a network of stakeholders over the course of the EU funded initiatives, this chapter will aim to help sketching the future policies and research funding programmes for ageing well in Europe. The chapter presents the visions and the perspectives of the running projects in the frame of the H2020 Personalized Medicine-15 call.",null,"Research for Development","Book Chapter","https:\/\/www.doi.org\/10.1007\/978-3-030-72663-8_20","2-s2.0-85109545497"],["2021-01-01","Carmine Spagnuolo","TraceMeNow: an Open-Source Software Framework for Indoor Localization Applications","The increased number of smartphone-connected devices and the pervasive presence of sensors enabled the application of localization and tracking technologies in multiple contexts. Health, customer care, traveling, crowd management are just some of the possible fields where an Indoor Positioning System could be useful. Despite the effort of the research community, the integration of an Indoor Positioning System within an application is still difficult since it requires expertise in diverse fields like communication technologies, localization techniques, and hardware. This paper presents TraceMeNow, an open-source framework for developing applications comprising an Indoor Positioning System based on Bluetooth Low Energy and low-cost hardware. TraceMeNow is designed to improve developers\u2019 experience without requiring specific knowledge to be used, thus aiming to be a simple and valuable tool suitable for different situations and accessible to any developer. TraceMeNow adopts a modular architecture enhancing the interoperability between components and supporting the developer throughout all the implementation phases. We aim to show the flexibility and ease of use of our framework by presenting an application to address a real-world use case. TraceMeNow aims to reduce the cost and the effort needed to create an application comprising an Indoor Positioning System, providing the basis for all the components and relying on mainstream technologies for hardware and communication. Moreover, TraceMeNow allows developers exploiting cloud computing when facing large scenarios with specific requirements such as high scalability and reliability, maintaining the same ease of use since the interaction with the provider is entirely abstracted.","Bluetooth Low Energy | Indoor Localization | Indoor Positioning System","CEUR Workshop Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-85126627686"],["2021-01-01","Biagio Cosenza","ALONA: Automatic Loop Nest Approximation with Reconstruction and\u00a0Space Pruning","Approximate computing comprises a large variety of techniques that trade the accuracy of an application\u2019s output for other metrics such as computing time or energy cost. Many existing approximation techniques focus on loops such as loop perforation, which skips iterations for faster, approximated computation. This paper introduces ALONA, a novel approach for automatic loop nest approximation based on polyhedral compilation. ALONA\u2019s compilation framework applies a sequence of loop approximation transformations, generalizes state-of-the-art perforation techniques, and introduces new multi-dimensional approximation schemes. The framework includes a reconstruction technique that significantly improves the accuracy of the approximations and a transformation space pruning method based on Barvinok\u2019s counting that removes inaccurate approximations. Evaluated on a collection of more than twenty applications from PolyBench\/C, ALONA discovers new approximations that are better than state-of-the-art techniques in both approximation accuracy and performance.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-85665-6_1","2-s2.0-85115176472"],["2021-01-01","Gennaro Cordasco","Advanced assistive technologies for elderly people: A psychological perspective on older users\u2019 needs and preferences (part B)","This paper provides a general overview of the literature regarding advanced assistive technologies devoted to improving elders\u2019 life. Recent studies on assistive robots and embodied conversational agents are carefully examined in order to identify main seniors\u2019 preferences regarding their general design. While providing data on seniors\u2019 preferences about the design of assistive devices, main evidence on both robots and virtual agent\u2019s appearance, abilities\/functionalities, personalities, and role features are summarized and commented.","Assistive technology | Design | Older user | Preferences | Robot | Virtual agent","Acta Polytechnica Hungarica","Article","https:\/\/www.doi.org\/10.12700\/APH.18.1.2021.1.3","2-s2.0-85108639952"],["2021-01-01","Gennaro Cordasco","Emotional virtual agents: How do young people decode synthetic facial expressions?","Given the need of remote learning and the growing presence of virtual agents within online learning environments, the present research aims at investigating young people\u2019 ability to decode emotional expressions conveyed by virtual agents. The study, involves 50 healthy participants aged between 22 and 35 years (mean age=27.86; SD= \u00b12.75; 30 females) which were required to label pictures and video clips depicting female and male virtual agents of different ages (young, middle-aged and old) displaying static and dynamic expressions of disgust, anger, sadness, fear, happiness, surprise and neutrality. Depending on the emotional category, significant effects were observed for the agents\u2019 age, gender, and type of administered (static vs dynamic) stimuli on the young people\u2019 decoding accuracy of the virtual agents\u2019 emotional faces. Anger was significantly more accurately decoded in male rather than female faces while the opposite result was observed for happy, fearful, surprised, and disgusted faces. Middle aged faces were generally more accurately decoded than young and old emotional faces except for sadness and disgust. Significantly greater accuracy was observed for dynamic vs static faces of disgust, sadness, and fear, in contrast to static vs dynamic neutral and surprised faces.","Age differences | Emotional decoding of synthetic facial expressions | Gender differences | Online learning | Virtual agents","CEUR Workshop Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-85101739839"],["2021-01-01","Delfina Malandrino","Education meets knowledge graphs for the knowledge management","Data are a crucial source for informed decision making. However, their unrestrainable growth requires approaches and tools to learn how to query and identify data of interest. The problem we want to face is how to guide students in going beyond the passive inspection of results returned by a search engine, and in actively searching for the data that best answer their questions. Our final goal is to guide future citizens in actively creating their knowledge supported by data. In particular, we focus on Knowledge Graphs and how they can be used in the knowledge management process in the educational context. We present ELODIE and the datalet mechanism as a tool to support the knowledge management process. We will describe its features, and we will discuss how teachers and students could exploit it in the educational context.","Data literacy | Data visualization | Information retrieval | Knowledge Graphs | Knowledge management | Semantic search | Semantic web","Advances in Intelligent Systems and Computing","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-52287-2_28","2-s2.0-85090094618"],["2021-01-01","Vittorio Scarano","Novelette, a Usable Visual Storytelling Digital Learning Environment","Educational digital storytelling is widely recognised as a powerful approach in developing literary skills, experiencing problem-solving and computational thinking, information and knowledge visualisation, building creativity and divergent thinking supported by technological solutions. However, educators feel that they miss opportunities, skills, and tools to support pupils developing creativity. Hence, we proposed a digital learning environment, named Novelette, to support both educators and learners in performing visual storytelling by scaffolding them in inventing and authoring stories. The main novelty of our approach lies in embedding literary artifices widely explored in learning settings into a digital learning environment, such as the opportunity to continue someone else's story and the suggestion mechanism to explore analogies or synonyms starting from a word of interest. Novelette has been ideated not only as a learning environment for educators, but with educators, as it results from a user-centered and participatory design methodology to involve them in the entire design and development process actively. This paper focuses on the assessment of Novelette usability according to both educators and pupils. As a conclusive step of the co-design approach, developers tested the resulting usability according to educators in a controlled environment. Moreover, it reports usability according to learners in real settings at school. Results demonstrate that Novelette is considered usable by both target groups, and it is perceived as a powerful approach in developing creativity both according to quantitative insight offered by the System Usability Scale, a.k.a., SUS, and qualitative interpretations enabled with direct observations and structured after scenario questionnaires. We can conclude that Novelette is a pleasant and usable tool to invent and author stories and seems to be a promising approach to develop creativity.","Collaborative design | digital learning environment | digital storytelling | education | usability","IEEE Access","Article","https:\/\/www.doi.org\/10.1109\/ACCESS.2021.3137076","2-s2.0-85122064602"],["2021-01-01","Gennaro Cordasco","Vertex Separation in Networks","We study the problems of finding a subset of nodes having a given size k and satisfying one of the following separation properties: The set is disconnected from the rest of the graph by a small\/large cut or by a small separator. The considered problems are of interest in several practical settings, such as epidemiology or disaster control as well as to contrast viruses, malware, or misinformation propagate quickly in online social networks. All the considered problems are known to be NP-hard. Being computation time for very large networks is an important issue, we consider some parameters of the input graph G and show that the problems become tractable for small values of such parameters. Namely, we show that they become tractable when parameterized either by the neighborhood diversity or by the treewidth of G. We also consider the complexity of the problems when parameterized by the clique-width cw of G and show that they all can be solved in O(n^f(cw)), where n is the number of nodes in G. We also show that there is no f(cw)n^o(cw)- time algorithm for the graph cut problems (unless ETH fails).","Graph cut | Graph separator | Neighbourhood diversity and Clique-width | Parameterized Complexity | Treewidth","2021 8th International Conference on Social Network Analysis, Management and Security, SNAMS 2021","Conference Paper","https:\/\/www.doi.org\/10.1109\/SNAMS53716.2021.9732127","2-s2.0-85127425496"],["2021-01-01","Gennaro Cordasco","Discriminative Power of EEG-Based Biomarkers in Major Depressive Disorder: A Systematic Review","Currently, the diagnosis of major depressive disorder (MDD) and its subtypes is mainly based on subjective assessments and self-reported measures. However, objective criteria as Electroencephalography (EEG) features would be helpful in detecting depressive states at early stages to prevent the worsening of the symptoms. Scientific community has widely investigated the effectiveness of EEG-based measures to discriminate between depressed and healthy subjects, with the aim to better understand the mechanisms behind the disorder and find biomarkers useful for diagnosis. This work offers a comprehensive review of the extant literature concerning the EEG-based biomarkers for MDD and its subtypes, and identify possible future directions for this line of research. Scopus, PubMed and Web of Science databases were researched following PRISMA's guidelines. The initial papers' screening was based on titles and abstracts; then full texts of the identified articles were examined, and a synthesis of findings was developed using tables and thematic analysis. After screening 1871 articles, 76 studies were identified as relevant and included in the systematic review. Reviewed markers include EEG frequency bands power, EEG asymmetry, ERP components, non-linear and functional connectivity measures. Results were discussed in relations to the different EEG measures assessed in the studies. Findings confirmed the effectiveness of those measures in discriminating between healthy and depressed subjects. However, the review highlights that the causal link between EEG measures and depressive subtypes needs to be further investigated and points out that some methodological issues need to be solved to enhance future research in this field.","Biomarkers | cognitive science | depressive subtypes | early detection | EEG measures | electroencephalography (EEG) | major depressive disorder (MDD)","IEEE Access","Review","https:\/\/www.doi.org\/10.1109\/ACCESS.2021.3103047","2-s2.0-85112193360"],["2021-01-01","Gennaro Cordasco","A Lightweight Machine Learning Approach to Detect Depression from Speech Analysis","The growing number of people suffering from depression makes it increasingly necessary to find new approaches able to support medical experts in its diagnosis. The early detection of depressive symptoms is crucial in limiting the co-occurrence of associated behavioural disorders such as psycho-motor retardation symptoms and social withdrawal. Therefore, automatic detection systems represent promising solutions not only for supporting the early diagnosis of the disease but also for monitoring patient's health status, thus improving both the quality of the care process and life quality of patients. At the light of these considerations, this paper proposes an automatic system exploiting a machine learning algorithm, to distinguish among depressed and healthy subjects through the analysis of selected acoustic features extracted from spontaneous speech narratives produced by healthy and depressed subjects. The proposed system achieves a classification accuracy of about 85%, proving to be a promising solution for supporting the diagnosis of depression in real-time in a reliable, fast, inexpensive and non-intrusive ways.","Biomedical Application | Depression Detection | Healthcare system | Machine Learning algorithms | Speech Signals","Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICTAI52525.2021.00054","2-s2.0-85123916502"],["2021-01-01","Gennaro Cordasco","Emotional Features of Interactions with Empathic Agents","The current study is part of the EMPATHIC project, whose aim is to develop an Empathic Virtual Coach (VC) capable of promoting healthy and independent aging. To this end, the VC needs to be capable of perceiving the emotional states of users and adjusting its behaviour during the interactions according to what the users are experiencing in terms of emotions and comfort. Thus, the present work focuses on some sessions where elderly users of three different countries interact with a simulated system. Audio and video information extracted from these sessions were examined by external observers to assess participants' emotional experience with the EMPATHIC-VC in terms of categorical and dimensional assessment of emotions. Analyses were conducted on the emotional labels assigned by the external observers while participants were engaged in two different scenarios: a generic one, where the interaction was carried out with no intention to discuss a specific topic, and a nutrition one, aimed to accomplish a conversation on users' nutritional habits. Results of analyses performed on both audio and video data revealed that the EMPATHIC coach did not elicit negative feelings in the users. Indeed, users from all countries have shown relaxed and positive behavior when interacting with the simulated VC during both scenarios. Overall, the EMPATHIC-VC was capable to offer an enjoyable experience without eliciting negative feelings in the users. This supports the hypothesis that an Empathic Virtual Coach capable of considering users' expectations and emotional states could support elderly people in daily life activities and help them to remain independent.",null,"Proceedings of the IEEE International Conference on Computer Vision","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICCVW54120.2021.00246","2-s2.0-85123058467"],["2020-12-01","Gennaro Cordasco","Analysis of the interaction between elderly people and a simulated virtual coach","The EMPATHIC project develops and validates new interaction paradigms for personalized virtual coaches (VC) to promote healthy and independent aging. To this end, the work presented in this paper is aimed to analyze the interaction between the EMPATHIC-VC and the users. One of the goals of the project is to ensure an end-user driven design, involving senior users from the beginning and during each phase of the project. Thus, the paper focuses on some sessions where the seniors carried out interactions with a Wizard of Oz driven, simulated system. A coaching strategy based on the GROW model was used throughout these sessions so as to guide interactions and engage the elderly with the goals of the project. In this interaction framework, both the human and the system behavior were analyzed. The way the wizard implements the GROW coaching strategy is a key aspect of the system behavior during the interaction. The language used by the virtual agent as well as his or her physical aspect are also important cues that were analyzed. Regarding the user behavior, the vocal communication provides information about the speaker\u2019s emotional status, that is closely related to human behavior and which can be extracted from the speech and language analysis. In the same way, the analysis of the facial expression, gazes and gestures can provide information on the non verbal human communication even when the user is not talking. In addition, in order to engage senior users, their preferences and likes had to be considered. To this end, the effect of the VC on the users was gathered by means of direct questionnaires. These analyses have shown a positive and calm behavior of users when interacting with the simulated virtual coach as well as some difficulties of the system to develop the proposed coaching strategy.","Emotional analysis from speech | Human behavior analysis | Human\u2013machine interaction | Language and face | Spanish","Journal of Ambient Intelligence and Humanized Computing","Article","https:\/\/www.doi.org\/10.1007\/s12652-020-01983-3","2-s2.0-85085276917"],["2020-12-01","Gennaro Cordasco","Ethical issues in assistive ambient living technologies for ageing well","Assistive Ambient Living (AAL) in ageing refers to any device used to support ageing related psychological and physical changes aimed at improving seniors\u2019 quality of life and reducing caregivers\u2019 burdens. The diffusion of these devices opens the ethical issues related to their use in the human personal space. This is particularly relevant when AAL technologies are devoted to the ageing population that exhibits special bio-psycho-social aspects and needs. In spite of this, relatively little research has focused on ethical issues that emerge from AAL technologies. The present article addresses ethical issues emerging when AAL technologies are implemented for assisting the elderly population and is aimed at raising awareness of these aspects among healthcare providers. The overall conclusion encourages a person-oriented approach when designing healthcare facilities. This process must be fulfilled in compliance with the general principles of ethics and individual nature of the person devoted to. This perspective will develop new research paradigms, paving the way for fulfilling essential ethical principles in the development of future generations of personalized AAL devices to support ageing people living independently at their home.","Ageing | Assistive ambient living | Elderly | Ethics | Healthcare","Multimedia Tools and Applications","Article","https:\/\/www.doi.org\/10.1007\/s11042-020-09313-7","2-s2.0-85088108633"],["2020-12-01","Gennaro Cordasco","'Not only faces': Specialized visual representation of human hands revealed by adaptation: Human hand adaptation","Classical neurophysiological studies demonstrated that the monkey brain is equipped with neurons selectively representing the visual shape of the primate hand. Neuroimaging in humans provided data suggesting that a similar representation can be found in humans. Here, we investigated the selectivity of hand representation in humans by means of the visual adaptation technique. Results showed that participants' judgement of human-likeness of a visual probe representing a human hand was specifically reduced by a visual adaptation procedure when using a human hand adaptor but not when using an anthropoid robotic hand or a non-primate animal paw adaptor. Instead, human-likeness of the anthropoid robotic hand was affected by both human and robotic adaptors. No effect was found when using a non-primate animal paw as adaptor or probe. These results support the existence of specific neural mechanisms encoding human hand in the human's visual system.","adaptation | anthropoid hand | hand representation | occipitotemporal cortex | visual processing","Royal Society Open Science","Article","https:\/\/www.doi.org\/10.1098\/rsos.200948","2-s2.0-85099553869"],["2020-11-01","Gennaro Cordasco","Seniors' ability to decode differently aged facial emotional expressions","The present investigation aims at assessing elders' ability to decode facial emotional expressions conveyed by differently aged people in order to confirm (or disconfirm) the appropriateness of the 'own age bias' theory, as well as investigate effects of different ages and different emotional categories. The study, involves 44 healthy elders (23 females), aged 65+ (mean age=75.09; SD=\u00b17.9) which were requested to label 76 pictures depicting elders, middle-aged and young women and men displaying the six facial emotional expressions of disgust, anger, fear, sadness, happiness and neutrality. Results show a complex pattern of influences that calls for more deep investigations on the features to be accounted by providing socially and emotionally believable interfaces of effective and efficient algorithms to detect and decode their users' emotional facial expressions.",null,"Proceedings - 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2020","Conference Paper","https:\/\/www.doi.org\/10.1109\/FG47880.2020.00077","2-s2.0-85101481217"],["2020-09-23","Gennaro Cordasco","Gender identification through handwriting: An online approach","The present study was designed to identify writer's gender trough online handwriting and drawing analysis. Two groups - one of 126 males (mean age 24.65, SD=2.45) and the other of 114 females (mean age 24.51, SD=2.50) participants were recruited in the experiment. They were asked to perform seven writing and drawing tasks utilizing a digitizing tablet and a special writing device. Seventeen writing features grouped into five categories have been considered. The experiment's results show that the set of considered features enable to discriminate between male and female writers investigating their performance while copying a house drawing (task 2), writing words in capital letters (task 3) and writing a complete sentence in cursive letters (task 7), in particular focusing on Ductus (number of strokes) and Time categories of writing features.","Drawing | Gender recognition | Handwriting | Online analysis","11th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2020 - Proceedings","Conference Paper","https:\/\/www.doi.org\/10.1109\/CogInfoCom50765.2020.9237863","2-s2.0-85096357531"],["2020-09-23","Gennaro Cordasco","Frontal left alpha activity as an indicator of willingness to interact with virtual agents: A pilot study","Over the last decade, much effort has been made to develop virtual agents acting as assistants of elderly people in their daily activities. With the emergence of such technologies, several questionnaires have been developed to investigate the factors increasing user's acceptance of virtual agents. While questionnaires provide detailed information about users' preferences, they may not be sufficient for investigating user's internal affective states and impressions during the interaction with virtual agents. Therefore, improving assessment techniques for elders' acceptance of virtual agents is necessary for understanding the impressions they arouse and determining their design accordingly. This paper is a report of a pilot study that benefits from the predictive ability of left frontal alpha activity in the brain on positive affect and approach related motivation, and investigates relationships between user's willingness to interact with virtual agents and left frontal alpha activity in order to gain insights on user's affective and motivational states during the interaction with an agent.","Affective-motivational states | Assistive technologies | EEG | Frontal alpha asymmetry | Left frontal activity | User acceptance","11th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2020 - Proceedings","Conference Paper","https:\/\/www.doi.org\/10.1109\/CogInfoCom50765.2020.9237885","2-s2.0-85096356247"],["2020-09-23","Gennaro Cordasco","Behavioral sentiment analysis of depressive states","The need to release accurate and incontrovertible diagnoses of depression has fueled the search for new methodologies to obtain more reliable measurements than the commonly adopted questionnaires. In such a context, research has sought to identify non-biased measures derived from analyses of behavioral data such as voice and language. For this purpose, sentiment analysis techniques were developed, initially based on linguistic characteristics extracted from texts and gradually becoming more and more sophisticated by adding tools for the analyses of voice and visual data (such as facial expressions and movements). This work summarizes the behavioral features accounted for detecting depressive states and sentiment analysis tools developed to extract them from text, audio, and video recordings.","Behaviors | Depression | Faces | Language | Sentiment analysis | Speech | Texts | Videos","11th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2020 - Proceedings","Conference Paper","https:\/\/www.doi.org\/10.1109\/CogInfoCom50765.2020.9237856","2-s2.0-85096351958"],["2020-09-01","Gennaro Cordasco","Speeding up networks mining via neighborhood diversity","Parameterized complexity was classically used to efficiently solve NP-hard problems for small values of a fixed parameter. Then it has also been used as a tool to speed up algorithms for tractable problems. Following this line of research, we design algorithms parameterized by neighborhood diversity (nd) for several graph theoretic problems in P (e.g., Maximum Matching, Triangle counting and listing, Girth and Global minimum vertex cut). Such problems are known to admit algorithms parameterized by modular-width (mw) and consequently - being the nd a \u201cspecial case\u201d of mw - by nd. However, the proposed novel algorithms allow to improve the computational complexity from a time O(f(mw) \u00b7 n + m) - where n and m denote, respectively, the number of vertices and edges in the input graph - which is multiplicative in n to a time O(g(nd) + n + m) which is additive only in the size of the input.","Girth | Global minimum vertex cut | Maximum Matching | Neighborhood Diversity | Parameterized Complexity | Triangle Counting","Leibniz International Proceedings in Informatics, LIPIcs","Conference Paper","https:\/\/www.doi.org\/10.4230\/LIPIcs.FUN.2021.21","2-s2.0-85091409281"],["2020-09-01","Vittorio Scarano","Visual Storytelling by Novelette","Storytelling is an effective way of communicating information and knowledge, and it is widely adopted in heterogeneous contexts, from education by improving critical thinking and enhancing learning practice, to journalism by encouraging coherent stories of news supported by graphical representations. However, storytelling platforms seem to be targeted to a specific audience without showing how they can be adapted to heterogeneous needs, from class support in education to mechanisms to overcome the syndrome of the white page. In this article, we propose Novelette, a digital storytelling environment, and we show how it can be applied in heterogeneous contexts and by the different target audience. We present Novelette operating mechanisms, its architecture, and we overview different use cases, from tales creation Rodari style to data-and media-stories. By use-cases, we desire to make evident that the same platform can generate stories engaging for any target audience.","Authoring stories | Digital environment | Narrative visualization | Storytelling","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV51561.2020.00126","2-s2.0-85102923780"],["2020-09-01","Delfina Malandrino","The Affordance of Law. Sliding Treemaps browsing Hierarchically Structured Data on Touch Devices","Sifting through the flood of documents today available and making sense of them is an ever-growing challenge of our time. Visualization is offering new ways to navigate through large sets of documents, mainly through graphs that intuitively depict textual entities (documents or parts thereof) and relations tying them. A relevant issue is that graphs can be smoothly used, especially in desktop environments. The small size of tablets' and smartphones' screens makes it difficult to simply port graph visualizations from desktop to mobile devices, just as the use of the latter is growing for browsing and reading texts. In the light of the above, a challenge is seamlessly merging abstraction power offered by visualization, information retrieval, and the access to texts. This paper presents a Human-Computer Interaction strategy integrating mobile devices (for visualization-based, high-level and intuitive interaction with data and their relations) and desktop computers (for full-Text reading). We focus on Sliding Treemap, a visualization designed to render graph-like (hierarchical, relational) structures on mobile touch devices. The solution, suitable to be applied also in other domains, has been designed based on the needs of the legal domain, which is \"highly textual\"and still rather unfamiliar with visualization techniques. Sliding Treemap has been developed in the prototype of a cross-platform app using as testbed the catalogue of the European Court of Justice Library, and sets of heterogeneous legal sources from the Italian legal system.","European Court of Justice Library | Human Computer Interaction | legal visual analytics | sliding treemap | touch devices","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV51561.2020.00013","2-s2.0-85102936045"],["2020-09-01","Delfina Malandrino","On the Limitation of Pathological Iris Recognition: Neural Network Perspectives","Over the last few years, biometrics has emerged as an increasingly reliable solution to recognize people using their physiological or behavioural characteristics. Despite their advantages, biometric systems raise many practical, ethical and legal issues. While, understandably, main concerns involve privacy and the risk of covert surveillance, profiling, and social control, another relevant question is the potential exclusion of individuals that, due to injuries, disability or genetic defects, may not meet the physical requirements used for the identification. In such situations, the risk comes out from the limits of current biometrics systems, which could exclude entire classes of individuals with negative spillovers on the possibility of access services and even exercise rights. In this paper, we focus on the recognition of iris suffering from Coloboma, a congenital abnormality of membranes of the eye. We first show how this pathological state impacts on the performance of the Daugman's algorithm, which represents the most widespread method used for the iris localization step in eye-based biometrics. Second, we designed and tested a classifier based on Convolutional Neural Network able to detect the presence of Coloboma with 95.45% accuracy. This result opens up new perspectives towards the definition of more sophisticated \"diversity-Aware\"biometric systems.","Iris Recognition | Neural Network | Techno-regulation","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV51561.2020.00021","2-s2.0-85102931392"],["2020-09-01","Delfina Malandrino","Human-Machine Teaming in Music: Anchored narrative-graph Visualization and Machine Learning","During the traditional music analysis process, stylistic rules usually have to be deduced directly from examples of compositions or past performance. In such cases, musicians create external representations of a music style domain as source for reflection, inspiration and collaboration. However, due to the large number of music examples, creating such representations can be essential, but at the same time, slow and costly.In this paper, we show that interactive visualization and machine learning could aid in supporting and enhancing musician cognition and team-based collaboration. Specifically, we propose an approach to this problem which: (1) allows musicians to visually externalize their evolving mental models of a music domain, in the form of thematically organized anchored pairs. i.e., (narrative, graph), each one corresponding to a specific music pattern, and (2) uses such pairs to develop a music style classification system based on machine learning, as support for musicians during their activities (composition, performance). To this end, we introduce a novel graph representation of music stylistic patterns and discuss the advantages of linking such a representation to machine learning. Results of a preliminary study involving 10 musicians provided us with overall positive feedback about the effectiveness of our approach as well as further directions to explore.","Interactive Visualization | Machine Learning | Music analysis","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV51561.2020.00095","2-s2.0-85102928108"],["2020-09-01","Gennaro Cordasco","How Human Likeness, Gender and Ethnicity affect Elders'Acceptance of Assistive Robots","The present study investigates the extent to which robots' 1) degree of human likeness, 2) gender and 3) ethnicity affect elders' attitude towards using robots as healthcare assistants. To this aim 2 groups of 45 seniors, aged 65 + years, were asked to watch video clips showing three speaking female and male robots, respectively. Each set of stimuli consisted in 2 androids, one with Caucasian and one with Asian aspect, and 1 humanoid robot. After each video clip elders were asked to assess, through the Robot Acceptance Questionnaire (RAQ) their willingness to interact with them, as well as robots' Pragmatic, Hedonic and Attractive qualities. Through this investigation it was found that male seniors were more proactive than female ones in their attitude toward robots showing more willingness to interact with them and attributing more positive scores to robots' qualities. It was also observed that androids were clearly more preferred than humanoid robots no matter their gender. Finally, seniors' preferences were for female android robots with Asian traits and male android with Caucasian traits suggesting that both gender and ethnical features are intermingled in defining robot's appearance that generate seniors' acceptance.","elder users | humanoid\/android robots | robot's acceptance | robots' ethnicity | robots' gender","Proceedings of the 2020 IEEE International Conference on Human-Machine Systems, ICHMS 2020","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICHMS49158.2020.9209546","2-s2.0-85093966045"],["2020-07-01","Biagio Cosenza","Vectorization cost modeling for NEON, AVX and SVE","Compiler optimization passes employ cost models to determine if a code transformation will yield performance improvements. When this assessment is inaccurate, compilers apply transformations that are not beneficial, or refrain from applying ones that would have improved the code. We analyze the accuracy of the cost models used in LLVM's and GCC's vectorization passes for three different instruction set architectures, including both traditional SIMD architectures with a defined fixed vector register size (AVX2 and NEON), and novel instruction set with scalable vector size (SVE). In general, speedup is over-estimated, resulting in mispredictions and a weak to medium correlation between predicted and actual performance gain. We therefore propose a novel cost model that is based on a code's intermediate representation with refined memory access pattern features. Using linear regression techniques, this platform independent model is fitted to an AVX2 and a NEON hardware, as well as an SVE simulator. Results show that the fitted model significantly improves the correlation between predicted and measured speedup (AVX2: +52% for training data, +13% for validation data), reduces the average error of the speedup prediction (SVE: -43% for training data, -36% for validation data), as well as the number of mispredictions (NEON: -88% for training data, -71% for validation data) for more than 80 code patterns.",null,"Performance Evaluation","Article","https:\/\/www.doi.org\/10.1016\/j.peva.2020.102106","2-s2.0-85085746372"],["2020-06-01","Biagio Cosenza","Accurate energy and performance prediction for frequency-scaled GPU kernels","Energy optimization is an increasingly important aspect of today's high-performance computing applications. In particular, dynamic voltage and frequency scaling (DVFS) has become a widely adopted solution to balance performance and energy consumption, and hardware vendors providemanagement libraries that allowthe programmer to change bothmemory and core frequencies manually to minimize energy consumption while maximizing performance. This article focuses on modeling the energy consumption and speedup of GPU applications while using different frequency configurations. The task is not straightforward, because of the large set of possible and uniformly distributed configurations and because of the multi-objective nature of the problem, which minimizes energy consumption and maximizes performance. This article proposes a machine learning-based method to predict the best core and memory frequency configurations on GPUs for an input OpenCL kernel. The method is based on two models for speedup and normalized energy predictions over the default frequency configuration. Those are later combined into a multi-objective approach that predicts a Pareto-set of frequency configurations. Results show that our approach is very accurate at predicting extema and the Pareto set, and finds frequency configurations that dominate the default configuration in either energy or performance.","Energy efficiency | Frequency scaling | GPU | Modeling","Computation","Article","https:\/\/www.doi.org\/10.3390\/COMPUTATION8020037","2-s2.0-85085473186"],["2020-04-27","Biagio Cosenza","SYCL-Bench: A Versatile Single-Source Benchmark Suite for Heterogeneous Computing",null,"Heterogeneous Computing | SYCL Benchmarks &amp;Runtime","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3388333.3388669","2-s2.0-85123042865"],["2020-04-06","Gennaro Cordasco","Fast and frugal targeting with incentives","A widely studied model of influence diffusion in social networks represents the network as a graph G=(V,E), with an integer influence threshold t(v) for each node, and the diffusion process as follows: Initially the members of a chosen set S\u2286V are influenced and, during each subsequent round, the set of influenced nodes is augmented by including every new node v that has at least t(v) previously influenced neighbours. The general problem is to find a small initial set that influences the whole network. In this paper we extend this model by using incentives to reduce the thresholds of some nodes. The goal is to minimize the total amount of the incentive required to ensure that the information diffusion process terminates within a given number of rounds \u03bb. The problem is hard to approximate in general networks. We present optimal polynomial-time algorithms for paths, cycles, trees, and complete networks for any \u03bb. For the special case \u03bb=1, we present a polynomial-time algorithm with a logarithmic approximation guarantee for any network.","Algorithms | Information diffusion | Social networks","Theoretical Computer Science","Article","https:\/\/www.doi.org\/10.1016\/j.tcs.2019.07.007","2-s2.0-85069575978"],["2020-03-02","Gennaro Cordasco","Whom to befriend to influence people","Alice wants to join a new social network, and influence its members to adopt a new product or idea. Each person v in the network has a certain threshold t(v) for activation, i.e. adoption of the product or idea. If v has at least t(v) activated neighbors, then v will also become activated. If Alice wants to activate the entire social network, whom should she befriend? More generally, we study the problem of finding the minimum number of links that a set of external influencers should form to people in the network, in order to activate the entire social network. This Minimum Links Problem has applications in viral marketing and the study of epidemics. Its solution can be quite different from the related and widely studied Target Set Selection problem. We prove that the Minimum Links problem cannot be approximated to within a ratio of O(2log1\u2212\u03f5\u2061n), for any fixed \u03f5>0, unless NP\u2286DTIME(npolylog(n)), where n is the number of nodes in the network. On the positive side, we give linear time algorithms to solve the problem for trees, cycles, and cliques, for any given set of external influencers, and give precise bounds on the number of links needed. For general graphs, we design a polynomial time algorithm to compute size-efficient link sets that can activate the entire graph.","Graphs | Greedy algorithms | Influence maximization | NP-complete | Social networks","Theoretical Computer Science","Article","https:\/\/www.doi.org\/10.1016\/j.tcs.2018.05.030","2-s2.0-85048341124"],["2020-02-11","Delfina Malandrino","Hybrid and lightweight detection of third party tracking: Design, implementation, and evaluation","A common practice for websites is to rely on services provided by third party sites to track users and provide personalized experiences. Unfortunately, this practice has strong implications for both users and performance. From one hand, the privacy of individuals is at a risk given the use of valuable information used for the reconstruction of personal profiles. From the other hand, many existing countermeasures to protect privacy, having been implemented into Web browsers, exhibit performance issues, mainly due to the use of huge (and difficult to maintain up to date) lists of resources that have to be filtered out, given their privacy intrusiveness. To overcome these limitations, we propose the use of a hybrid mechanism exploiting blacklisting and machine learning for the automatic identification of privacy intrusive services requested while browsing Web pages. The idea is to use the blacklisting technique (widely used by the majority of privacy tools), in combination with a machine learning model which distinguishes between malicious and functional resources, and hence updates the blacklist, accordingly. We found out that machine learning models are able to classify JavaScript programs and HTTP requests with accuracy up to 91% and 97%, respectively. We provided a prototype implementation of this hybrid mechanism, named GuardOne, and we performed an exhaustive evaluation study to assess its effectiveness and performance. Results showed that GuardOne is able to filter out malicious resources from users\u2019 requests without performance degradation when compared with traditional systems that leverage on the use of static lists for filtering. Moreover, results about effectiveness show that our mechanism, even with some small improvements, is able to efficiently filter out malicious requests and reduce in a substantial way personal information leakage.","Experimental study | Information leakage | Machine learning techniques | Privacy","Computer Networks","Article","https:\/\/www.doi.org\/10.1016\/j.comnet.2019.106993","2-s2.0-85074918339"],["2020-01-02","Vittorio Scarano","Detecting Data Accuracy Issues in Textual Geographical Data by a Clustering-based Approach","Data are published to encourage data exploitation. However, data quality issues threaten data consumption and require data consumers investing time and effort in data cleansing. By focusing on textual geographical data, we aim to detect inaccurate values, such as typos, truncated values, and propose corrections by a clustering-based approach. Our method is mainly based on a dictionary of correct values, the Agglomerative clustering to group data in clusters, and Levenshtein and Fuzzy string searching for computing word similarity. We test our approach on real open datasets published by the Campania region, heterogeneous in the topic, size, and type of errors by showing the positive results of using Levenshtein and Fuzzy Matching and exploiting clustering methods in detecting and correcting quality issues in textual geographical data. The achieved results are useful for data producers and consumers, both for the academy and the industry, in any application domain.","Clustering | Data cleaning | Data quality | Quality improvement","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3430984.3431031","2-s2.0-85098860524"],["2020-01-01","Biagio Cosenza","SYCL-bench: A versatile cross-platform benchmark suite for heterogeneous computing","The SYCL standard promises to enable high productivity in heterogeneous programming of a broad range of parallel devices, including multicore CPUs, GPUs, and FPGAs. Its modern and expressive C++ API design, as well as flexible task graph execution model give rise to ample optimization opportunities at run-time, such as the overlapping of data transfers and kernel execution. However, it is not clear which of the existing SYCL implementations perform such scheduling optimizations, and to what extent. Furthermore, SYCL\u2019s high level of abstraction may raise concerns about sacrificing performance for ease of use. Benchmarks are required to accurately assess the performance behavior of high-level programming models such as SYCL. To this end, we present SYCL-Bench, a versatile benchmark suite for device characterization and runtime benchmarking, written in SYCL. We experimentally demonstrate the effectiveness of SYCL-Bench by performing device characterization of the NVIDIA TITAN X GPU, and by evaluating the efficiency of the hipSYCL and ComputeCpp SYCL implementations.","Cross platform | Heterogeneous computing | SYCL benchmarks | SYCL runtime","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-57675-2_39","2-s2.0-85090093281"],["2020-01-01","Gennaro Cordasco","A design-methodology for epidemic dynamics via time-varying hypergraphs","In epidemiology science, the importance to explore innovative modeling tools for acutely analyzing epidemic diffusion is turning into a big challenge considering the myriad of real-world aspects to capture. Typically, equation-based models, such as SIS and SIR, are used to study the propagation of diseases over a population. Improved approaches also include human-mobility patterns as network information to describe contacts among individuals. However, there still is the need to incorporate in these models information about different types of contagion, geographical information, humans habits, and environmental properties. In this paper, we propose a novel approach that takes into account: 1. direct and indirect epidemic contagion pathways to explore the dynamics of the epidemic, 2. the times of possible contagions, and 3. human-mobility patterns. We combine these three features exploiting time-varying hypergraphs, and we embed this model into a design-methodology for agent-based models (ABMs), able to improve the correctness in the epidemic estimations of classical contact-network approaches. We further describe a diffusion algorithm suitable for our design-methodology and adaptable to the peculiarities of any disease spreading policies and\/or models. Finally, we tested our methodology by developing an ABM, realizing the SIS epidemic compartmental model, for simulating an epidemic propagation over a population of individuals. We experimented the model using real user-mobility data from the location-based social network Foursquare, and we demonstrated the high-impact of temporal direct and indirect contagion pathways.","Agent-based Model | Direct and indirect infection | Epidemiology | Location-based Social Network | Time-Varying Hypergraph","Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-85096648502"],["2020-01-01","Vittorio Scarano","Detecting and generalizing quasi-identifiers by affecting singletons","In order to adhere to Open Government doctrine, Public Administrations (PAs) are requested to publish Open Data while preventing the disclosure of personal information of their citizens. Therefore, it is crucial for PAs to employ methods that ensure Privacy-preserving data publishing by distributing useful data while protecting individual privacy. In this paper, we study this problem by providing a two phases approach. First, we detect privacy issues by recognizing the minimum number of attributes that expose the highest number of unique values (that will be referred to as singletons) as Quasi-Identifier. We test our approach on real datasets openly published by the Italian government, and we discover that the quasi-identifier (year_of_birth, sex, ZIP_ofresidence) discloses up to 2% unique values in already anonymized datasets. Once accomplished the detection phase, we propose an anonymization approach to limit the privacy leakage. We investigate which combination of attributes must be generalized to achieve the minimum number of singletons while minimising the amount of modified and removed rows. We tested our approach on real datasets as in the previous phase, and we noticed that by generalizing only rows corresponding to the singletons, we achieve nearly no singletons while affecting only the 2% of rows.","Anonymization | Generalization | Privacy | Quasi-Identifies","CEUR Workshop Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-85099251961"],["2020-01-01","Gennaro Cordasco","Preface",null,null,"CEUR Workshop Proceedings","Editorial","https:\/\/www.doi.org\/None","2-s2.0-85106823084"],["2020-01-01","Gennaro Cordasco","Iterated Type Partitions","This paper introduces a novel parameter, called iterated type partition, that can be computed in polynomial time and nicely places between modular-width and neighborhood diversity. We prove that the Equitable Coloring problem is W[1]-hard when parametrized by the iterated type partition. This result extends to modular-width, answering an open question on the complexity of Equitable Coloring when parametrized by modular-width. On the contrary, we show that the Equitable Coloring problem is FPT when parameterized by neighborhood diversity. Furthermore, we present a scheme for devising FPT algorithms parameterized by iterated type partition, which enables us to find optimal solutions for several graph problems. While the considered problems are already known to be FPT with respect to modular-width, the novel algorithms are both simpler and more efficient. As an example, in this paper, we give an algorithm for the Dominating Set problem that outputs an optimal set in time O(2t + poly(n)), where n and t are the size and the iterated type partition of the input graph, respectively.","Fixed-parameter tractable algorithms | Modular-width | Neighborhood diversity | Parameterized complexity | W[1]-hardness","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-48966-3_15","2-s2.0-85086256612"],["2020-01-01","Vittorio Scarano","FLY: A Domain-Specific Language for Scientific Computing on FaaS","Cloud Computing is widely recognized as distributed computing paradigm for the next generation of dynamically scalable applications. Recently a novel service model, called Function-as-a-Service (FaaS), has been proposed, that enables users to exploit the computational power of cloud infrastructures, without the need to configure and manage complex computations systems. FaaS paradigm represents an opportunity to easily develop and execute extreme-scale applications as it allows fine-grain decomposition of the application with a much more efficient scheduling on cloud provider infrastructure. We introduce fly, a domain-specific language for designing, deploying and executing scientific computing applications by exploiting the FaaS service model on different cloud infrastructures. In this paper, we present the design and the language definition of fly on several computing (local and FaaS) back-ends: Symmetric multiprocessing (SMP), Amazon AWS Lambda, Microsoft Azure Functions, Google Cloud Functions, and IBM Bluemix\/Apache OpenWhisk. We also present the first fly source-to-source compiler, publicly available on GitHub, which supports SMP and AWS back-ends.","Distributed computing | Domain-Specific Languages | Functions as a Service (FaaS) | Parallel computing | Scientific computing | Serverless computing","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-48340-1_41","2-s2.0-85086221836"],["2020-01-01","Gennaro Cordasco","Information diffusion in complex networks: a model based on hypergraphs and its analysis","This work introduces the problem of social influence diffusion in complex networks, where vertices are linked not only through simple pairwise relationships to other nodes but with groups of nodes of arbitrary size. A challenging problem that arises in this domain is to determine a small subset of nodes S (a target-set) able to spread their influence in the whole network. This problem has been formalized and studied in different ways, and many viable solutions have been found for graphs. These have been applied to study several phenomena in research fields such as social, economic, biological, and physical sciences. In this contribution, we investigated the social influence problem on hypergraphs. As hypergraphs are mathematical structures generalization of graphs, they can naturally model the many-to-many relationships characterizing a complex network. Given a network represented by a hypergraph H=(V, E), we consider a dynamic influence diffusion process on H, evolving as follows. At the beginning of the process, the nodes in a given set S (Formula Presented) V are influenced. Then, at each iteration, the influenced hyperedges set is augmented by all hyperedges having a sufficiently large number of influenced nodes. Consequently, the set of influenced nodes is extended by all the nodes contained in a sufficiently large number of already influenced hyperedges. The process terminates when no new nodes can be influenced. The so defined problem is an inherent chicken-and-egg question as nodes are influenced by groups of other nodes (or hyperedges), while hyperedges (or group of nodes) are influenced by the nodes they contain. In this paper, we provide a formal definition of the influence diffusion problem on hypergraphs. We propose a set of greedy-based heuristic strategies for finding the minimum influence target set, and we present an in-depth analysis of their performance on several classes of random hypergraphs. Furthermore, we describe an experiment on a real use-case, based on the character co-occurrences network of the Game-of-Thrones TV Series.","Influence diffusion | Random hypergraphs | Social network | Target set selection","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-48478-1_3","2-s2.0-85086232060"],["2020-01-01","Gennaro Cordasco","Analyzing, exploring, and visualizing complex networks via hypergraphs using simplehypergraphs.Jl","Real-world complex networks are usually being modeled as graphs. The concept of graphs assumes that the relations within the network are binary (for instance, between pairs of nodes); however, this is not always true for many real-life scenarios, such as peer-to-peer communication schemes, paper co-authorship, or social network interactions. For such scenarios, it is often the case that the underlying network is better and more naturally modeled by hypergraphs. A hypergraph is a generalization of a graph in which a single (hyper)edge can connect any number of vertices. Hypergraphs allow modelers to have a complete representation of multi-relational (many-to-many) networks; hence, they are extremely suitable for analyzing and discovering more subtle dependencies in such data structures. Working with hypergraphs requires new software libraries that make it possible to perform operations on them, from basic algorithms (such as searching or traversing the network) to computing significant hypergraph measures, to including more challenging algorithms (such as community detection). In this paper, we present a new software library, SimpleHypergraphs.jl, written in the Julia language and designed for high-performance computing on hypergraphs and propose two new algorithms for analyzing their properties: s-betweenness and modified label propagation. We also present various approaches for hypergraph visualization integrated into our tool. In order to demonstrate how to exploit the library in practice, we discuss two case studies based on the 2019 Yelp Challenge dataset and the collaboration network built upon the Game of Thrones TV series. The results are promising and they confirm the ability of hypergraphs to provide more insight than standard graph-based approaches.","Analyzing hypergraphs | Exploring hypergraphs | Hypergraphs | Julia language | Software library | Visualizing hypergraphs","Internet Mathematics","Article","https:\/\/www.doi.org\/10.24166\/im.01.2020","2-s2.0-85085085510"],["2020-01-01","Gennaro Cordasco","Advanced assistive technologies for elderly people: A psychological perspective on seniors\u2019 needs and preferences (part A)","This paper provides an overview of the literature concerning Seniors\u2019 psychological perspective in exploiting assistive robots and the embodied conversational agents. The main theoretical models devoted to assess user\u2019s technology acceptance are briefly reviewed along with a description of the main factors empirically found to be positively\/negatively associated with Seniors\u2019 acceptance level. Special attention is reserved to barriers generated by Seniors\u2019 representations of social assistive technologies, such as, a stigma or threat to their autonomy, infantilization, privacy interferences, fear of dehumanization and isolation.","Acceptance | Assistive technology | Older user | Preferences | Robot | Virtual agent","Acta Polytechnica Hungarica","Article","https:\/\/www.doi.org\/10.12700\/APH.17.2.2020.2.10","2-s2.0-85079883685"],["2020-01-01","Gennaro Cordasco","Seniors\u2019 Appreciation of Humanoid Robots","This paper is positioned inside a research project investigating elders\u2019 preferences and acceptance toward robots, in order to collect insights for the design and implementation of socially assistive robots. To this aim, short video clips of five manufactured robots (Roomba, Nao, Pepper, Ishiguro, and Erica) were shown to 100 seniors (50 Female) aged 65+ years (average age: 71.34\u00a0years, DS: \u00b15.60). After watching each robot video clip, seniors were administered a short questionnaire assessing their willingness to interact with robots, feelings robots aroused, and duties they would entrust to robots. The questionnaire\u2019s scores were assessed through repeated measures ANOVA in order to ascertain statistically significant differences among seniors\u2019 preferences. A clear uncanny valley effect was identified. The robot Pepper received significantly higher scores than Roomba, Nao, Ishiguro, and Erica on communication skills, ability to remind friendly and pleasant memories, comprehension, and ability to provide emotional support. In addition, Pepper was considered the most suitable, among the five proposed robots, in performing welfare duties for elders, children and disabled, protection and security, and front desk occupations.","Assistive technologies | Senior\u2019s preferences | Uncanny valley effects | User\u2019s acceptance | User\u2019s requirements and expectations","Smart Innovation, Systems and Technologies","Book Chapter","https:\/\/www.doi.org\/10.1007\/978-981-13-8950-4_30","2-s2.0-85073160666"],["2020-01-01","Vittorio Scarano","QueDI: From Knowledge Graph Querying to Data Visualization","While Open Data (OD) publishers are spur in providing data as Linked Open Data (LOD) to boost innovation and knowledge creation, the complexity of RDF querying languages, such as SPARQL, threatens their exploitation. We aim to help lay users (by focusing on experts in table manipulation, such as OD experts) in querying and exploiting LOD by taking advantage of our target users\u2019 expertise in table manipulation and chart creation. We propose QueDI (Query Data of Interest), a question-answering and visualization tool that implements a scaffold transitional approach to 1)\u00a0query LOD without being aware of SPARQL and representing results by data tables; 2) once reached our target user comfort zone, users can manipulate and 3) visually represent data by exportable and dynamic visualizations. The main novelty of our approach is the split of the querying phase in SPARQL query building and data table manipulation. In this article, we present the QueDI operating mechanism, its interface supported by a guided use-case over DBpedia, and the evaluation of its accuracy and usability level.","Data visualization | Faceted search | Knowledge graph | Natural language queries | Query builder | SPARQL &amp; SQL queries","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-59833-4_5","2-s2.0-85096578577"],["2020-01-01","Delfina Malandrino","On analyzing third-party tracking via machine learning","Nowadays, websites rely on services provided by third party sites to track users and offer personalized experiences. However, this practice threatens the privacy of individuals through the use of valuable information to create a digital personal profile. The existing client-side countermeasures to protect privacy, exhibit performance issues, mainly due to the use of blacklisting mechanisms (list of resources to be filtered out). In this paper, we study the use of machine learning methods to classify the thirdy-party privacy intrusive resources (trackers). To this end, we first downloaded (browsing Alexa's Top 10 websites for each category like sports, shopping etc.) a dataset of 1000 web resources split into functional and tracking, and then we identified suitable metrics to distinguish between the two classes. In order to evaluate the effectiveness of the proposed metrics we have compared the performances of several machine learning models based on supervised learning among the most used in literature. As a result, we obtained that the Random Forest can classify functional and tracking resources with an accuracy of 91%.","Machine learning | Privacy | Third party tracking","ICISSP 2020 - Proceedings of the 6th International Conference on Information Systems Security and Privacy","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-85083031537"],["2019-12-01","Delfina Malandrino","Learning the harmonic analysis: is visualization an effective approach?","Understanding the structure of music compositions requires an ability built over time, through the study of the music theory and the application of countless hours of practice. In particular for beginner learners, it can be a time-consuming and a tedious task due to the steep learning curve, especially for classical music. In this work we focus on a specific type of classical music composition, that is music in chorale style. Composing such type of music requires the study of rules that are related to many structural aspects of music, such as melodic and mainly harmonic aspects. To overcome these difficulties, interdisciplinary techniques could be exploited to understand whether extra (visual) information, provided through a specific software tool, could be useful to improve learning in a quick and effective way. We introduce therefore VisualHarmony, a tool that allows users to perform the harmonic analysis of music compositions by exploiting visual clues superimposed on the music scores. Since the harmonic analysis requires to identify similar tonalities and relevant degrees, the visualization approach proposed uses closest colors to represent similar tonalities and degrees. To assess the effectiveness of our idea, we performed an evaluation study involving 60 participants among experts (with a conservatory degree) and music students from conservatory classes. We derived interesting results about the overall learning capabilities (when using visualization in supporting learning) and music information retention when using VisualHarmony in a first phase to study rules, and then move on to the classic way of performing harmonization. This result allowed us to further demonstrate the effectiveness of visualization to learn classic music rules. Finally, we also obtained positive feedback about the system usability and the satisfaction of the users with regard to the easiness and the usefulness of the tested tool.","Evaluation | Harmonic analysis visualization | Learning | Music visualization | Tool","Multimedia Tools and Applications","Article","https:\/\/www.doi.org\/10.1007\/s11042-019-07879-5","2-s2.0-85067799382"],["2019-11-01","Delfina Malandrino","A social platform designed for music: Learning and making compositions through collaboration","In music, the score has always been the main instrument used for the transcription, performance, and composition. There exist several systems for transcribing and composing music scores. Although there are a number of evolved systems for composing music scores, they generally lack of (1) collaborative mechanisms, to allow composers to share their contributions and look for other author's compositions, and (2) communication mechanisms, to allow composers to become an active part of the composition process of other composers, by messaging and sharing contents. Generally, musicians take advantage of the most social media systems to implement these features, such as Facebook. Twitter. Instagrarm, and Linkedin. In this work, we introduce SoMusic, a Social platform designed for collaboration and learning. In addition to the main features provided by the most important social networks, SoMusic allows musicians to collaborate, simultaneously create a musical composition (in a concurrent manner), and to find other composers with a similar composition style. Social collaboration is the key aspect for increasing the musical quality productivity, where musicians participate in the discussions, learn in the web classrooms, cocreate music compositions, and share musical ideas. Furthermore, SoMusic proposes itself as an educational support tool allowing teachers to create online classes, to monitor the performance of students, and to interact with them in real-time. We involved 20 participants to analyze SoMusic effectiveness, usability, and the overall user satisfaction. We split the people involved in the evaluation study in two classes: one class with a traditional teaching approach and the other one using SoMusic. On average, participants that tested SoMusic produced music with fewer errors.",null,"2019 6th International Conference on Systems and Informatics, ICSAI 2019","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICSAI48974.2019.9010436","2-s2.0-85081974983"],["2019-10-01","Biagio Cosenza","Portable cost modeling for auto-vectorizers","Compiler optimization passes employ cost models to determine if a code transformation will yield performance improvements. When this assessment is inaccurate, compilers apply transformations that are not beneficial, or refrain from applying ones that would have improved the code. We analyze the accuracy of the cost models used in LLVM's and GCC's vectorization passes for two different instruction set architectures. In general, speedup is over-estimated, resulting in mispredictions and a weak to medium correlation between predicted and actual performance gain. We therefore propose a novel cost model that is based on a code's intermediate representation with refined memory access pattern features. Using linear regression techniques, this platform independent model is fitted to an AVX2 and a NEON hardware. Results show that the fitted model significantly improves the correlation between predicted and measured speedup (AVX2: +52% for training data, +13% for validation data), as well as the number of mispredictions (NEON: -15 for training data, -12 for validation data) for more than 80 code patterns.","Compiler | Cost model | Performance prediction | Vectorization","Proceedings - IEEE Computer Society's Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems, MASCOTS","Conference Paper","https:\/\/www.doi.org\/10.1109\/MASCOTS.2019.00046","2-s2.0-85077790055"],["2019-10-01","Gennaro Cordasco","Handwriting and Drawing Features for Detecting Personality Traits","This research reports on handwriting\/drawing quantitative features and their links with personality traits. To this aim, handwriting\/drawing tasks have been proposed to 78 subjects (equally balance by gender and aged between 22-35 years), which were first administered the Big Five Personality questionnaire (BFQ). Subjects were clustered as low, typical, and high according to the scores obtained to each 5 personality dimensions (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism). Measures of pressure, ductus, time, space, and inclination, were computed from digital recordings of the proposed handwriting\/drawing tasks through an INTUOS WACOM digitizing tablet. On these data, ANOVA repeated measures were performed with gender and group category (low, typical and high for each of the BFQ dimension) as between and associated computed measures as within factors. Results show significant differences for each of the BFQ dimension among subject group categories and handwriting\/drawing measures connecting quantitatively personality traits to graphology.",null,"10th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2019 - Proceedings","Conference Paper","https:\/\/www.doi.org\/10.1109\/CogInfoCom47531.2019.9089985","2-s2.0-85085580873"],["2019-10-01","Vittorio Scarano","Towards the online computer-aided design of catalytic pockets","The engineering of catalysts with desirable properties can be accelerated by computer-aided design. To achieve this aim, features of molecular catalysts can be condensed into numerical descriptors that can then be used to correlate reactivity and structure. Based on such descriptors, we have introduced topographic steric maps that provide a three-dimensional image of the catalytic pocket\u2014the region of the catalyst where the substrate binds and reacts\u2014enabling it to be visualized and also reshaped by changing various parameters. These topographic steric maps, especially when used in conjunction with density functional theory calculations, enable catalyst structural modifications to be explored quickly, making the online design of new catalysts accessible to the wide chemical community. In this Perspective, we discuss the application of topographic steric maps either to rationalize the behaviour of known catalysts\u2014from synthetic molecular species to metalloenzymes\u2014or to design improved catalysts.",null,"Nature Chemistry","Article","https:\/\/www.doi.org\/10.1038\/s41557-019-0319-5","2-s2.0-85072111046"],["2019-08-05","Biagio Cosenza","Predictable GPUs frequency scaling for energy and performance","Dynamic voltage and frequency scaling (DVFS) is an important solution to balance performance and energy consumption, and hardware vendors provide management libraries that allow the programmer to change both memory and core frequencies. The possibility to manually set these frequencies is a great opportunity for application tuning, which can focus on the best application-dependent setting. However, this task is not straightforward because of the large set of possible configurations and because of the multi-objective nature of the problem, which minimizes energy consumption and maximizes performance. This paper proposes a method to predict the best core and memory frequency configurations on GPUs for an input OpenCL kernel. Our modeling approach, based on machine learning, first predicts speedup and normalized energy over the default frequency configuration. Then, it combines the two models into a multi-objective one that predicts a Pareto-set of frequency configurations. The approach uses static code features, is built on a set of carefully designed micro-benchmarks, and can predict the best frequency settings of a new kernel without executing it. Test results show that our modeling approach is very accurate on predicting extrema points and Pareto set for ten out of twelve test benchmarks, and discover frequency configurations that dominate the default configuration in either energy or performance.","Energy efficiency | Frequency scaling | GPUs | Modeling","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3337821.3337833","2-s2.0-85071140452"],["2019-07-08","Delfina Malandrino","Social support for collaboration and group awareness in life science research teams","Background: Next-generation sequencing (NGS) technologies have revolutionarily reshaped the landscape of '-omics' research areas. They produce a plethora of information requiring specific knowledge in sample preparation, analysis and characterization. Additionally, expertise and competencies are required when using bioinformatics tools and methods for efficient analysis, interpretation, and visualization of data. These skills are rarely covered in a single laboratory. More often the samples are isolated and purified in a first laboratory, sequencing is performed by a private company or a specialized lab, while the produced data are analyzed by a third group of researchers. In this scenario, the support, the communication, and the information sharing among researchers represent the key points to build a common knowledge and to meet the project objectives. Results: We present ElGalaxy, a system designed and developed to support collaboration and information sharing among researchers. Specifically, we integrated collaborative functionalities within an application usually adopted by Life Science researchers. ElGalaxy, therefore, is the result of the integration of Galaxy, i.e., a Workflow Management System, with Elgg, i.e., a Social Network Engine. Conclusions: ElGalaxy enables scientists, that work on the same experiment, to collaborate and share information, to discuss about methods, and to evaluate results of the individual steps, as well as of entire activities, performed during their experiments. ElGalaxy also allows a greater team awareness, especially when experiments are carried out with researchers which belong to different and distributed research centers.","Life science teams collaboration | Social interactions | Working group awareness","Source Code for Biology and Medicine","Article","https:\/\/www.doi.org\/10.1186\/s13029-019-0074-4","2-s2.0-85068822204"],["2019-07-01","Biagio Cosenza","A Performance Analysis of Vector Length Agnostic Code","Vector extensions are a popular mean to exploit data parallelism in applications. Over recent years, the most commonly used extensions have been growing in vector length and amount of vector instructions. However, code portability remains a problem when speaking about a compute continuum. Hence, vector length agnostic (VLA) architectures have been proposed for the future generations of ARM and RISC-V processors. With these architectures, code is vectorized independently of the vector length of the target hardware platform. It is therefore possible to tune software to a generic vector length. To understand the performance impact of VLA code compared to vector length specific code, we analyze the current capabilities of code generation for ARM's SVE architecture. Our experiments show that VLA code reaches about 90% of the performance of vector length specific code, i.e. a 10% overhead is inferred due to global predication of instructions. Furthermore, we show that code performance is not increasing proportionally with increasing vector lengths due to the higher memory demands.","SIMD | SVE | vector length agnostic | vectorization","2019 International Conference on High Performance Computing and Simulation, HPCS 2019","Conference Paper","https:\/\/www.doi.org\/10.1109\/HPCS48598.2019.9188238","2-s2.0-85090395879"],["2019-07-01","Delfina Malandrino","Visual Analytics to Make Sense of Large-Scale Administrative and Normative Data","The paper presents ongoing research aiming to ease the interaction with large amounts of public sector data. The project focuses on the development of a modular online platform for both desktop and mobile devices exploiting Visual Analytics to offer citizens, researchers and policymakers crosscutting reading of heterogeneous information. We experiment new ways to integrate, analyze, and visualize administrative, legal, and economic data as they appear to be a powerful ally not only to increase the transparency of government activities but also to enhance evidence-based policy making and agenda setting.","Administrative Data | Computational Legal Science | Legal Informatics | Visual Analytics","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV.2019.00031","2-s2.0-85072276027"],["2019-07-01","Delfina Malandrino","On the Visualization of Logic: A Diagrammatic Language Based on Spatial, Graphical and Symbolic Notations","Visual languages are studied in many different disciplines including Formal Logic. Several diagram methods have been proposed for the visual representation of the logical relations and in particular for First Order Predicate Logic (FOPL) formulas. Among these, logical symbolism, Euler diagrams, semantic networks, conceptual grids, conceptual spaces and so on. It is shown that these representations are formally equivalent and can be inter-translated algorithmically, but provide different and complementary visualizations such that the use of multiple representations may provide greater insight than any alone. We present a new visual language, V-Logic, which support different visual representation schemes: spatial, graphical and symbolic notations. It specifies rules for mapping FOPL formulas in special semantically equivalent diagrams, named V-diagrams. Logical inference based on the interpretation of a V-diagram is essentially a translation of the diagram into a logical formalism. Such a translation is natural and could be used to teach FOPL. We performed a preliminary study with 10 students. Results provided us with overall positive feedback about the effectiveness of our approach as well as further directions to explore.","Evaluation | First Order Predicate Logic | Learning","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV.2019.00011","2-s2.0-85072274658"],["2019-07-01","Delfina Malandrino","Platform economy and techno-regulation-Experimenting with reputation and nudge","In the cloud-based society, where the vast majority of social, economic and personal interactions is mediated by information communication technology (ICT), technology is no longer simply a subject of regulation but is becoming an integral part of the regulatory process. Techno-regulation, the \"intentional influencing of individuals' behavior by building norms into technological devices,\" is inspiring new ways to support legal safeguards through hardware and software tools, technical solutions allowing the creation of legal relations, hampering breaches of law and even promoting norm compliance. This paper touches on these issues by focusing on Digital Labor Platforms, one of the most relevant phenomena in the gig economy. We present a research project exploring innovative techno-regulatory solutions to protect gig economy workers. The idea is to integrate, in the same strategy, legal principles, regulatory objectives and software solutions. Our attention focuses on two results of our activity-a techno-regulatory model relying on reputational mechanisms to affect the behavior of digital labor market operators and GigAdvisor, a cross-platform experimental application implementing the model.","Digital labour platforms | Nudge | Reputational systems | Techno-regulation","Future Internet","Article","https:\/\/www.doi.org\/10.3390\/fi11070163","2-s2.0-85070109438"],["2019-07-01","Biagio Cosenza","Approximating Memory-bound Applications on Mobile GPUs","Approximate computing techniques are often used to improve the performance of applications that can tolerate some amount of impurity in the calculations or data. In the context of embedded and mobile systems, a broad number of applications have exploited approximation techniques to improve performance and overcome the limited capabilities of the hardware. On such systems, even small performance improvements can be sufficient to meet scheduled requirements such as hard real-time deadlines. We study the approximation of memory-bound applications on mobile GPUs using kernel perforation, an approximation technique that exploits the availability of fast GPU local memory to provide high performance with more accurate results. Using this approximation technique, we approximated six applications and evaluated them on two mobile GPU architectures with very different memory layouts: a Qualcomm Adreno 506 and an ARM Mali T860 MP2. Results show that, even when the local memory is not mapped to dedicated fast memory in hardware, kernel perforation is still capable of 1.25times speedup because of improved memory layout and caching effects. Mobile GPUs with local memory show a speedup of up to 1.38times.","approximate computing | GPU | kernel perforation","2019 International Conference on High Performance Computing and Simulation, HPCS 2019","Conference Paper","https:\/\/www.doi.org\/10.1109\/HPCS48598.2019.9188051","2-s2.0-85092046469"],["2019-06-18","Delfina Malandrino","A non-prescriptive environment to scaffold high quality and privacy-aware production of open data with AI","Data quality is strictly related to fitness for use. Therefore, data providers should improve the intrinsic quality of published data to prevent the diffusion of data sets practically impossible to use. Among all data providers, it is critical that governments and public agencies better assess and improve the quality of the produced data sets as early as possible - ideally during the production phase. Besides the quality aspect, data providers should also bear in mind that if they want to expose personal information, data must be compliant with EU General Data Protection Regulation (GDPR). Thus, this paper introduces a methodology to scaffold the agile production of Open Data (OD) that takes into account both quality and privacy concerns. To guarantee efficiency, our methodology is based on a pattern matching approach enhanced by artificial intelligence (AI) - in particular by using decision trees. The presented approach has been tested on real data sets already published as OD. In the evaluation, the advantages offered by the support of AI are evident. The described methodology is integrated into a social platform which is non-prescriptive as it supports (and does not force) users in producing better quality\/privacy OD.","Open Data | Open Data Authoring | Open Government","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3325112.3325230","2-s2.0-85068603882"],["2019-06-18","Vittorio Scarano","Re-using open data by automatically building immersive virtual reality worlds as personal museums","While Open Data represent an important tool to ensuring transparency, they can also be the ground for the collaboration between Public Administrations (PAs) and citizens around shared objectives, such as Cultural Heritage preservation. In this paper, we present the work of our project Hetor, that is now entering year 2, that, after several fruitful co-creation activities, fostered by the PA but designed and realized by citizens (associations, schools, etc.), is now entering in a phase where the innovation in re-use is needed, by further engaging citizens through the appeal of a Virtual Personal Museum, i.e., a 3d virtual world where the data collected is presented as a museum and can be visited. The main contribution of this paper is the presentation of a tool VR-ReUse that allows to automatically create 3d Virtual Personal Museums, after a simple configuration, starting from the open datasets available. This is the next step of our engaging strategy, that will present the Virtual Personal Museums into the Town public Library in the month of April. We present the motivations to build such an innovative tool, the architecture, the examples, and their future development.","Open Data | Open Data Re-use | Open Government | Virtual Personal Museums | Virtual Reality","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3325112.3325258","2-s2.0-85068624200"],["2019-06-05","Gennaro Cordasco","The Empathic project: Mid-term Achievements","The goal of active aging is to promote changes in the elderly community so as to maintain an active, independent and socially-engaged lifestyle. Technological advancements currently provide the necessary tools to foster and monitor such processes. This paper reports on mid-term achievements of the European H2020 EMPATHIC project, which aims to research, innovate, explore and validate new interaction paradigms and platforms for future generations of personalized virtual coaches to assist the elderly and their carers to reach the active aging goal, in the vicinity of their home. The project focuses on evidence-based, user-validated research and integration of intelligent technology, and context sensing methods through automatic voice, eye and facial analysis, integrated with visual and spoken dialogue system capabilities. In this paper, we describe the current status of the system, with a special emphasis on its components and their integration, the creation of a Wizard of Oz platform, and findings gained from user interaction studies conducted throughout the first 18 months of the project.","Assisted Living | Coaching | Emotional Artificial Agents | Spoken Dialogue Systems","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3316782.3322764","2-s2.0-85069198797"],["2019-06-01","Gennaro Cordasco","Elders prefer female robots with a high degree of human likeness","Elders' acceptance of robots is still a novel field and a clear research methodology to assess users' preferences has not yet been developed. The exploitation of robots, as assistive technologies, requires the properly identification of users' needs and expectations and the matching of robot's role, appearance, and behavior to these needs. Robot's degree of resemblance to humans may play a fundamental role on their acceptance into domestic spheres. The present paper investigates elders' preferences towards female robots showing different levels of human likeness (two androids and a humanoid robot are involved in the study) considering their pragmatic, hedonic and attractive dimensions, as well as occupations elders entrusted to robots. A total of 51 elders (29 females) aged 65+ years were recruited. Participants were asked to watch video clips showing three speaking female manufactured robots (Erica, Sophia, and Pepper) and after each video clip, the Robot Appearance Questionnaire (RAQ) was administered. The results highlight that the degree of robot's human likeness affects elders' preferences in favor of android robots. Elders expressed a clear preference for female android rather than humanoid robots, in contrast with the current trend observed in literature. In addition, female robots were considered more suitable in performing housework rather than protection\/security, healthcare, and front office occupations.","Assistive technologies | Human-robot interaction | Users' acceptance","2019 IEEE 23rd International Symposium on Consumer Technologies, ISCT 2019","Conference Paper","https:\/\/www.doi.org\/10.1109\/ISCE.2019.8900983","2-s2.0-85075632168"],["2019-05-13","Delfina Malandrino","Characterizing the behavioral evolution of twitter users and the truth behind the 90-9-1 rule","Online Social Networks (OSNs) represent a fertile field to collect real user data and to explore OSNs user behavior. Recently, two topics are drawing the attention of researchers: the evolution of online social roles and the question of participation inequality. In this work, we bring these two fields together to study and characterize the behavioral evolution of OSNs users according to the quantity and the typology of their social interactions. We found that online participation on the microblogging platform can be categorized into four different activity levels. Furthermore, we empirically verified that the 90-9-1 rule of thumb about participation inequality is not an accurate representation of reality. Findings from our analysis reveal that lurkers are less than expected: they are not 9 out of 10 as suggested by Nielsen, but 3 out of 4. This represents a significant result that can give new insights on how users relate with social media and how their use is evolving towards a more active interaction with the new generation of consumers.","Data-Driven Analysis | Lurker | Online Social Networks | Participation Inequality | Role Discovery | User behavior","The Web Conference 2019 - Companion of the World Wide Web Conference, WWW 2019","Conference Paper","https:\/\/www.doi.org\/10.1145\/3308560.3316705","2-s2.0-85066906028"],["2019-05-01","Delfina Malandrino","Linked data queriesby a trialogical learning approach","Querying Linked (Open) Data (LOD) by directly using SPARQL could be a painful task for most potential users of semantic data. Several approaches have been proposed to help users in query formulation. They succeed in hiding the underlying complexity but exploit only the monological - individual - approach. Information seeking and retrieval is not merely an individual effort, but it inherently involves various collaborative activities. For this reason, our proposal is to facilitate the exploitation of LODs by wrapping the querying and visualization tool in a social platform environment. In this way, we enable the dialogical approach. Moreover, since the users can collaboratively create datasets and visualizations, and reuse them also out of the social platform, we reach the trialogical learning. In this paper, we present our design approach, our tool, and related tests.","Linked (Open) Data | NLI | Social Platform | SPARQL query builder | Trialogical Learning","Proceedings of the 2019 IEEE 23rd International Conference on Computer Supported Cooperative Work in Design, CSCWD 2019","Conference Paper","https:\/\/www.doi.org\/10.1109\/CSCWD.2019.8791867","2-s2.0-85071455841"],["2019-04-11","Gennaro Cordasco","Active influence spreading in social networks","Identifying the most influential spreaders is an important issue for the study of the dynamics of information diffusion in complex networks. In this paper we analyze the following spreading model. Initially, a few nodes know a piece of information and are active spreaders of it. At subsequent rounds, spreaders communicate the information to their neighbors. Upon receiving the information, a node becomes aware of it but does not necessarily become a spreader; it starts spreading only if it gets the information from a sufficiently large number of its neighbors. A set of initial spreaders that guarantees that all the nodes become aware of the information is called a perfect seed set. We study the problem of choosing a perfect seed set of minimum size. We provide hardness results and show that the problem becomes tractable on trees. In case of general graphs, we provide an efficient algorithm and validate its effectiveness (in terms of the solution size) on real-life networks. We also study perfect seed sets in dense graphs and derive a bound on the size of a dominating set in Ore graphs.","Algorithms | Complexity | Social networks | Spread of influence","Theoretical Computer Science","Article","https:\/\/www.doi.org\/10.1016\/j.tcs.2018.02.024","2-s2.0-85042919112"],["2019-04-01","Carmine Spagnuolo","Large-scale Optimized Searching for Cruise Itinerary Scheduling on the Cloud","We consider the Cruise Itinerary Schedule Design (CISD) problem, which consists in identifying a cruise itinerary in order to optimize the payoff of a cruising company. To deal with this problem we present an optimization strategy based on a parameters optimization process. We exploits the Simulation exploration and Optimization Framework for the cloud (SOF) for building our computing intensive process on a cloud computing infrastructure. The optimization process is based on a heuristic tabu-search strategy, which computes and evaluates the cruise schedule and a genetic algorithm that optimizes the parameters of the heuristic search. We have evaluated the proposed solution in terms of quality as well as the scalability\/cost efficiency on the cloud infrastructure Amazon Web Services.","Cloud Computing | Cruise Itinerary Schedule Design | Distributed Computing | Optimization | Parameters Space Exploration | Transportation Logistics.","2019 International Conference on Optimization and Applications, ICOA 2019","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICOA.2019.8727704","2-s2.0-85068068597"],["2019-02-11","Gennaro Cordasco","Emotional faces of children and adults: What changes in their perception","This work investigates disparities between children and middle aged adults in their ability to decode the six primary facial expressions of emotions when portrayed by contemporary children and adult faces. The analyses were conducted on a sample of 40 (20 females) very closely aged children (mean age=7.4; SD=\u00b10.2), and 40 middle aged (mean age=54.3; SD=\u00b12.9) adults (20 females). Four different experimental conditions were assessed: a) 20 children and 20 middle aged adults assessing child faces; b) 20 children and 20 middle aged adults assessing adult faces; c) 20 children assessing adult faces and 20 children assessing child faces; d) 20 middle aged adults assessing adult faces and 20 middle aged adults assessing child faces. The analyses do not show significant differences between children and adults for conditions a), and b). Children performances on condition c) did not support the peers-prejudice theory, since no significant differences were found among children on their ability to decode either facial expressions of adults or children. Middle aged adults were significantly more accurate in decoding adult rather than children faces. No significant gender differences were found in the four conditions, even though significant interactions were found between emotional categories and gender of stimuli. In particular, the gender of stimuli had a significant effect in condition a) where emotional faces portrayed by male children are more accurately decoded than those portrayed by female children. Several significant interactions were observed between emotional categories, participants' age, and gender of stimuli. Details are discussed in the text.","children and adult emotional faces | emotional decoding accuracy | emotional gender differences | middle aged adults | primary emotions","9th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2018 - Proceedings","Conference Paper","https:\/\/www.doi.org\/10.1109\/CogInfoCom.2018.8639963","2-s2.0-85063083285"],["2019-01-22","Delfina Malandrino","Characterizing Twitter Users: What do Samantha Cristoforetti, Barack Obama and Britney Spears Have in Common?","The exponential growth in the use of digital devices and the ubiquitous online access produce a huge amount of structured and unstructured data that can be mined and analyzed to gather insights into several domains. In particular, since the advent of Web 2.0, Online Social Networks (OSNs) represent a rich opportunity for researchers to collect real user data and to explore OSNs users behavior. This study represents a first attempt to characterize and classify OSNs users according to their level of activity through the use of user profile attributes. We analyzed four case studies from the Twitter platform for a final total of around 721 thousand users, divided into four sub-datasets and examined over a period of at least six months in 2017. Following a data-driven methodology, we found that static, profile-based information - based on the entire lifetime of the users - can help to recognize users influence in Twitter online communities. On the other hand, these profile attributes are not enough to characterize user activity on the microblogging platform.","Data-driven analysis | Online Social Networks | Role Discovery | User Behavior","Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018","Conference Paper","https:\/\/www.doi.org\/10.1109\/BigData.2018.8622045","2-s2.0-85062607585"],["2019-01-03","Carmine Spagnuolo","Scalability in the MASON Multi-Agent Simulation System","This paper describes Distributed MASON, a distributed version of the MASON agent-based simulation tool. Distributed MASON is architected to take advantage of well known principles from Parallel and Discrete Event Simulation, such as the use of Logical Processes (LP) as a method for obtaining scalable and high performing simulation systems. We first explain data management and sharing between LPs and describe our approach to load balancing. We then present both a local greedy approach and a global hierarchical approach. Finally, we present the results of our implementation of Distributed MASON on an instance in the Amazon Cloud, using several standard multi-agent models. The results indicate that our design is highly scalable and achieves our expected levels of speed-up.",null,"Proceedings of the 2018 IEEE\/ACM 22nd International Symposium on Distributed Simulation and Real Time Applications, DS-RT 2018","Conference Paper","https:\/\/www.doi.org\/10.1109\/DISTRA.2018.8601006","2-s2.0-85061637766"],["2019-01-02","Delfina Malandrino","Virtual Reality Interfaces for Interacting with Three-Dimensional Graphs","Today, virtual reality (VR) systems are widely available through low-cost devices such as Oculus Rift and HTC Vive. Although VR technology has so far been centered on entertainment, there is a growing interest from developers, technology companies, and consumers to evaluate it in a wider variety of contexts. This paper explores the effectiveness of visualizing and interacting with three-dimensional graphs in VR in comparison with the traditional approach. In particular, we present an empirical evaluation study for exploring and interacting with three-dimensional graphs using Oculus Rift and Leap Motion. We designed several interfaces exploiting the natural user interface in a VR environment and compared them with traditional mouse\u2013keyboard and joypad configurations. Our evaluation suggests that, although these upcoming VR technologies are more challenging than more traditional ones, they facilitate user involvement during graph interaction and visualization tasks, given the enjoyable experience elicited when combining gesture-based interfaces and VR.",null,"International Journal of Human-Computer Interaction","Article","https:\/\/www.doi.org\/10.1080\/10447318.2018.1429061","2-s2.0-85041169833"],["2019-01-01","Delfina Malandrino","Orchestrated Co-creation of High-Quality Open Data Within Large Groups","According to Open Government Data, governments should co-operate with citizens in order to co-create Open Data (OD). When large groups are involved, there is the need to orchestrate the work by clearly defining and distributing roles. Our Regional Administration - the Council of the Campania Region in Italy - claimed a motivating use case which inspired the proposed roles involved in the OD production process. We consider validator, creator, and filler as roles. To each role tasks and responsibilities are attached. Roles and related activities are integrated into SPOD (a Social Platform for Open Data) to guide users in producing high-quality OD by proactive quality assurance techniques.","Co-creation | Large groups | Open Data | Open Government | Orchestration | Quality assurance | Roles","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-27325-5_13","2-s2.0-85077109715"],["2019-01-01","Gennaro Cordasco","SimpleHypergraphs.jl\u2014novel software framework for modelling and analysis of hypergraphs","Hypergraphs are natural generalization of graphs in which a single (hyper)edge can connect any number of vertices. As a result, hypergraphs are suitable and useful to model many important networks and processes. Typical applications are related to social data analysis and include situations such as exchanging emails with several recipients, reviewing products on social platforms, or analyzing security vulnerabilities of information networks. In many situations, using hypergraphs instead of classical graphs allows us to better capture and analyze dependencies within the network. In this paper, we propose a new library, named SimpleHypergraphs.jl, designed for efficient hypegraph analysis. The library exploits the Julia language flexibility and direct support for distributed computing in order to bring a new quality for simulating and analyzing processes represented as hypergraphs. In order to show how the library can be used we study two case studies based on the Yelp dataset. Results are promising and confirm the ability of hypergraphs to provide more insight than standard graph-based approaches.","Hypergraphs | Julia programming language | Modelling hypergraphs | Software library","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-25070-6_9","2-s2.0-85069880556"],["2019-01-01","Gennaro Cordasco","Dual domination","Inspired by the feedback scenario, which characterizes online social networks, we introduce a novel domination problem, which we call Dual Domination (DD). We assume that the nodes in the input network are partitioned into two categories: Positive nodes (V+) and negative nodes (V-). We are looking for a set D \u2286 V+ that dominates the largest number of positive nodes while avoiding as many negative nodes as possible. In particular, we study the Maximum Bounded Dual Domination (MBDD) problem, where given a bound k, the problem is to find a set D \u2286 V+, which maximizes the number of nodes dominated in V+ dominating at most k nodes in V- We show that the MBDD problem is hard to approximate to a factor better than (1 \u2212 1\/e). We give a polynomial time approximation algorithm with approximation guaranteed (1 \u2212 e\u22121\/\u0394), where \u0394 represents the maximum number of neighbors in V+ of any node in V- Furthermore, we give an O(|V|k2) time algorithm to solve the problem on trees.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-25005-8_14","2-s2.0-85069750374"],["2019-01-01","Gennaro Cordasco","The MASON Simulation Toolkit: Past, Present, and Future","MASON is a widely-used open-source agent-based simulation toolkit that has been in constant development since 2002. MASON\u2019s architecture was cutting-edge for its time, but advances in computer technology now offer new opportunities for the ABM community to scale models and apply new modeling techniques. We are extending MASON to provide these opportunities in response to community feedback. In this paper we discuss MASON, its history and design, and how we plan to improve and extend it over the next several years. Based on user feedback will add distributed simulation, distributed GIS, optimization and sensitivity analysis tools, external language and development environment support, statistics facilities, collaborative archives, and educational tools.","Agent-based simulation | Library | Open source","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-22270-3_6","2-s2.0-85068334008"],["2019-01-01","Gennaro Cordasco","Handwriting and drawing features for detecting negative moods","In order to provide support to the implementation of on-line and remote systems for the early detection of interactional disorders, this paper reports on the exploitation of handwriting and drawing features for detecting negative moods. The features are collected from depressed, stressed, and anxious subjects, assessed with DASS-42, and matched by age and gender with handwriting and drawing features of typically ones. Mixed ANOVA analyses, based on a binary categorization of the groups, reveal significant differences among features collected from subjects with negative moods with respect to the control group depending on the involved exercises and features categories (in time or frequency of the considered events). In addition, the paper reports the description of a large database of handwriting and drawing features collected from 240 subjects.","Affective database | Depression\u2013anxiety\u2013stress scales (DASS) | Emotional state | Handwriting","Smart Innovation, Systems and Technologies","Book Chapter","https:\/\/www.doi.org\/10.1007\/978-3-319-95095-2_7","2-s2.0-85051848218"],["2019-01-01","Carmine Spagnuolo","On Evaluating Rust as a Programming Language for the Future of Massive Agent-Based Simulations","The analysis of real systems and the development of predictive models to describe the evolution of real phenomena are challenging tasks that can improve the design of methodologies in many research fields. In this context, Agent-Based Model (ABM) can be seen as an innovative tool for modelling real-world complex simulations. This paper presents Rust-AB, an open-source library for developing ABM simulation on sequential and\/or parallel computing platforms, exploiting Rust as programming language. The Rust-AB architecture as well as an investigation on the ability of Rust to develop ABM simulations are discussed. An ABM simulation written in Rust-AB, and a performance comparison against the well-adopted Java ABM toolkit MASON is also presented.","Agent-Based Model | Framework | Rust language | Simulation","Communications in Computer and Information Science","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-981-15-1078-6_2","2-s2.0-85075680624"],["2019-01-01","Gennaro Cordasco","The dependability of voice on elders' acceptance of humanoid agents","The research on ambient assistive technology is concerned with features humanoid agents should show in order to gain user acceptance. However, differently aged groups may have different requirements. This paper is particularly focused on agent's voice preferences among elders, young adults, and adolescents. To this aim 316 users organized in groups of 45\/46 subjects of which 3 groups of elders (65+ years old), 2 of young adults (aged between 22-35 years), and 2 of adolescents (aged between 14-16 years) were recruited and administered the Virtual Agent Acceptance Questionnaire (VAAQ), after watching video-clips of mute and speaking agents, in order to test their preferences in terms of willingness to interact, pragmatic and hedonic qualities, and attractiveness, of proposed speaking and mute agents. In addition, the elders were also tested on listening only the agent's. The results suggest that voice is primary for getting elder's acceptance of virtual humanoid agents in contrast to young adults and adolescents which accept equally well either mute or speaking agents.","Differently aged users | Humanoid agents | Users'acceptability | Voice role","Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH","Conference Paper","https:\/\/www.doi.org\/10.21437\/Interspeech.2019-1734","2-s2.0-85074685857"],["2019-01-01","Biagio Cosenza","Celerity: High-Level C++ for Accelerator Clusters","In the face of ever-slowing single-thread performance growth for CPUs, the scientific and engineering communities increasingly turn to accelerator parallelization to tackle growing application workloads. Existing means of targeting distributed memory accelerator clusters impose severe programmability barriers and maintenance burdens. The Celerity programming environment seeks to enable developers to scale C++ applications to accelerator clusters with relative ease, while leveraging and extending the SYCL domain-specific embedded language. By having users provide minimal information about how data is accessed within compute kernels, Celerity automatically distributes work and data. We introduce the Celerity C++ API as well as a prototype implementation, demonstrating that existing SYCL code can be brought to distributed memory clusters with only a small set of changes that follow established idioms. The Celerity prototype runtime implementation is shown to have comparable performance to more traditional approaches to distributed memory accelerator programming, such as MPI+OpenCL, with significantly lower implementation complexity.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-29400-7_21","2-s2.0-85077114097"],["2019-01-01","Vittorio Scarano","Syntactical heuristics for the open data quality assessment and their applications","Open Government Data are valuable initiatives in favour of transparency, accountability, and openness. The expectation is to increase participation by engaging citizens, non-profit organisations, and companies in reusing Open Data (OD). A potential barrier in the exploitation of OD and engagement of the target audience is the low quality of available datasets [3, 14, 16]. Non-technical consumers are often unaware that data could have potential quality issues, taking for grant that datasets can be used immediately without any further manipulation. In reality, in order to reuse data, for instance to create visualisations, they need to perform a data clean, which requires time, resources, and proper skills. This leads to a reduced chance to involve citizens. This paper tackles the quality barrier of raw tabular datasets (i.e. CSV), a popular format (Tim-Berners Lee tree-stars) for Governmental Open Data. The objective is to increase awareness and provide support in data cleaning operations to both PAs to produce better quality Open Data and non-technical data consumers to reuse datasets. DataChecker is an open source and modular JavaScript library shared with community and available on GitHub that takes in input a tabular dataset and generate a machine-readable report based on the data type inferencing (a data profiling technique). Based on it the Social Platform for Open Data (SPOD) provides quality cleaning suggestions to both PAs and end-users.","Open data | Quality assessment | Type inferencing","Lecture Notes in Business Information Processing","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-04849-5_51","2-s2.0-85061578958"],["2019-01-01","Delfina Malandrino","The conundrum of success in music: Playing it or talking about it?","Nowadays social media are the main means for conducting discussions and sharing opinions. The huge amount of information generated by social media users is helpful for predicting outcomes of real-world events in different fields, including business, politics and the entertainment industry. In this paper, we studied the possibility of forecasting the success of music albums by analyzing heterogeneous data sources spanning from social media (Twitter, Instagram and Facebook) to mainstream American newspapers (e.g., New York Times, Rolling Stones). The idea is to exploit music albums' pre-release hype and post-release approval to predict the album's rank with reference to the well-known Billboard 200 album chart, which tabulates the weekly popularity of music albums in the USA. To predict the success of a music album, that is its rank in the chart, we identified metrics based on the messages' posting trend, the variation of the sentiment associated to such messages, the number of followers of the album's author, and the importance of the people who talk about it. To evaluate the effectiveness of the proposed metrics we have compared the prediction performances of several models based on supervised learning approaches among those most used in literature. As a result, we obtained that the Random Forest approach is able to predict the music album rank in the Billboard 200 Chart with an expected accuracy of 97%. As a further validation, using this specific model, we also conducted an additional real usage test obtaining an almost matching result (accuracy of 94%).","machine learning | music industry | prediction | sentiment analysis | Social media","IEEE Access","Article","https:\/\/www.doi.org\/10.1109\/ACCESS.2019.2937743","2-s2.0-85074930688"],["2018-12-13","Gennaro Cordasco","Power poses affect risk tolerance and skin conductance levels","Humans are used to express their feelings of selfconfidence\/powerfulness or their distress\/sadness through either expansive postures that occupy as much space as possible or closing postures occupying as less space as possible to avoid contact. This conduct suggests that feelings of selfconfidence\/powerfulness or distress\/sadness change our body expressions\/postures. It can be interesting to assess whether the reverse is also true, i.e. the way we arrange our body at a given moment would affect our feelings. The present research reports an investigation on such argument. To this aim, 50 subjects (25 females) aged between 23 and 31 years were requested to adopt either an expansive (high-powered) or contracted (low-powered) posture for as long as 3 minutes and then asked to bet money in a dice game. The results show that assuming high-power poses favors risk tolerant behaviors and rises feelings of powerfulness. This is not true in the case of low-power postures, which engender a sense of stress, sustained by a significant increase of skin conductance levels. Considerations are made on how to exploit these results for psychotherapy and rehabilitation purposes, as well as, for the implementation of artificial intelligent systems operating as tools for well-being and coaching.","Decision making | Embodiment | Feelings | High-power and low-power poses | Risk tolerant behaviors | Skin conductance levels","Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICTAI.2018.00159","2-s2.0-85060795936"],["2018-12-08","Delfina Malandrino","A multi-objective optimization model for music styles","Style recognition is one of the problems mostly faced by Computational Intelligence techniques. Most of them were defined ad-hoc for a specific music genre and so not generalizable and applicable to any style. A music style, both of soloists performer and of musical collectives, is the result of aesthetic goals, i.e., experience and preferences, functional rules, i.e., rules used to produce music, and external influence, i.e., the choices depending by the simultaneous presence of other musicians. We propose a new model of style, defined in terms of a multi-objective problem, where the objective is to minimize the distance between the style of each musician and the stylistic features derived by other musicians. Such a model is general since it is applicable to any type of style. We also propose a new approach for both recognition and automatic composition of styles based on such a model, which exploits a machine learning recognizer and a splicing composer. To assess the effectiveness and the generalization capability of our system we performed several tests using a large set of Jazz transcriptions and a corpus of 4-voice music by J. S. Bach. We show that our classifier is able to achieve a recognition accuracy of 97.1%. With regard to the composition process, we measured the capability of our system to capture both aesthetic goals by collecting subjective perceptions from domain experts, and functional rules by computing the average percentage of (1) typical harmonic progressions in the Jazz music produced and (2) forbidden exceptions, which occur in the 4-voice music, produced.","Machine learning | Music Style recognition | Splicing systems","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3297156.3297205","2-s2.0-85062791351"],["2018-12-05","Delfina Malandrino","Visualization and music harmony: Design, implementation, and evaluation","Music expertise is the ability to understand the structural elements of music compositions by reading musical scores or simply listening to music performance. Although the most common way to learn music is through the study of musical scores, this approach is demanding in terms of learning ability, given the required implicit knowledge of music theoretical concepts. Learning musical rules is hard, especially for classical music. To simplify this task, visualization is one of the most promising approaches, also thanks to the human visual cognition ability (i.e., visual memory, visual attention, and so on). This work aims at building a visual tool, named VisualHarmony, to help people in composing music pieces in a quick and efficient way (i.e., avoiding specific errors as dictated by classical music theory rules). More specifically, a visualization technique able to represent harmonic structures has been evaluated by teachers of Conservatory classes and from domain experts in order to collect requirements used to define graphical features needed to facilitate the study of the rules used in classical music, and to implement VisualHarmony. We have focused our attention on a specific type of music compositions, i.e., the chorale style (4-voice music). VisualHarmony was tested in order to analyze system usability and user satisfaction. Results of these studies provided us with positive feedback about the effectiveness of the idea, the pleasantness of the graphical choices, the satisfaction of the users with regard to the easiness and the usefulness of the provided tool.","Evaluation | Music-learning | Music-performance","Information Visualisation - Biomedical Visualization, Visualisation on Built and Rural Environments and Geometric Modelling and Imaging, IV 2018","Conference Paper","https:\/\/www.doi.org\/10.1109\/iV.2018.00092","2-s2.0-85060140659"],["2018-12-05","Delfina Malandrino","Evaluation study of visualisations for harmonic analysis of 4-part music","In order to master the harmonic analysis of musical compositions, a musician needs to profoundly understand the music theory, have an extensive training, and put a considerable effort in the task. For learners it can be a time-consuming and tedious task due to the steep learning curve. The idea throughout this paper is to visually annotate musical compositions with the objective to support users in performing the harmonic analysis, in which the task is mainly based on the identification of similar tonalities and relevant degrees. The paper proposes two visualisations that use rectangles to represent tonalities and the degree and exploit colours to represent similarities. The design of visualisations is based on guidelines drawn from informal interviews with teachers of the Conservatorio G. Martucci, a conservatory in Salerno, and from literature. The evaluation study by involving 30 participants showed that overall the 30 participants of the evaluation study achieved better results performing the harmonic analysis using the musical composition enhanced with visualisations compared to the standard musical composition; it is a promising result that encourages further investigation in the field.","-Classical-Music | -Evaluation | -Harmonic-Analysis | -Visualization | Computer-Music","Information Visualisation - Biomedical Visualization, Visualisation on Built and Rural Environments and Geometric Modelling and Imaging, IV 2018","Conference Paper","https:\/\/www.doi.org\/10.1109\/iV.2018.00090","2-s2.0-85060180054"],["2018-12-05","Delfina Malandrino","Cartographies of the legal world. Rise and challenges of visual legal analytics","In recent years, together with the adoption of data driven approaches and the development of computational heuristics, visualization has become part of a process that is gradually changing methods of social sciences. In this paper we present some applications of visual computing in the legal science and practice. After a brief introduction to the rise and challenges of what we define as Visual Legal Analytics, we briefly sketch the results of three research projects dealing with visualization at the boundaries between law and computer science discussing their objectives, advantages and perspectives.","Computational Legal Science | Legal Informatics | Visual analytics","Information Visualisation - Biomedical Visualization, Visualisation on Built and Rural Environments and Geometric Modelling and Imaging, IV 2018","Conference Paper","https:\/\/www.doi.org\/10.1109\/iV.2018.00049","2-s2.0-85060169098"],["2018-12-01","Gennaro Cordasco","Distributed MASON: A scalable distributed multi-agent simulation environment","Computational Social Science (CSS) involves interdisciplinary fields and exploits computational methods, such as social network analysis as well as computer simulation with the goal of better understanding social phenomena. Agent-Based Models (ABMs) represent an effective research tool for CSS and consist of a class of models, which, aim to emulate or predict complex phenomena through a set of simple rules (i.e., independent actions, interactions and adaptation), performed by multiple agents. The efficiency and scalability of ABMs systems are typically obtained distributing the overall computation on several machines, which interact with each other in order to simulate a specific model. Unfortunately, the design of a distributed simulation model is particularly challenging, especially for domain experts who sporadically are computer scientists and are not used to developing parallel code. D-MASON framework is a distributed version of the MASON library for designing and executing ABMs in a distributed environment ensuring scalability and easiness. D-MASON enable the developer to exploit the computing power of distributed environment in a transparent manner; the developer has to do simple incremental modifications to existing MASON models, without re-designing them. This paper presents several novel features and architectural improvements introduced in the D-MASON framework: an improved space partitioning strategy, a distributed 3D field, a distributed network field, a decentralized communication layer, a novel memory consistency mechanism and the integration to cloud environments. Full documentation, additional tutorials, and other material can be found at https:\/\/github.com\/isislab-unisa\/dmason where the framework can be downloaded.","Agent-based simulation | Cloud computing | Distributed computing | Parallel computing | Scalable computational science","Simulation Modelling Practice and Theory","Article","https:\/\/www.doi.org\/10.1016\/j.simpat.2018.09.002","2-s2.0-85053387248"],["2018-10-29","Biagio Cosenza","Cost Modelling for Vectorization on ARM","When applying a code transformation to optimize for performance, compilers need to assess its profitability beforehand. For this purpose, they utilize cost models, which compare the cost, an abstract measure of the code, before and after the transformation. If the cost is lower after the transformation, it will be applied. Exact cost modelling is therefore critical to avoid slowdowns or missed opportunities for speedups. In this work, we analyze the accuracy of LLVM's loop-level vectorization (LLV) cost model, and show the benefit of modelling speedup instead of instruction costs for higher vectorization rates and smaller execution times. The presented approach is portable to other compilers and hardwares as well.","ARM | Compiler | Cost Modelling | Performance Prediction | Vectorization","Proceedings - IEEE International Conference on Cluster Computing, ICCC","Conference Paper","https:\/\/www.doi.org\/10.1109\/CLUSTER.2018.00084","2-s2.0-85057256402"],["2018-06-06","Biagio Cosenza","Accelerating the RICH Particle Detector Algorithm on Intel Xeon Phi","At the LHC, particles are collided in order to understand how the universe was created. Those collisions are called events and generate large quantities of data, which have to be pre-filtered before they are stored to hard disks. This paper presents a parallel implementation of these algorithms that is specifically designed for the Intel Xeon Phi Knights Landing platform, exploiting its 64 cores and AVX-512 instruction set. It shows that a linear speedup up until approximately 64 threads is attainable when vectorization is used, data is aligned to cache line boundaries, program execution is pinned to MCDRAM, mathematical expressions are transformed to a more efficient equivalent formulation, and OpenMP is used for parallelization. The code was transformed from being compute bound to memory bound. Overall, a speedup of 36.47x was reached while obtaining an error which is smaller than the detector resolution.","Intel Xeon Phi | Knights Landing | OpenMP | Parallel Programming | Vectorization","Proceedings - 26th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing, PDP 2018","Conference Paper","https:\/\/www.doi.org\/10.1109\/PDP2018.2018.00066","2-s2.0-85048787296"],["2018-06-04","Gennaro Cordasco","How traders' appearances and moral descriptions influence receivers' choices in the ultimatum game","This work reports on a series of experiments involving 960 participants (aged between 20-30 years and equally balanced by gender), asked to play the receiver role in a modified version of the Ultimatum Game, where together with information on the offer's fairness (e.g. 40 (fair) vs 10 (unfair) of 100 euros), a photo depicted the trader's appearance (trustworthy vs. untrustworthy) and a text provided his moral description (honest vs. dishonest). Receivers were asked to motivate their decision in connection with the appearance, moral judgment, and fairness of the offer, and report on how these variables affected their emotional feelings. Data analysis shows that, in all conditions containing a fair offer, the trader's appearance plays a significant role in the receivers' decisions in terms of acceptance rate. Moral descriptions play a significant role only in conditions containing an unfair offer. However, when asked to motivate their choices, subjects do not feel the interference of the social appearance, rather they provide more or less equal number of motivations with reference to the amount of offers and moral judgments. As for the emotions driving their decisions, non-converging feelings are observed both at intra and inter group level.","Contextual information | Decisional behaviors | Emotional behaviors | Moral judgments | Social appearances | Ultimatum Game","Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICTAI.2017.00070","2-s2.0-85048466548"],["2018-06-01","Gennaro Cordasco","Evangelism in social networks: Algorithms and complexity","We consider a population of interconnected individuals that, with respect to a piece of information, at each time instant can be subdivided into three (time-dependent) categories: agnostics, influenced, and evangelists. A dynamical process of information diffusion evolves among the individuals of the population according to the following rules. Initially, all individuals are agnostic. Then, a set of people is chosen from the outside and convinced to start evangelizing, that is, to start spreading the information. When a number of evangelists, greater than a given threshold, communicate with a node v, the node v becomes influenced, whereas, as soon as the individual v is contacted by a sufficiently much larger number of evangelists, it is itself converted into an evangelist and consequently it starts spreading the information. The question is: How to choose a bounded cardinality initial set of evangelists so as to maximize the final number of influenced individuals? We prove that the problem is hard to solve, even in an approximate sense. On the positive side, we present exact polynomial time algorithms for trees and complete graphs. For general graphs, we derive exact parameterized algorithms. We also study the problem when the objective is to select a minimum number of evangelists capable of influencing the whole network. Our motivations to study these problems come from the areas of Viral Marketing and spread of influence in social networks. \u00a9 2017 Wiley Periodicals, Inc. NETWORKS, Vol. 71(4), 346\u2013357 2018.","influence maximization | parametrized complexity | social network | spread of influence | viral marketing","Networks","Article","https:\/\/www.doi.org\/10.1002\/net.21756","2-s2.0-85024475252"],["2018-06-01","Gennaro Cordasco","Discovering Small Target Sets in Social Networks: A Fast and Effective Algorithm","Given a network represented by a graph G= (V, E) , we consider a dynamical process of influence diffusion in G that evolves as follows: Initially only the nodes of a given S\u2286 V are influenced; subsequently, at each round, the set of influenced nodes is augmented by all the nodes in the network that have a sufficiently large number of already influenced neighbors. The question is to determine a small subset of nodes S (a target set) that can influence the whole network. This is a widely studied problem that abstracts many phenomena in the social, economic, biological, and physical sciences. It is known that the above optimization problem is hard to approximate within a factor of 2log1-\u03f5|V|, for any \u03f5> 0. In this paper, we present a fast and surprisingly simple algorithm that exhibits the following features: (1) when applied to trees, cycles, or complete graphs, it always produces an optimal solution (i.e, a minimum size target set); (2) when applied to arbitrary networks, it always produces a solution of cardinality which improves on previously known upper bounds; (3) when applied to real-life networks, it always produces solutions that substantially outperform the ones obtained by previously published algorithms (for which no proof of optimality or performance guarantee is known in any class of graphs).","Algorithms | Information diffusions | Social networks","Algorithmica","Article","https:\/\/www.doi.org\/10.1007\/s00453-017-0390-5","2-s2.0-85032361567"],["2018-05-30","Vittorio Scarano","A comprehensive architecture to support Open Data access, co-creation, and Dissemination","Contemporary data infrastructures are yet to afford easy access to available data, better understanding of these data, engagement around data to drive collective sense-making and knowledge cocreation. This work synthesizes the knowledge gained through a 40-month research and innovation project which led to designing and implementing an architecture which addresses those challenges.","Open Data | Open Data Infrastructure | Open Government","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3209281.3209411","2-s2.0-85049050893"],["2018-05-30","Vittorio Scarano","Agile production of high quality open data","This paper introduces an Agile Methodology to support the production of Open Data (OD) which can be internally adopted and adapted by Public Agencies (PAs) in order to make data publicly available. The methodology is iterative, incremental, evolutionary, test-driven, and collaborative. The novel idea is that PAs produce open data and, at same time, envision and anticipate possible uses and re-uses by citizens. The opportunity is that PAs will publish use cases along with Open Data as a way to engage citizens. The fit-for-use test is a specific step of the methodology in which PAs conceive possible uses of the dataset by creating a set of relevant visualisations (e.g., charts). This step mitigates some well-known barriers in the field of the OD, such as, that the data could be not accurate, not interesting, or too costly to be re-used [27]. The paper describes a platform named SPOD, based on the above agile methodology, meant to be used by PAs over their Intranet to support the collaborative process to make data publicly available. Moreover, the methodology and the SPOD have specific steps to assist PAs in checking the dataset quality through syntactic, sanity and domainspecific steps implemented through a set of heuristics. Both the methodology and the SPOD have been successfully adopted by the Council of the Campania Region in Italy to produce their open data, this experience has detailed described and reported in the paper.","Open data | Open data authoring | Open government","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3209281.3209352","2-s2.0-85049022050"],["2018-05-28","Biagio Cosenza","Control flow vectorization for ARM NEON","Single Instruction Multiple Data (SIMD) extensions in processors enable in-core parallelism for operations on vectors of data. From the compiler perspective, SIMD instructions require automatic techniques to determine how and when it is possible to express computations in terms of vector operations. When this is not possible automatically, a user may still write code in a manner that allows the compiler to deduce that vectorization is possible, or by explicitly define how to vectorize by using intrinsics. This work analyzes the challenge of generating efficient vector instructions by benchmarking 151 loop paerns with three compilers on two SIMD instruction sets. Comparing the vectorization rates for the AVX2 and NEON instruction sets, we observed that the presence of control flow poses a major problem for the vectorization on NEON. We consequently propose a set of solutions to generate efficient vector instructions in the presence of control flow. In particular, we show how to overcome the lack of masked load and store instruction with different code generation strategies. Results show that we enable vectorization of conditional read operations with a minimal overhead, while our technique of atomic select stores achieves a speedup of more than 2x over state of the art for large vectorization factors.",null,"Proceedings of the 21st International Workshop on Software and Compilers for Embedded Systems, SCOPES 2018","Conference Paper","https:\/\/www.doi.org\/10.1145\/3207719.3207721","2-s2.0-85054146071"],["2018-04-26","Delfina Malandrino","Ex Machina: Analytical platforms, law and the challenges of computational legal science","Over the years, computation has become a fundamental part of the scientific practice in several research fields that goes far beyond the boundaries of natural sciences. Data mining, machine learning, simulations and other computational methods lie today at the hearth of the scientific endeavour in a growing number of social research areas from anthropology to economics. In this scenario, an increasingly important role is played by analytical platforms: integrated environments allowing researchers to experiment cutting-edge data-driven and computation-intensive analyses. The paper discusses the appearance of such tools in the emerging field of computational legal science. After a general introduction to the impact of computational methods on both natural and social sciences, we describe the concept and the features of an analytical platform exploring innovative cross-methodological approaches to the academic and investigative study of crime. Stemming from an ongoing project involving researchers from law, computer science and bioinformatics, the initiative is presented and discussed as an opportunity to raise a debate about the future of legal scholarship and, inside of it, about the challenges of computational legal science.","Analytical platforms | Computational legal science | Computational science | Crime analysis | Legal informatics | Machine learning | Network-based inference","Future Internet","Article","https:\/\/www.doi.org\/10.3390\/fi10050037","2-s2.0-85046684097"],["2018-04-04","Carmine Spagnuolo","A layered architecture for open data: Design, implementation and experiences","In order to increase transparency, Public Administrations (PAs) have their own portals to publish Open Data, resulting in more openness, reduced corruption and improved services. Open Data (OD) initiatives are achieving less citizens' engagement than expected. Hence, the need to find other ways and services to obtain more engagement and extract value from OD. This paper introduces an architectural model to design software platforms with the objective to increase public value through collective participation of citizens, public administrations and key stakeholders. The architectural model originates from the Data-Information-Knowledge hierarchy, where greater value is at the top of the pyramid, in information and knowledge gathered from data. Thus, the architectural model adds the collaborative and presentation layers to the classical data layer; citizens, public administrations, and stakeholders form groups of interests to understand, reason and interpret Open Data to gather information and generate knowledge that will be communicated to the general audience over Internet, thus, increasing public value. The paper describes three platform instances: the ROUTE-TO-PA ecosystem, the data.world, and DKAN, which functionalities can be mapped onto the architectural model proposed in the paper. Furthermore, the paper describes HETOR, a concreate experience of exploitation of the architectural model and the ROUTE-TO-PA ecosystem with groups of students and associations of citizens, who collaborated together to ultimately generate new knowledge for Cultural Heritage to be communicated over Internet through blog posts.","E-Participation | Open Data | Open Government","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3209415.3209466","2-s2.0-85051438473"],["2018-04-01","Carmine Spagnuolo","Distributed simulation optimization and parameter exploration framework for the cloud","Simulation models are becoming an increasingly popular tool for the analysis and optimization of complex real systems in different fields. Finding an optimal system design requires performing a large sweep over the parameter space in an organized way. Hence, the model optimization process is extremely demanding from a computational point of view, as it requires careful, time-consuming, complex orchestration of coordinated executions. In this paper, we present the design of SOF (Simulation Optimization and exploration Framework in the cloud), a framework which exploits the computing power of a cloud computational environment in order to carry out effective and efficient simulation optimization strategies. SOF offers several attractive features. Firstly, SOF requires \u201czero configuration\u201d as it does not require any additional software installed on the remote node; only standard Apache Hadoop and SSH access are sufficient. Secondly, SOF is transparent to the user, since the user is totally unaware that the system operates on a distributed environment. Finally, SOF is highly customizable and programmable, since it enables the running of different simulation optimization scenarios using diverse programming languages \u2013 provided that the hosting platform supports them \u2013 and different simulation toolkits, as developed by the modeler. The tool has been fully developed and is available on a public repository1 under the terms of the open source Apache License. It has been tested and validated on several private platforms, such as a dedicated cluster of workstations, as well as on public platforms, including the Hortonworks Data Platform and Amazon Web Services Elastic MapReduce solution.","Agent-based simulation | Cloud computing | Distributed computing | Model exploration | Parallel computing | Simulation optimization","Simulation Modelling Practice and Theory","Article","https:\/\/www.doi.org\/10.1016\/j.simpat.2017.12.005","2-s2.0-85039448974"],["2018-02-24","Biagio Cosenza","Local memory-aware kernel perforation","Many applications provide inherent resilience to some amount of error and can potentially trade accuracy for performance by using approximate computing. Applications running on GPUs often use local memory to minimize the number of global memory accesses and to speed up execution. Local memory can also be very useful to improve the way approximate computation is performed, e.g., by improving the quality of approximation with data reconstruction techniques. This paper introduces local memory-aware perforation techniques specifically designed for the acceleration and approximation of GPU kernels. We propose a local memory-aware kernel perforation technique that first skips the loading of parts of the input data from global memory, and later uses reconstruction techniques on local memory to reach higher accuracy while having performance similar to state-of-the-art techniques. Experiments show that our approach is able to accelerate the execution of a variety of applications from 1.6\u00d7 to 3\u00d7 while introducing an average error of 6%, which is much smaller than that of other approaches. Results further show how much the error depends on the input data and application scenario, the impact of local memory tuning and different parameter configurations.","Approximate computing | GPU | Kernel perforation","CGO 2018 - Proceedings of the 2018 International Symposium on Code Generation and Optimization","Conference Paper","https:\/\/www.doi.org\/10.1145\/3168814","2-s2.0-85052761969"],["2018-02-01","Delfina Malandrino","A methodological evaluation of natural user interfaces for immersive 3D Graph explorations","In this paper, we present a novel approach for a real-time 3D exploration and interaction of large graphs using an immersive virtual reality environment and a natural user interface. The implementation of the approach has been developed as plug-in module, named 3D Graph Explorer, for Gephi, an open software for graph and network analysis. To assess the validity of the approach and of the overall environment, we have also conducted an empirical evaluation study by grouping people in two different configurations to explore and interact with a large graph. Specifically, we designed an innovative configuration, exploiting the natural user interface in a virtual reality environment, against a well-known and widespread mouse\u2013keyboard configuration. The evaluation suggests that these upcoming technologies are more challenging than the traditional ones, but enable user to be more involved during graph interaction and visualization tasks, given the enjoyable experience elicited when combining gestures-based interfaces and virtual reality.","Evaluation study | Graph exploration | Natural user interface | Software visualization | Virtual reality","Journal of Visual Languages and Computing","Article","https:\/\/www.doi.org\/10.1016\/j.jvlc.2017.11.002","2-s2.0-85034605578"],["2018-01-01","Vittorio Scarano","OpenABL: A Domain-Specific Language for Parallel and Distributed Agent-Based Simulations","Agent-based simulations are becoming widespread among scientists from different areas, who use them to model increasingly complex problems. To cope with the growing computational complexity, parallel and distributed implementations have been developed for a wide range of platforms. However, it is difficult to have simulations that are portable to different platforms while still achieving high performance. We present OpenABL, a domain-specific language for portable, high-performance, parallel agent modeling. It comprises an easy-to-program language that relies on high-level abstractions for programmability and explicitly exploits agent parallelism to deliver high performance. A source-to-source compiler translates the input code to a high-level intermediate representation exposing parallelism, locality and synchronization, and, thanks to an architecture based on pluggable backends, generates target code for multi-core CPUs, GPUs, large clusters and cloud systems. OpenABL has been evaluated on six applications from various fields such as ecology, animation, and social sciences. The generated code scales to large clusters and performs similarly to hand-written target-specific code, while requiring significantly fewer lines of codes.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-96983-1_36","2-s2.0-85052967604"],["2018-01-01","Gennaro Cordasco","EMPATHIC, Expressive, Advanced Virtual Coach to Improve Independent Healthy-Life-Years of the Elderdy","The EMPATHIC Research & Innovation project researchs, innovates, explores and validates new paradigms and platforms, laying the foundation for future generations of Personalised Virtual Coaches to assist elderly people living independently at and around their home. The project uses remote non-intrusive technologies to extract physiological markers of emotional states in real-time for online adaptive responses of the coach, and advances holistic modelling of behavioural, computational, physical and social aspects of a personalised expressive virtual coach. It develops causal models of coach-user interactional exchanges that engage elders in emotionally believable interactions keeping off loneliness, sustaining health status, enhancing quality of life and simplifying access to future telecare services. EMPATHIC proposes multidisciplinary research and development, involving: \u2022 Geriatrician, Neuroscientist, Psychiatric, health and social work specialists, knowledgeable in age related conditions and the aims of a coaching program in maintaining independence, functional capacity, and monitoring physical, cognitive, mental and social wellbeing to implement the individual coaching goals \u2022 Psychologist, Neuroscientist and Computer Science experts for detection and identification of the emotional status of the user \u2022 Engineers and Computer Scientists in speech and language technologies, biometrics, image analysis, and machine learning. They will develop tools to detect emotional cues, model users' emotional status, translate coaching plans into actions, user-adapt spoken dialogue and personalise talking agents \u2022 Telecare services, a senior association and a hospital interested in testing and validating EMPATHIC \u2022 Companies interested in providing and developing technology for the project and commercialising the products and derived services Through measurable end-user validation, to be performed in 3 different countries (Spain, Norway and France) with 3 distinct languages and cultures (plus English for R&D), the proposed methods and solutions will ensure usefulness, reliability, flexibility and robustness.","emotional features from speech and language | emotional voice | human-computer interaction | natural language generation | natural language understanding | speech recognition | spoken dialog systems | text to speech conversion","4th International Conference, IberSPEECH 2018","Conference Paper","https:\/\/www.doi.org\/10.26342\/2018-61-24","2-s2.0-85133531775"],["2018-01-01","Carmine Spagnuolo","Heterogeneous Scalable Multi-languages Optimization via Simulation","Scientific Computing (SC) is a multidisciplinary field that uses the computational approach to understand and study complex artificial and natural systems belonging many scientific sectors. Optimization via Simulation (OvS) is a fast developing area in SC field. OvS combines classical optimization algorithms and stochastic simulations to face problems with unknown and\/or dynamic data distribution. We present Heterogeneous Simulation Optimization (HSO), an architecture that enable to distribute the OvS process on an Heterogeneous Computing systems. HSO is designed according to two levels of heterogeneity: hardware heterogeneity, that is the ability to exploit the computational power of several general-purpose CPUs and\/or hardware accelerators such as Graphics Processing Units (GPUs); programming languages heterogeneity, that is the capability to develop the OvS methodology combining different programming languages such as C++, C, Clojure, Erlang, Go, Haskel, Java, Node.js, Objective-C, PHP, Python, Scala and many others. The proposed HSO architecture has been fully developed and is available on a public GitHub repository. We have validated and tested the scalability of HSO developing two different use cases that show both the levels of heterogeneity, and showing how to exploit Optimal Computing Budget Allocation (OCBA) algorithm and a Genetic Algorithm in a OvS process.","GPU Computing | Heterogeneous computing | Multi agent-based simulation | Optimization | Parallel computing | Simulation via optimization","Communications in Computer and Information Science","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-981-13-2853-4_13","2-s2.0-85055640657"],["2018-01-01","Gennaro Cordasco","Seniors\u2019 acceptance of virtual humanoid agents","This paper reports on a study conducted as part of the EU EMPATHIC project, whose goal is to develop an empathic virtual coach capable of enhancing seniors\u2019 well-being, focusing on user requirements and expectations with respect to participants\u2019 age and technology experiences (i.e. participants\u2019 familiarity with technological devices such as smartphones, laptops, and tablets). The data shows that seniors\u2019 favorite technological device is the smartphone, and this device was also the one that scored the highest in terms of easiness to use. We found statistically significant differences on the preferences expressed by seniors toward the gender of the agents. Seniors (independently from their gender) prefer to interact with female humanoid agents on both the pragmatic and hedonic dimensions of an interactive system and are more in favor to commit themselves in a long-lasting interaction with them. In addition, we found statistically significant effects of the seniors\u2019 technology savviness on the hedonic qualities of the proposed interactive systems. Seniors with technological experience felt less motivated and judged the proposed agents less captivating, exciting, and appealing.","Agent\u2019s appearance | Aging well | Assistive technologies | User\u2019s requirements and expectations | Virtual agents","Lecture Notes in Electrical Engineering","Book Chapter","https:\/\/www.doi.org\/10.1007\/978-3-030-05921-7_35","2-s2.0-85062279159"],["2018-01-01","Gennaro Cordasco","Time-bounded influence diffusion with incentives","A widely studied model of influence diffusion in social networks represents the network as a graph G = (V, E) with an influence threshold t(v) for each node. Initially the members of an initial set S \u2286 V are influenced. During each subsequent round, the set of influenced nodes is augmented by including every node v that has at least t(v) previously influenced neighbours. The general problem is to find a small initial set that influences the whole network. In this paper we extend this model by using incentives to reduce the thresholds of some nodes. The goal is to minimize the total of the incentives required to ensure that the process completes within a given number of rounds. The problem is hard to approximate in general networks. We present polynomial-time algorithms for paths, trees, and complete networks.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-030-01325-7_25","2-s2.0-85061126716"],["2018-01-01","Gennaro Cordasco","Threshold-bounded dominating set with incentives","Motivated by some problems in the area of influence spread in social networks, we introduce a new variation on the domination problem which we call Threshold-Bounded Domination with Incentives. Let G = (V, E) be a graph with an influence threshold t(v) for each node. An assignment of external incentives to the nodes of G is a cost function c : V \u2192 N0, where c(v) is the incentive given to v \u2208 V . The effect of applying incentive c(v) to node v is to decrease its threshold, i.e., to make v more susceptible to be dominated. A node is in the Threshold-Bounded dominating set D if it receives an incentive equal to its threshold, that is, c(v) = t(v). A node, which is not in D, is dominated if the number of its neighbors in D plus the incentives it has received is at least equal to the node threshold t(v). The goal is to minimize the total of the incentives required to ensure that all the nodes are dominated. The problem is log-APX-complete in general networks with unbounded degree. We prove that a greedy strategy has approximation factor ln \u2206 + 2, where \u2206 is the maximum degree of a node. We also give exact linear time algorithms for some classes of graphs.","Approximation algorithms | Incentives | Recommending systems | Social networks | Vector domination | Weighted domination","CEUR Workshop Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-85056860149"],["2018-01-01","Gennaro Cordasco","Seniors\u2019 sensing of agents\u2019 personality from facial expressions","The presented study investigated the preferences of seniors towards artificial avatars showing personality both from a pragmatic and a hedonic point of view. Also, preferences for technological devices were considered. The involved participants were 45 adults (20 female) aged 65+ years in good health. They were asked to watch video clips of 4 agents (two males and two females) showing different personality traits (i.e. angry, depressed, joyful, and practical), and subsequently had to complete a questionnaire. Subjects were not informed about an avatar\u2019s personality and not openly interviewed regarding this subject. Rather, the administered questionnaire was devoted to test their perception of agents and whether such complies with the intended characteristics. Results show that subjects prefer female agents with a positive personality (joyful and practical) on both pragmatic and hedonic dimensions of the interactive system.","Assisted living | Emotional artificial agents | Facial expressions","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-94274-2_63","2-s2.0-85049771620"],["2018-01-01","Vittorio Scarano","A Social Platform to support citizens reuse of open 3d visualisations: A citizen science approach","There is a growing interest in the world of Open Data, with many initiatives in the Cultural Heritage field. Platforms like Europeana, archive.org, Open Heritage by Google are only few examples of on-line catalogues full of open artefacts published with various formats. It is a new and promising way to engage public, such as, students, citizens, non-profit organisations. This paper faces the question of how to help audience in reusing Open 3D models and other artefacts available on Open Cultural Heritage repositories. The idea is to provide a Social Platform named SPOD where citizens can visualise artefacts, share and comment with others in a social way to increase understanding, awareness and engagement in cultural heritage. The foundation is the Datalet-Ecosystem Provider (DEEP), an open source, extensible, scalable, and Edge-centric visualisation architecture to support reuse of visualisations of Open Data in Cultural Heritage. It consists of reusable, dynamic and interactive visualizations named datalets. It includes a variety of visualisations, charts, geographical maps and 3D visualisations. Datalets can be generated and embedded in any web-page as well. SPOD exploits the DEEP architecture to support users within the platform in generating visualisations of Open artefacts, reuse and share them within discussions.",null,"GCH 2018 - Eurographics Workshop on Graphics and Cultural Heritage","Conference Paper","https:\/\/www.doi.org\/10.2312\/gch.20181350","2-s2.0-85087408098"],["2018-01-01","Delfina Malandrino","Network, Visualization, Analytics. A Tool Allowing Legal Scholars to Experimentally Investigate EU Case Law","Legal Informatics has recently witnessed a growing interest towards the insights offered by the intersection among Network Analysis (NA), visualization techniques and legal science research questions. Also thanks to several seminal works, the field is ready to tackle new challenges at a theoretical and application level. The first is to bring the network approach into \u201cgenuinely legal\u201d research questions. The second is to create tools allowing legal scholars without technical skills to exploit NA with two goals: (i) make experiments with NA and push new ideas both in legal and NA science; (ii) use NA and visualization in their daily activities (e.g., legal analysis and information retrieval). Against this backdrop, a truly interdisciplinary approach deeply involving legal experts\/scholars is needed. The paper presents an ongoing research project - EUCaseNet - dealing with these challenges and aiming to explore the potentialities of NA in supporting the study of EU case law.","Analytics | EU case law | Legal documents\u2019 relevance | Network analysis | On-line laboratory | Visualization","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Article","https:\/\/www.doi.org\/10.1007\/978-3-030-00178-0_37","2-s2.0-85064436759"],["2018-01-01","Delfina Malandrino","E-science and the law. Three experimental platforms for legal analytics","The paper presents three experimental platforms for legal analytics, online environments integrating heterogeneous computational heuristics, information processing, and visualization techniques to extract actionable knowledge from legal data. Our goal is to explore innovative approaches to issues spanning from information retrieval to the quantitative analysis of legal corpora or to the study of criminal organizations for research and investigative purposes. After a brief introduction to the e-science paradigm and to the role played in it by research platforms, we focus on visual analytics as a viable way to interact with legal data. We then present the tools, their main features and the results so far obtained. The paper ends up with some considerations about the computational turn of science and its role in promoting a much needed interdisciplinary and empirical evolution of legal research.","Analytical platforms | E-science | Legal visual analytics | Network analysis","Frontiers in Artificial Intelligence and Applications","Conference Paper","https:\/\/www.doi.org\/10.3233\/978-1-61499-935-5-71","2-s2.0-85059606177"],["2017-12-05","Delfina Malandrino","A Bio-Inspired Approach to Infer Functional Rules and Aesthetic Goals from Music Genre Styles","Computational Intelligence in Arts is a recent area of research. There is a growing interest in the application of these techniques in fields such as style recognition. Several works have been proposed for the recognition of styles for performers in which the improvisation often plays an important role. However, most of music genres, as classical music, are based on written music often composed according to specific rules. In this complex context, the style is the result of aesthetic goals, i.e. experience and preferences of the main composers in such a genre, and functional rules, i.e., the rules used to compose music according such a style. We propose a new approach for both recognition and automatic composition of music genre styles, which exploits a machine learning recognizer based on one-class support vector machines and neural networks, and a splicing composer. To assess the effectiveness of our system we performed several tests using a large corpus of 4-voice Bach's music. About the recognition, we show that our classifier is able to achieve an accuracy of 96.2%. With regard to the composition, we measured the capability of our system to capture both aesthetic goals, by collecting subjective perceptions from domain experts, and functional rules by computing the average percentage of classical forbidden exceptions that occur in the compositions produced.","Machine learning | Music style recognition | Splicing systems","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3168390.3168408","2-s2.0-85042094400"],["2017-12-01","Vittorio Scarano","A framework to design, develop, and evaluate immersive and collaborative serious games in cultural heritage","Video games and their design are complex in nature, given the variety of aspects and challenges to face and the different areas of expertise involved. Furthermore, serious games have an even tougher challenge, since the knowledge acquisition has the same importance and relevance as entertainment and pleasure for the players. Serious games in cultural heritage require additional effort to introduce immersivity and collaboration among players. This article introduces a framework, named FRACH, to conceive, design, and evaluate immersive and collaborative serious games in cultural heritage. In particular, FRACH provides a design framework with steps to follow during the whole process that is from the early design phase to the evaluation phase of a serious game. We assessed the efficacy of our framework, with a specific case study in cultural heritage, by implementing a section of a serious game named HippocraticaCivitasGame, where players were allowed to visit the thermae of the historical site of San Pietro a Corte and Palazzo Fruscione in the city of Salerno, Italy, and to solve a given puzzle. Results of the game evaluation showed that the game was effective in terms of knowledge acquisition, the participants enjoyed the game, were highly involved in the immersive experience, and, finally, positively rated the idea of using the game for educational learning in the field of cultural heritage.&copy; 2017 ACM 1556-4673\/2017\/12-ART4 &dollar;15.00.","Cultural heritage | Game evaluation | Game-based learning | Serious games","Journal on Computing and Cultural Heritage","Conference Paper","https:\/\/www.doi.org\/10.1145\/3064644","2-s2.0-85038576642"],["2017-12-01","Delfina Malandrino","Correction to: A computational approach for the experimental study of EU case law: analysis and implementation (Soc. Netw. Anal. Min, (2016), 6, (56), 10.1007\/s13278-016-0365-6)","The author would like to correct the errors in the publication of the original article.",null,"Social Network Analysis and Mining","Erratum","https:\/\/www.doi.org\/10.1007\/s13278-017-0477-7","2-s2.0-85037053844"],["2017-11-14","Delfina Malandrino","Music plagiarism at a glance: Metrics of similarity and visualizations","The plagiarism is a debated topic in different fields and in particular in music, given the huge amount of money that music is able to generate. Moreover, it is controversial aspect in the law's field given the subjectivity of the judges that have to pronounce on a suspicious case. Automatic detection of music plagiarism is fundamental to overcome these limits by representing an useful support for judges during their pronouncements and an important result to avoid musicians to spend more time in court than on composing and playing music.In this paper we address this issue by defining a new metric to discover pop music similarity and we study whether visualization can assist domain experts in judging suspicious cases. We describe a user study in which subjects performed different tasks on a song collection using different visual representations to investigate which one is best in terms of intuitiveness and accuracy. Results provided us with positive feedback about our choices and some useful suggestions for future directions.","Graph visualization | Information visualization | Melodic similarity | Music plagiarism | User evaluation","Proceedings - 2017 21st International Conference Information Visualisation, iV 2017","Conference Paper","https:\/\/www.doi.org\/10.1109\/iV.2017.49","2-s2.0-85040630465"],["2017-10-24","Delfina Malandrino","Privacy as a proxy for Green Web browsing: Methodology and experimentation","Nowadays, users\u2019 privacy on the Internet is highly at risk, due to the monetization by advertising companies that support many of the so-called \u201cfree\u201d services such as searching or social networking. In fact, several mechanisms are used to monitor users and build detailed profiles to tailor behavioral advertising. Given the increasing use of mobile devices and the increasing revenues from behavioral advertising, large advertising companies are present in this market as well. The increasing use of mobile devices for interacting with the Web and using mobile applications has been also drawing attention to their energy consumption. Several studies have addressed this issue from different point of views, i.e., hardware, software, as well as by analyzing the energy drained by different mobile applications. Our goal in this work is to measure the effectiveness of a methodology that exploits a hardware-based instrumentation to study whether privacy-preserving mechanisms are also able to efficiently reduce communication and computation overhead and, thus, save the battery life of mobile phones with the overall aim of a more sustainable Internet.","Information leakage | Measurement experiments | Mobile energy consumption | Privacy-enhancing technologies","Computer Networks","Article","https:\/\/www.doi.org\/10.1016\/j.comnet.2017.07.003","2-s2.0-85022029172"],["2017-10-01","Delfina Malandrino","The legal macroscope: Experimenting with visual legal analytics","This work presents Knowlex, a web application designed for visualization, exploration, and analysis of legal documents coming from different sources. Understanding the legal framework relating to a given issue often requires the analysis of complex legal corpora. When a legal professional or a citizen tries to understand how a given phenomenon is disciplined, his attention cannot be limited to a single source of law but has to be directed on the bigger picture resulting from all the legal sources related to the theme under investigation. Knowlex exploits data visualization to support this activity by means of interactive maps making sense out of heterogeneous documents (norms, case law, legal literature, etc.). Starting from a legislative measure (what we define as Root) given as input by the user, the application implements two visual analytics functionalities aiming to offer new insights on the legal corpus under investigation. The first one is an interactive node graph depicting relations and properties of the documents. The second one is a zoomable treemap showing the topics, the evolution, and the dimension of the legal literature settled over the years around the norm of interest. The article gives an overview of the research so far conducted presenting the results of a preliminary evaluation study aiming at evaluating the effectiveness of visualization in supporting legal activities as well as the effectiveness of Knowlex, the usability of the proposed system, and the overall user satisfaction when interacting with its applications.","Data mining | Evaluation | Legal informatics | Visual analytics | Visualization","Information Visualization","Article","https:\/\/www.doi.org\/10.1177\/1473871616681374","2-s2.0-85032214696"],["2017-09-19","Vittorio Scarano","DatalEt-ecosystem provider (DEEP): Scalable architecture for reusable, portable and user-friendly visualizations of open data","This paper presents the DatalEt-Ecosystem Provider (DEEP), an extensible, and scalable Edge-centric architecture to visualize Open Data, retrieved in real time from institutional open data portals. The aim is to engage citizens and stakeholders through reusable, portable and interactive visualizations, named datalets. The DEEP architecture exploits the increasing computing power and capacity of end-users devices, moving the computation to process and visualize data, from the central server, directly to the client-side ensuring data trustiness, privacy, scalability and dynamic data loading. DEEP and its datalets have been fully exploited, in the ROUTE-TO-PA, HORIZON 2020 funded project, by five public administrations across Europe as pilot projects. The project engages and involves citizens in creating, sharing and commenting existing visualizations of Open Data. DEEP is open source, its source code is fully available on GitHub, thus every single component can be reused by other projects.","Collaboration | E-partecipation | Open data | Social platform | Visualization of open data","Proceedings of the 7th International Conference for E-Democracy and Open Government, CeDEM 2017","Conference Paper","https:\/\/www.doi.org\/10.1109\/CeDEM.2017.14","2-s2.0-85032816516"],["2017-09-19","Vittorio Scarano","Technology-supported effective transparency around open data: A dialogue game analysis","Although open data of Public Administrations may enable nominal transparency for citizens (opening-up of data sets), achieving effective transparency requires meaning-making in dialogue. We describe an approach to analysing such dialogues based on Dialogue Game theory, applied to interaction corpora produced using SPOD (Social Platform for Open Data) developed within the ROUTE-TO-PA project. Users were able to engage in meaning-making dialogue games on\/around open data visualisations.","Dialogue games | Online community | Open data | Transparency","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3121283.3121293","2-s2.0-85033502834"],["2017-08-23","Delfina Malandrino","Fuzzy vectorial-based similarity detection of music plagiarism","Plagiarism, i.e., copying the work of others and trying to pass it off as one own, is a debated topic in different fields. In particular, in music field, the plagiarism is a controversial and debated phenomenon that has to do with the huge amount of money that music is able to generate. However, the existing mechanisms for plagiarism detection mainly apply superficial and brute-force string matching techniques. Such well-known metrics, widely used to discover similarities in text documents, cannot work well in discovering similarities in music compositions. Despite the wide-spread belief that few notes in common between two songs is enough to decide whether a plagiarism exists, the analysis of similarities is a very complex process. In this work, we provide novel perspectives in the field of automatic music plagiarism detection, and specifically, we propose an approach based on a fuzzy vectorial-based similarity. Given a suspicious melody, our approach envisions three steps: (1) its transformation in a vectorial representation, (2) retrieving of a list of similar melodies, (3) analysis and comparison with this subset of associated similar scores by using a fuzzy degree of similarity, that varies in a range between 0 for melodies that are fully musically different, and 1 for identical melodies. To assess the effectiveness of our system we performed tests on a large dataset of ascertained plagiarisms. Results show that it is able to reach an accuracy of 93%.",null,"IEEE International Conference on Fuzzy Systems","Conference Paper","https:\/\/www.doi.org\/10.1109\/FUZZ-IEEE.2017.8015655","2-s2.0-85030153212"],["2017-06-30","Vittorio Scarano","Work partitioning on parallel and distributed agent-based simulation","Work partitioning is a key challenge with ap- plications in many scientific and technological fields. The problem is very well studied with a rich literature on both distributed and parallel computing architectures. In this paper we deal with the work partitioning problem for parallel and distributed agent-based simulations which aims at (i) balancing the overall load distribution, (ii) minimizing, at the same time, the communication overhead due to agents' inter-dependencies. We introduce a classification taxonomy of work partitioning strategies and present a space-based work partitioning ap- proach, based on a Quad-tree data structure, which enables to: identify a good space partitioning (even when the distribution of agents on the fields is non-uniform) with a limited impact in terms of communication. Being a multi-objective problem, the results are difficult to compare and it is hard to foresee what can be the impact of one solution. For this reason we evaluate our strategy in a real context using a well-known behavior (the boids flocking model), on a distributed agent based simulation framework (D-MASON). The results show that our proposal provides a sensible impact on the performances of the system and scales in terms of the number of logical processors.","Agent-based simulations | D-MASON | Distributed Systems | Parallel Computing | Work partitioning","Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017","Conference Paper","https:\/\/www.doi.org\/10.1109\/IPDPSW.2017.87","2-s2.0-85028058800"],["2017-06-30","Biagio Cosenza","Autotuning Stencil Computations with Structural Ordinal Regression Learning","Stencil computations expose a large and complex space of equivalent implementations. These computations often rely on autotuning techniques, based on iterative compilation or machine learning (ML), to achieve high performance. Iterative compilation autotuning is a challenging and time-consuming task that may be unaffordable in many scenarios. Meanwhile, traditional ML autotuning approaches exploiting classification algorithms (such as neural networks and support vector machines) face difficulties in capturing all features of large search spaces. This paper proposes a new way of automatically tuning stencil computations based on structural learning. By organizing the training data in a set of partially-sorted samples (i.e., rankings), the problem is formulated as a ranking prediction model, which translates to an ordinal regression problem. Our approach can be coupled with an iterative compilation method or used as a standalone autotuner. We demonstrate its potential by comparing it with state-of-the-art iterative compilation methods on a set of nine stencil codes and by analyzing the quality of the obtained ranking in terms of Kendall rank correlation coefficients.","automatic tuning | stencil computations | structural SVMs","Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium, IPDPS 2017","Conference Paper","https:\/\/www.doi.org\/10.1109\/IPDPS.2017.102","2-s2.0-85027705131"],["2017-06-29","Vittorio Scarano","Increasing Public Value through Co-Creation of Open Knowledge","The aim of our research is to study how to increase Public Value through the collective participation, involving Public Administrations, stakeholders and citizens together. The Public Value for citizens is in the available and gained Knowledge. The paper models this concept by introducing a variant of the classic Data-Information-Knowledge pyramid, considering everything published as open and public. The paper introduces a social and iterative process designed for user appropriation, that includes the Knowledge and Data Co-Creation with the aim to generate public Open Knowledge. Users with process and technology appropriation can creatively follow the process in different ways. The paper concludes by introducing a brief preliminary scenario that exploits the process, platform and technology in the context of Cultural Heritage.",null,"2017 4th International Conference on eDemocracy and eGovernment, ICEDEG 2017","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICEDEG.2017.7962512","2-s2.0-85026835638"],["2017-06-28","Delfina Malandrino","A computational intelligence text-based detection system of music plagiarism","A debated controversies in recent years is the Plagiarism, specially in fields able to generate huge amount of money, such as the Music. However, the existing mechanisms to detect plagiarism, i.e., copying the work of others and trying to pass it off as one, mainly apply superficial and brute-force string matching techniques. Such well-known metrics, widely used to discover similarities in text documents, could not work well in discovering similarities in music compositions. This because many algorithms for text similarity are based on the well-known bag-of-word representation of text. Despite its popularity, bag-of-word representation ignores semantic of the words, and this is a weakness when the text is a representation of a piece of music, and so the semantic of the words (sequence of notes) is a fundamental aspect to detect similarities. In fact, despite the wide-spread belief that few notes in common between two songs is enough to decide whether a plagiarism exists, the analysis of similarities is a very complex process. In this work, we provide novel perspectives in the field of automatic music plagiarism detection, and specifically, we show how the advantages of a textual representation of music (simplicity, readability) can be exploited by a plagiarism detection system based on two computational intelligence modules: an unsupervised machine learning algorithm to retrieve similar melodies, and a fuzzy deep analyzer to discover plagiarisms. Given a dataset of melodies and a suspicious melody, our system envisions three steps: (1) its transformation in a text representation, (2) retrieving of a list of similar melodies by using a machine learning algorithm that, in an unsupervised way, learns representations of features with a fixed length starting from pieces of text with a variable length, (3) analysis and comparison with this subset of associated similar scores by using a fuzzy degree of similarity, that varies in a range between 0 for melodies that are fully musically different, and 1 for identical melodies. The effectiveness of our approach was assessed with tests performed on a large dataset of ascertained plagiarisms. Results show that it is able to reach an accuracy of 96.4%.",null,"2017 4th International Conference on Systems and Informatics, ICSAI 2017","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICSAI.2017.8248347","2-s2.0-85046674942"],["2017-06-28","Delfina Malandrino","BAND: A mobile-based collaboration system for composing and playing music","In recent years collaborative platforms offering support for learning and working have received considerable attention. One particular aspect often targeted by collaborative systems is teaching and learning. Both leaning and E-learning platforms are becoming widespread. Some collaborative systems have been developed for music teaching and learning. In this paper we describe BAND, a support system for composing and playing music through collaboration. The system has been developed for Android-based hardware, that is every participant uses an Android device (tablet or similar) to interact with other participants. The system can be used in two main scenarios: one targeted to teach music composition and another one targeted to the execution of music. In both scenarios there is a coordinator of the session (the teacher for music composition and the conductor for music execution) and several participants. The coordinator and the participant collaborate exploiting the facilities that BAND offers. In the music composition scenario BAND allows the development of a distributed composition under the guidance of the teacher, while in the music execution scenario BAND allows musician to rehearse under the guidance of the conductor. We have implemented BAND by using the Android platform and thus can be deployed on all Android devices, although some of the features, like score viewing, require a large enough display. We performed a preliminary evaluation with a sample of musicians by gathering positive feedback about the easiness of the tool when using and interacting with it, as well as interesting insights about possible improvements.",null,"2017 4th International Conference on Systems and Informatics, ICSAI 2017","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICSAI.2017.8248544","2-s2.0-85046620588"],["2017-06-12","Biagio Cosenza","Stencil autotuning with ordinal regression","The increasing performance of today's computer architecture comes with an unprecedented augment of hardware complexity. Unfortunately this results in difficult-to-tune software and consequentially in a gap between the potential peak performance and the actual performance. Automatic tuning is an emerging approach that assists the programmer in managing this complexity. State-of-the-art autotuners are limited, though: they either require long tuning times, e.g., due to iterative searches, or cannot tackle the complexity of the problem due to the limitation of the supervised machine learning (ML) methodologies used. In particular, traditional ML autotuning approaches exploiting classification algorithms (such as neural networks and support vector machines) face difficulties in capturing all features of large search spaces. We propose a new way of performing automatic tuning based on structural learning: the tuning problem is formulated as a version ranking prediction modeling and solved using ordinal regression. We demonstrate its potential on a well-known autotuning problem: stencil computations. We compare state-of-the-art iterative compilation methods with our ordinal regression approach and analyze the quality of the obtained ranking in terms of Kendall rank correlation coefficients.","Automatic tuning | Ordinal regression | Stencil computations | Support vector machines","Proceedings of the 20th International Workshop on Software and Compilers for Embedded Systems, SCOPES 2017","Conference Paper","https:\/\/www.doi.org\/10.1145\/3078659.3078664","2-s2.0-85029668832"],["2017-06-07","Vittorio Scarano","Engaging Citizens with a Social Platform for Open Data","Open Data are valuable initiatives in favour of transparency. Public administrations are increasing the availability of datasets for citizens, associations, innovators and other stakeholders, by releasing their data with open licenses. Open initiatives are achieving less success than expected, mainly due to the lack of engagement. There is a growing demand for approaches to actively engage citizens in exploiting Open Data. This paper introduces SPOD, a Social Platform for Open Data, which aims to engage citizens, local associations and organizations in forming communities of interests, stimulating the interpretation of Open Data and exploiting their use in Data-driven discussions, something not well-supported on traditional social networks. Social collaboration is the key aspect to increase the public value, where citizens participate in the discussions, co-create knowledge and data. The paper describes the engagement of four communities of citizens, which contributed to the public value by discussing topics in the context of Cultural Heritage, generating information from existing and co-created open datasets, by using SPOD.","Case study | E-participation | Open data | Open government","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3085228.3085302","2-s2.0-85023619143"],["2017-06-01","Delfina Malandrino","By investigation, I mean computation: A framework to investigate the societal dimension of crime","The computational analysis of the societal dimension of crime has aroused an increasing interest in recent years. Data mining, social network analysis (SNA), and visualization techniques are offering promising opportunities to the scientific and investigative study of criminal organizations. In spite of that, the spread of technological innovation faces serious difficulties due to the concurrence of different factors: the absence of user friendly crime analysis tools, the lack of technical skills of investigators (public prosecutors, police officers), two factors that, when combined with the pressure of daily routine, often result into a resistance to change. In this work we present an ongoing research project aiming to foster the potentialities of SNA and computation into criminal investigation. We define an holistic methodology that combines document-enhancement, social network analysis, and visualization techniques to support public prosecutors and criminal investigation departments in exploring the societal dimension of criminal groups. This approach has been deployed in a computational framework, CrimeMiner, validated with a case study based on data coming from real criminal investigations.","Computational social science | Criminal investigations | Legal informatics | Social network analysis | Visual analytics","Trends in Organized Crime","Article","https:\/\/www.doi.org\/10.1007\/s12117-016-9284-1","2-s2.0-85020643631"],["2017-04-01","Delfina Malandrino","Splicing music composition","Splicing systems were introduced by Tom Head (1987) as a formal model of a recombination process between DNA molecules. The existing literature on splicing systems mainly focuses on the computational power of these systems and on the properties of the generated languages; very few applications based on splicing systems have been introduced. In this paper we show a novel application of splicing systems: we use them to build an automatic music composer. The proposed system can be seen also as a new valid bio-inspired strategy for automatic music composition. It is tailored on 4-voice chorale-like music. We define a new music representation based on words, which extends an earlier splicing approach and uses additional music information to produce music in a quick and effective way. A performance study shows that our composer outperforms other meta-heuristics by producing better music according to a specific measure of quality evaluation. Moreover, the composition is carried out in a shorter time and using less memory with respect to a previous approach.","Automatic music composition | Music formal model | Splicing systems","Information Sciences","Article","https:\/\/www.doi.org\/10.1016\/j.ins.2017.01.004","2-s2.0-85008334995"],["2017-04-01","Delfina Malandrino","Understanding the structure of musical compositions: Is visualization an effective approach?","Experienced musicians have the ability to understand the structural elements of music compositions. Such an ability is built over time through the study of music theory, the understanding of rules that guide the composition of music, and countless hours of practice. The learning process is hard, especially for classical music, where the rigidity of the music structures and styles requires great effort to understand, assimilate, and then master the learned notions. In particular, we focused our attention on a specific type of music compositions, namely, music in chorale style (four-voice music). Composing such type of music is often perceived as a difficult task because of the rules the composer has to adhere to. In this article, we propose a visualization technique that can help people lacking a strong knowledge of music theory. The technique exploits graphic elements to draw the attention on the possible errors in the composition. We then developed an interactive system, named VisualMelody, that employs the proposed visualization technique to facilitate the understanding of the structure of music compositions. The aim is to allow people to make four-voice music composition in a quick and effective way, that is, avoiding errors, as dictated by classical music theory rules. We have involved 40 people in testing VisualMelody in order to analyze its effectiveness, its usability, and the overall user satisfaction. We partitioned the people involved in the evaluation study into two groups evenly splitting the musical expertise. Then, we had one group use VisualMelody without the visualization facilities and the other using the tool enhanced with our visualization. On average, people in the group that used our visualization were 60% faster and produced music with less errors.","Classical music | Melodic analysis | User evaluation | Visualization","Information Visualization","Review","https:\/\/www.doi.org\/10.1177\/1473871616655468","2-s2.0-85018271439"],["2017-04-01","Gennaro Cordasco","EMOTHAW: A Novel Database for Emotional State Recognition from Handwriting and Drawing","The detection of negative emotions through daily activities such as writing and drawing is useful for promoting wellbeing. The spread of human-machine interfaces such as tablets makes the collection of handwriting and drawing samples easier. In this context, we present a first publicly available database which relates emotional states to handwriting and drawing, that we call EMOTHAW (EMOTion recognition from HAndWriting and draWing). This database includes samples of 129 participants whose emotional states, namely anxiety, depression, and stress, are assessed by the Depression-Anxiety-Stress Scales (DASS) questionnaire. Seven tasks are recorded through a digitizing tablet: pentagons and house drawing, words copied in handprint, circles and clock drawing, and one sentence copied in cursive writing. Records consist in pen positions, on-paper and in-air, time stamp, pressure, pen azimuth, and altitude. We report our analysis on this database. From collected data, we first compute measurements related to timing and ductus. We compute separate measurements according to the position of the writing device: on paper or in-air. We analyze and classify this set of measurements (referred to as features) using a random forest approach. This latter is a machine learning method [1], based on an ensemble of decision trees, which includes a feature ranking process. We use this ranking process to identify the features which best reveal a targeted emotional state. We then build random forest classifiers associated with each emotional state. We provide accuracy, sensitivity, and specificity evaluation measures obtained from cross-validation experiments. Our results show that anxiety and stress recognition perform better than depression recognition.","Affective database | anxiety | depression | depression-anxiety-stress scales (DASS) | emotional state | handwriting | random forests | stress","IEEE Transactions on Human-Machine Systems","Article","https:\/\/www.doi.org\/10.1109\/THMS.2016.2635441","2-s2.0-85010000311"],["2017-02-05","Biagio Cosenza","Static optimization in PHP 7","PHP is a dynamically typed programming language commonly used for the server-side implementation of web applications. Approachability and ease of deployment have made PHP one of the most widely used scripting languages for the web, powering important web applications such as WordPress, Wikipedia, and Facebook. PHP's highly dynamic nature, while providing useful language features, also makes it hard to optimize statically. This paper reports on the implementation of purely static bytecode optimizations for PHP 7, the last major version of PHP. We discuss the challenge of integrating classical compiler optimizations, which have been developed in the context of statically-typed languages, into a programming language that is dynamically and weakly typed, and supports a plethora of dynamic language features. Based on a careful analysis of language semantics, we adapt static single assignment (SSA) form for use in PHP. Combined with type inference, this allows type-based specialization of instructions, as well as the application of various classical SSA-enabled compiler optimizations such as constant propagation or dead code elimination. We evaluate the impact of the proposed static optimizations on a wide collection of programs, including micro-benchmarks, libraries and web frameworks. Despite the dynamic nature of PHP, our approach achieves an average speedup of 50% on microbenchmarks, 13% on computationally intensive libraries, as well as 1.1% (MediaWiki) and 3.5% (WordPress) on web applications.","PHP | SSA form | Static optimization","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/3033019.3033026","2-s2.0-85015180857"],["2017-02-01","Gennaro Cordasco","Multi-level dynamo and opinion spreading","We consider the following multi-level opinion spreading model on networks. Initially, each node gets a weight, from the set {0,.,k-1}, which measures the individual conviction of a new idea or product. Then, by proceeding in rounds, each node updates its weight according to those of its neighbours. We study k-dynamos that are initial assignments of weights leading each node to get the value k-1-e.g. unanimous maximum level of acceptance-within a given number of rounds; the goal is to minimize the sum of the initial weights of the nodes. We determine lower bounds on the sum of the initial weights under the irreversible simple majority rules, where a node increases its weight if and only if the majority of its neighbours have a weight that is higher than its own. We study the relations among 2-dynamos and k-dynamos, with and without a bound on the number of rounds needed to reach the desired all-(k-1) configuration. Moreover, we provide constructive tight upper bounds for some classes of regular topologies: rings, tori and cliques.",null,"Mathematical Structures in Computer Science","Article","https:\/\/www.doi.org\/10.1017\/S0960129515000080","2-s2.0-84929017990"],["2017-02-01","Gennaro Cordasco","Online region computations for Euler diagrams with relaxed drawing conventions","Euler diagrams are an accessible and effective visualisation of data involving simple set-theoretic relationships. Efficient algorithms to quickly compute the abstract regions of an Euler diagram upon curve addition and removal have previously been developed (the single marked point approach, SMPA), but a strict set of drawing conventions (called well-formedness conditions) were enforced, meaning that some abstract diagrams are not representable as concrete diagrams. We present a new methodology (the multiple marked point approach, MMPA) enabling online region computation for Euler diagrams under the relaxation of the drawing convention that zones must be connected regions. Furthermore, we indicate how to extend the methods to deal with the relaxation of any of the drawing conventions, with the use of concurrent line segments case being of particular importance. We provide complexity analysis and compare the MMPA with the SMPA. We show that these methods are theoretically no worse than other comparators, whilst our methods apply to any case, and are likely to be faster in practise due to their online nature. The machinery developed for the concurrency case could be of use in Euler diagram drawing techniques (in the context of the Euler Graph), and in computer graphics (e.g. the development of an advanced variation of a winged edge data structure that deals with concurrency). The algorithms are presented for generic curves; specialisations such as utilising fixed geometric shapes for curves may occur in applications which can enhance capabilities for fast computations of the algorithms\u2019 input structures. We provide an implementation of these algorithms, utilising ellipses, and provide time-based experimental data for benchmarking purposes.","Euler diagrams | Interactive Diagram Construction | On-line algorithms | Region computation","Journal of Visual Languages and Computing","Article","https:\/\/www.doi.org\/10.1016\/j.jvlc.2016.10.006","2-s2.0-85006932818"],["2017-02-01","Gennaro Cordasco","Editorial",null,null,"International Journal on Artificial Intelligence Tools","Review","https:\/\/www.doi.org\/10.1142\/S0218213017020018","2-s2.0-85013635256"],["2017-01-01","Vittorio Scarano","Governance, transparency and the collaborative design of open data collaboration platforms: understanding barriers, options, and needs","Developments in open data have prompted a range of proposals and innovations in the domain of governance and public administration. Within the democratic tradition, transparency is seen as a fundamental element of democratic governance. While the use of open government data has the potential to enhance transparency and trust in government, realising any ideal of transparent democratic governance implies responding to a range of sociotechnical design challenges. In order to address these design challenges it is essential to adopt an interdisciplinary and stakeholder-engaged approach to research and innovation. In the current study, we describe a contextualist approach to the design of an open data collaboration platform in the context of an EU innovation project, focused on enhancing transparency and collaboration between citizens and public administrators through the use of open government data. We report on a collective intelligence scenario-based design process that has shaped the development of open data platform requirements and ongoing system engineering and evaluation work. Stakeholders across five pilot sites identified barriers to accessing, understanding, and using open data, and options to overcome these barriers across three broad categories: government and organisational issues; technical, data, and resource issues; and training and engagement issues. Stakeholders also expressed a broad variety of user needs across three domains: information needs; social-collaborative needs; and understandability, usability, and decision-making needs. Similarities and differences across sites are highlighted along with implications for open data platform design.","Citizens | Collaboration | Governance | Open data | Transparency","Public Administration and Information Technology","Book Chapter","https:\/\/www.doi.org\/10.1007\/978-3-319-63743-3_12","2-s2.0-85060222457"],["2017-01-01","Carmine Spagnuolo","D-MASON on the cloud: An experience with amazon web services","D-Mason framework is a parallel version of the Mason library for writing and running Agent-based simulations \u2013 a class of models that, by simulating the behavior of multiple agents, aims to emulate and\/or predict complex phenomena. D-Mason has been conceived to harness the amount of unused computing power available in common installations like educational laboratory. Then the focus moved to dedicated installation, such as massively parallel machines or supercomputing centers. In this paper, D-Mason takes another step forward and now it canbeusedonacloudenvironment. The goal of the paper is twofold. Firstly, we are going to present D-Mason on the cloud \u2013 a D-Mason extension that, starting from an IaaS (Infrastructure as a Service) abstraction, and exploiting Amazon Web Services and StarCluster, provides a SIMulation-as-a-Service (SIMaaS) abstraction that simplifies the process of setting up and running distributed simulations in the cloud. Secondly, an additional goal of the paper is to assess computational and economic efficiency of running distributed multi-agent simulations on the Amazon Web Services EC2 instances. The computational speed and costs of an EC2 cluster will be compared against an on-site HPC cluster.","agent-based simulation models | Cloud computing | D-MASON | Distributed systems | High performance computing | Parallel computing","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-58943-5_26","2-s2.0-85020380521"],["2017-01-01","Delfina Malandrino","A kind of bio-inspired learning of music style","In the field of Computer Music, computational intelligence approaches are very relevant for music information retrieval applications. A challenging task in this area is the automatic recognition of musical styles. The style of a music performer is the result of the combination of several factors such as experience, personality, preferences, especially in music genres where the improvisation plays an important role. In this paper we propose a new approach for both recognition and automatic composition of music of a specific performer\u2019s style. Such a system exploits: (1) a one-class machine learning classifier to learn a specific music performer\u2019s style, (2) a music splicing system to compose melodic lines in the learned style, and (3) a LSTM network to predict patterns coherent with the learned style and used to guide the splicing system during the composition. To assess the effectiveness of our system we performed several tests using transcriptions of solos of popular Jazz musicians. Specifically, with regard to the recognition process, tests were performed to analyze the capability of the system to recognize a style. Also, we show that performances of our classifier are comparable to that of traditional two-class SVM, and that it is able to achieve an accuracy of 97%. With regard to the composition process, tests were performed to verify whether the produced melodies were able to catch the most significant music aspects of the learned style.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-55750-2_7","2-s2.0-85017542441"],["2017-01-01","Delfina Malandrino","Agents shaping networks shaping agents: Integrating social network analysis and agent-based modeling in computational crime research","The paper presents a recent development of an interdisciplinary research exploring innovative computational approaches to the scientific study of criminal behavior. The attention is focused on an attempt to combine social network analysis and agent-based modelling into CrimeMiner, an experimental framework that seamlessly integrates document-enhancement, visualization and network analysis techniques to support the study of criminal organizations. Our goal is both methodological and scientific. We are exploring how the synergy between ABM and SNA can support a deeper and more empirically grounded understanding of the complex dynamics taking place within criminal organizations between the individual\/behavioral and social\/structural level.","Agent-based modeling | Computational crime analysis | Social network analysis","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-65340-2_2","2-s2.0-85028967179"],["2017-01-01","Vittorio Scarano","Fostering citizens\u2019 participation and transparency with social tools and personalization","In this paper we present innovative solutions to the problem of transparency in Public Administrations (PAs) by opening up public data and services so that citizens participation is facilitated and encouraged with a Social Platform and a personalized user-friendly Transparency-Enhancing Toolset.",null,"Public Administration and Information Technology","Book Chapter","https:\/\/www.doi.org\/10.1007\/978-3-319-63743-3_8","2-s2.0-85060198441"],["2017-01-01","Gennaro Cordasco","Space-optimal proportion consensus with population protocols","Population protocols provide a distributed computing model in which a set of finite-state identical agents cooperate through random interactions, between neighbors in the interaction graph, to collectively carry out a computation in a distributed setting. Population protocols have become very popular in various research areas, such as distributed computing, sensor or social networks, as well as chemistry and biology. A central task in this model is majority computation, in which agents need to reach an agreement on the leading one of two possible initial opinions. In this paper we consider a generalization of the majority problem, named proportion consensus, which asks for an agreement on the proportion of one opinion, between two possible views (say A or B). The objective is to reach a configuration where all the agents agree on a range \u03b3A \u2286 [0,1] which contains the value of the fraction \u03c1A of agents that started with view A; the goal is to get the size of \u03b3A as small as possible while also minimizing the number of states adopted by agents. We provide a lower bound on the trade-off between precision \u03f5 (the size of \u03b3A) and the number of states required by any population protocol that solves the proportion consensus problem. In particular, we show that in any population protocol that solves the proportion consensus problem with precision \u03f5, any agent must have at least \u23082\/\u03f5\u2309 states. We also provide a population protocol that exactly solves the proportion consensus problem with precision \u03f5 and 6\u23081\/(2\u03f5)\u2309 - 1 states. We show that in case of an arbitrary interaction graph our protocol requires O(n6\/\u03f5)interactions (which corresponds to the number of rounds in the sequential communication model) on any network with n agents. On complete interaction networks, the expected number of required interactions is O(n2 log n). Using the random matching communication model, the expected number of rounds, required to reach a consensus, decreases to O(\u0394 n4\/\u03f5) in case of arbitrary interaction networks (where \u0394 denotes the maximum degree among the agents in the network) and O(n log n) for complete networks.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-69084-1_28","2-s2.0-85032666758"],["2017-01-01","Delfina Malandrino","Splicing-inspired recognition and composition of musical collectives styles","Computer music is an emerging area for the application of computational techniques inspired by information processing in Nature. A challenging task in this area is the automatic recognition of musical styles. The style of a musician is the result of the combination of several factors such as experience, personality, preferences. In the last years, several works have been proposed for the recognition of styles for soloists performers, where the improvisation often plays an important role. The evolution of this problem, that is the recognition of multiple performers\u2019 style that collaborate over time to perform, record or compose music, know as Musical collective, presents many more difficulties, due to the simultaneous presence of various performers, mutually conditionable. In this paper, we propose a new approach for both recognition and automatic composition of styles for musical collectives. Specifically, our system exploits a machine learning recognizer, based on one-class support vector machines and neural networks for style recognition, and a splicing composer, for music composition (in the style of the whole collective). To assess the effectiveness of our system we performed several tests using transcriptions of popular jazz bands. With regard to the recognition, we show that our classifier is able to achieve an accuracy of 97.7 %. With regard to the composition, we measured the quality of the generated compositions by collecting subjective perceptions from domain experts.","Composition of musical collectives styles | Neural network | Splicing-inspired recognition | Support vector machine","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-71069-3_17","2-s2.0-85041299900"],["2017-01-01","Gennaro Cordasco","Effects of gender and luminance backgrounds on the recognition of neutral facial expressions","In this study we challenged the universal view of facial emotion perception evaluating the effects of gender and different luminance backgrounds on the recognition accuracy of neutral facial expressions. To this aim, we applied the Ekman standard paradigm for assessing the human ability to decode neutral facial expressions reproduced on black, white and grey backgrounds and portrayed by male and female actors. The exploited stimuli consisted of 10 different neutral faces (5 females) selected from the Dutch Radboud database (Langner et al. Cogn Emot, 2010 [21]) where luminance backgrounds were changed in black, grey and white. The resulted 30 stimuli were assessed by 31 subjects (16 females) who were asked to tag each of them with one of the six primary emotion labels. The data analysis demonstrates a significant gender effect where neutral male faces are less accurately decoded than females ones. On the other hand, no effects of luminance backgrounds have been identified.","Emotional recognition | Emotions | Gender effects | Neutral facial expressions | Socio-cultural influence","Smart Innovation, Systems and Technologies","Book Chapter","https:\/\/www.doi.org\/10.1007\/978-3-319-56904-8_30","2-s2.0-85029187048"],["2016-12-01","Gennaro Cordasco","On finding small sets that influence large networks","We consider the problem of selecting a minimum size subset of nodes in a network that allows to activate all the nodes of the network. We present a fast and simple algorithm that, in real-life networks, produces solutions that outperform the ones obtained by using the best algorithms in the literature. We also investigate the theoretical performances of our algorithm and give proofs of optimality for some classes of graphs. From an experimental perspective, experiments also show that the performance of the algorithms correlates with the modularity of the analyzed network. Moreover, the more the influence among communities is hard to propagate, the less the performances of the algorithms differ. On the other hand, when the network allows some propagation of influence between different communities, the gap between the solutions returned by the proposed algorithm and by the previous algorithms in the literature increases.","Minimum target set | Social networks | Spread of influence | Viral marketing","Social Network Analysis and Mining","Article","https:\/\/www.doi.org\/10.1007\/s13278-016-0408-z","2-s2.0-84991327461"],["2016-12-01","Delfina Malandrino","A computational approach for the experimental study of EU case law: analysis and implementation","In recent years, the encounter between network analysis (NA) and Law has issued new challenges both on a scientific and application level. If, on the one hand, it is fostering new computational-inspired approaches to visualize, retrieve, manipulate and analyze legal information, on the other hand, it is inspiring the creation of innovative tools allowing legal scholars without technical skills to start dealing with NA and visual analytics on their own. This paper presents an ongoing research project aiming to explore how approaches and techniques at the boundaries between Network analysis, Legal informatics and Visualization can help shedding new light into legal matters. The attention is focused, on EuCaseNet, an online toolkit allowing legal scholars to apply NA and visual analytics techniques to the entire corpus of EU case law.","Computational legal studies | Legal informatics | Network analysis | Visual analytics","Social Network Analysis and Mining","Article","https:\/\/www.doi.org\/10.1007\/s13278-016-0365-6","2-s2.0-84982792202"],["2016-11-01","Vittorio Scarano","Introducing a clustering step in a consensus approach for the scoring of protein-protein docking models","Correctly scoring protein-protein docking models to single out native-like ones is an open challenge. It is also an object of assessment in CAPRI (Critical Assessment of PRedicted Interactions), the community-wide blind docking experiment. We introduced in the field the first pure consensus method, CONSRANK, which ranks models based on their ability to match the most conserved contacts in the ensemble they belong to. In CAPRI, scorers are asked to evaluate a set of available models and select the top ten ones, based on their own scoring approach. Scorers' performance is ranked based on the number of targets\/interfaces for which they could provide at least one correct solution. In such terms, blind testing in CAPRI Round 30 (a joint prediction round with CASP11) has shown that critical cases for CONSRANK are represented by targets showing multiple interfaces or for which only a very small number of correct solutions are available. To address these challenging cases, CONSRANK has now been modified to include a contact-based clustering of the models as a preliminary step of the scoring process. We used an agglomerative hierarchical clustering based on the number of common inter-residue contacts within the models. Two criteria, with different thresholds, were explored in the cluster generation, setting either the number of common contacts or of total clusters. For each clustering approach, after selecting the top (most populated) ten clusters, CONSRANK was run on these clusters and the top-ranked model for each cluster was selected, in the limit of 10 models per target. We have applied our modified scoring approach, Clust-CONSRANK, to SCORE-SET, a set of CAPRI scoring models made recently available by CAPRI assessors, and to the subset of homodimeric targets in CAPRI Round 30 for which CONSRANK failed to include a correct solution within the ten selected models. Results show that, for the challenging cases, the clustering step typically enriches the ten top ranked models in native-like solutions. The best performing clustering approaches we tested indeed lead to more than double the number of cases for which at least one correct solution can be included within the top ten ranked models.",null,"PLoS ONE","Article","https:\/\/www.doi.org\/10.1371\/journal.pone.0166460","2-s2.0-84995677089"],["2016-09-01","Vittorio Scarano","Energy consumption and privacy in mobile Web browsing: Individual issues and connected solutions","Providing mechanisms to improve energy efficiency of mobile devices is, in the past few years, one of the important objectives in the field of green computing and energy savings. Several studies have addressed this issue from different point of views, i.e., hardware, software, as well as by analyzing the energy drained by different mobile applications. On the other hand, the energy consumption of Web browsing activities has been poorly addressed, given the lack of analysis about users\u2019 real browsing sessions. In this paper we explore how energy savings in mobile devices can be effectively tackled by switching on\/off filtering techniques offered by a privacy-enhancing technology. We present first, results about a survey that we conducted to understand the beliefs, attitudes, behaviors, and expectations of mobile users towards privacy and energy issues, and their behavioral intention on what kind of countermeasures adopt to reduce their privacy leakage. Then, we present a tool, mNoTrace, that allows to protect privacy during Web Navigation and prove, by an experimental study, that, by helping users in protecting their privacy, mNoTrace also achieves a significant reduction in terms of communication and computation overhead and thus battery consumption. Conclusions, remarks and lessons learned on our experimental methodology, that employs hardware-based instrumentation, real workloads, and testing on real sites, will conclude the paper.","Mobile Web browsing | Privacy-preserving technologies | Smartphone energy consumption","Sustainable Computing: Informatics and Systems","Article","https:\/\/www.doi.org\/10.1016\/j.suscom.2016.02.003","2-s2.0-84961784372"],["2016-08-31","Vittorio Scarano","Support citizens in visualising open data","This paper contributes in the field of Open Data and their visualisations, trying to reduce the gap between the public institutions (who publish Open Data) and citizens, providing awareness of data quality and supporting them during the process of chart creation. Proposed solution syntactically analyses the dataset's values to infer its data types and continually shows a list of chart visualisations compatible with the selected dataset and its fields. Instead to start with a catalogue containing all available charts, the system reduces the space of charts proposing any time only those that are compatible. In addition, a well-known barrier in the use of Open Data is the poor quality of the available datasets, thus, this paper proposes two quality indexes to provide at glance awareness of the dataset quality. This provides a quantitative measurement to dataset publishers (e.g., public institutions), who can evaluate the data quality, and also the citizens, who can ask for better open datasets providing a reason for such request.","Chart visualisations | Data type inferencing | E-Government | Open Data","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV.2016.45","2-s2.0-84989892326"],["2016-08-31","Delfina Malandrino","Visualization of music plagiarism: Analysis and evaluation","Nowadays plagiarism is an interesting and debated topic in different fields. In music, the plagiarism is a very common phenomenon which touch the vast amounts of money that music melodies are able to generate in today's pop music market. In a music composition, the melody is assumed to be the most significant factor in a court's decision about whether a new music composition is an illegitimate version of a pre-existing composition. Despite the wide-spread belief that there is a fixed and trivial number of corresponding notes between two melodies, the similarity analysis is a very complex process. In this paper we address the plagiarism in pop music, and specifically, we study whether visualization can facilitate the task of discovering melodic similarities among musical songs. To investigate this, we defined three representations to show the melodic relations among songs. We performed a user study in which subjects performed different tasks on a song collection using these representations to investigate which one is best in terms of intuitiveness and accuracy. Results of the study provided us with positive feedback as well as further directions to explore.","Graph Visualization | Infomation Visualization | Melodic Similarity | Music Plagiarism | User Evaluation","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV.2016.56","2-s2.0-84989809409"],["2016-07-25","Gennaro Cordasco","Brief announcement: Active information spread in networks","Identifying the most influential spreaders is an important issue for the study of the dynamics of information diffusion in complex networks. In this paper we analyze the following spreading model. Initially, a few nodes know a piece of information and are active spreaders of it. At subsequent rounds, spreaders communicate the information to their neighbors. Upon receiving the information, a node becomes aware of it but does not necessarily become a spreader; it starts spreading only if it gets the information from a sufficiently large number of its neighbors. We study the problem of choosing a small set of initial spreaders so as to maximize the final number of nodes that become aware of the information.","Social Networks | Spread of Influence | Viral Marketing","Proceedings of the Annual ACM Symposium on Principles of Distributed Computing","Conference Paper","https:\/\/www.doi.org\/10.1145\/2933057.2933069","2-s2.0-84984674652"],["2016-07-18","Carmine Spagnuolo","Toward the new version of D-MASON: Efficiency, effectiveness and correctness in parallel and distributed agent-based simulations","Agent-Based Models (ABMs) denote a class of models which, by simulating the behavior of multiple agents (i.e., independent actions, interactions and adaptation), aim to emulate and\/or predict complex phenomena. One of the general features of ABM simulations is their experimental capacity, that requires a viable and reliable infrastructure to interact with a running simulation, monitoring its behaviour, as it proceeds, and applying changes to the configurations at run time, in order to study \u00abwhat if\u00bb scenarios. A common approach for improving the efficiency and the effectiveness of ABMs as a research tool is to distribute the overall computation on a number of machines, which makes the design of the simulation model particularly challenging. D-MASON framework is a distributed version of the MASON library for writing and running Agent-based simulations. We briefly present D-MASON architecture and functionalities. Then we presents its novel features: a distributed network field and a novel communication layer dedicated to massive parallel machines. The main contribution of the paper is in providing a memory consistency modeling, where the previous state of theagent is made available (consistently) for all other agents (even the one on other processors) and this is obtained by exploiting the Java Method Handler mechanism. Full documentation, additional tutorials and other material can be found at www.dmason.org where the framework can be downloaded.","Agent-based simulations | D-MASON | Distributed Systems | High Performance Computing | MASON | Parallel Computing","Proceedings - 2016 IEEE 30th International Parallel and Distributed Processing Symposium, IPDPS 2016","Conference Paper","https:\/\/www.doi.org\/10.1109\/IPDPSW.2016.52","2-s2.0-84991577930"],["2016-07-11","Vittorio Scarano","SambVca 2. A Web Tool for Analyzing Catalytic Pockets with Topographic Steric Maps","Developing more efficient catalysts remains one of the primary targets of organometallic chemists. To accelerate reaching this goal, effective molecular descriptors and visualization tools can represent a remarkable aid. Here, we present a Web application for analyzing the catalytic pocket of metal complexes using topographic steric maps as a general and unbiased descriptor that is suitable for every class of catalysts. To show the broad applicability of our approach, we first compared the steric map of a series of transition metal complexes presenting popular mono-, di-, and tetracoordinated ligands and three classic zirconocenes. This comparative analysis highlighted similarities and differences between totally unrelated ligands. Then, we focused on a recently developed Fe(II) catalyst that is active in the asymmetric transfer hydrogenation of ketones and imines. Finally, we expand the scope of these tools to rationalize the inversion of enantioselectivity in enzymatic catalysis, achieved by point mutation of three amino acids of mononuclear p-hydroxymandelate synthase.",null,"Organometallics","Article","https:\/\/www.doi.org\/10.1021\/acs.organomet.6b00371","2-s2.0-84978841967"],["2016-07-02","Carmine Spagnuolo","From desktop to large-scale model exploration with swift\/T","As high-performance computing resources have become increasingly available, new modes of computational processing and experimentation have become possible. This tutorial presents the Extreme-scale Model Exploration with Swift\/T (EMEWS) framework for combining existing capabilities for model exploration approaches (e.g., model calibration, metaheuristics, data assimilation) and simulations (or any \"black box\" application code) with the Swift\/T parallel scripting language to run scientific workflows on a variety of computing resources, from desktop to academic clusters to Top 500 level supercomputers. We will present a number of use-cases, starting with a simple agent-based model parameter sweep, and ending with a complex adaptive parameter space exploration workflow coordinating ensembles of distributed simulations. The use-cases are published on a public repository for interested parties to download and run on their own.",null,"Proceedings - Winter Simulation Conference","Conference Paper","https:\/\/www.doi.org\/10.1109\/WSC.2016.7822090","2-s2.0-85014201500"],["2016-07-02","Vittorio Scarano","Filter large-scale engine data using apache spark","This paper introduces a minimum viable software product to filter large datasets of engine data recorded during laboratory experiments of combustion engines. The aim is to support analysts in the identification and analysis of specific physical phenomenon within hours of recorded engine experimental data. Specifically, the tool has been designed considering the use case of identifying Low Speed Pre-Ignition events. This work describes the tool's graphical user interface and its scalable architecture based on mainstream web and big-data technologies as well as the practical application to pre-ignition events identification. The paper provides details on the architecture's performance, providing evidence of its scalability by increasing the number of available computing workers.","Big-data Technologies | Combustion Engine Experimental Data | Data Exploration | Data Visualisation","IEEE International Conference on Industrial Informatics (INDIN)","Conference Paper","https:\/\/www.doi.org\/10.1109\/INDIN.2016.7819368","2-s2.0-85012908850"],["2016-06-07","Delfina Malandrino","Natural User interfaces to support and enhance real-time music performance","Today's technology is redefining the way individuals can work, communicate, share experiences, constructively debate, and actively participate to any aspect of the daily life, ranging from business to education, from political and intellectual to social, and so on. Enabling access to technology by any individual, reducing obstacles, avoiding discrimination, and making the overall experience easier and enjoyable is an important objective of both research and industry. Exploiting natural user interfaces, initially conceived for the game market, it is possible to enhance the traditional modalities of interaction when accessing to technology, build new forms of interactions by transporting users in a virtual dimension, but that fully reects the reality, and finally, improve the overall perceived experience. The increasing popularity of these innovative interfaces involved their adoption in other fields, including Computer Music. This paper presents MarcoSmiles, a system designed to allow individuals to perform music in a easy, innovative, and personalized way. The idea is to design new interaction modalities during music performances by using hands without the support of a real musical instrument. We exploited Artificial Neural Networks to customize the virtual musical instrument, to provide the information for the mapping of the hands configurations into musical notes and, finally, to train and test these configurations. We studied the behavior of the system and its effcacy in terms of learning capabilities. We also report results about a preliminary evaluation study aimed at analyze general users' perceptions about the system and their overall satisfaction.","Evaluation | Music performance | Natural user interfaces | Neural networks","Proceedings of the Workshop on Advanced Visual Interfaces AVI","Conference Paper","https:\/\/www.doi.org\/10.1145\/2909132.2909249","2-s2.0-84977100951"],["2016-04-01","Vittorio Scarano","Visual Exploration System in an Industrial Context","This paper describes ExploraTool, a new interactive tool to visually explore data from multiple repositories. The tool has been applied in a real setting to explore computational fluid dinamics (CFD) simulation data and obtain new insights into the space of simulations. The inclusion of free exploration, filtering operations, and chart generation provides a quick method for performance comparisons. The paper proposes an algorithmic means of processing input in the form of tabular data sets, generating a plausible hierarchical structure over metadata categories, which is used to initialize the visualization together with interactions' methods to explore, select, and compare sets of simulation data. This paper also reports on the evaluation study performed involving 24 engineers over two distinct locations from a large automotive manufacturer to evaluate the usability and the overall user satisfaction with the tool. Participants rated the tool as intuitive, useful, and effective.","Data set processing | data visualization | exploratory search system | industrial user evaluation study | information retrieval | multirun simulations | user interfaces","IEEE Transactions on Industrial Informatics","Article","https:\/\/www.doi.org\/10.1109\/TII.2016.2521613","2-s2.0-84963804690"],["2016-03-31","Vittorio Scarano","SOF: Zero Configuration Simulation Optimization Framework on the Cloud","Simulation models are becoming an increasingly popular tool for the analysis and optimization of complex real systems in different fields. Finding an optimal system design requires performing a large parameter sweep. In this paper, we present the design of SOF (Simulation Optimization and exploration Framework on the cloud), a framework which exploits the computing power of a cloud computational environment in order to realize effective and efficient simulation optimization strategies. SOF offers several attractive features: SOF requires \u00abzero configuration\u00bb as it does not require any additional software installed on the remote node, SOF is transparent to the user, since the user is totally unaware that system operates on a distributed environment, SOF is highly customizable and programmable, since it enables the running of different simulation optimization scenarios on different simulation toolkits. The tool has been fully developed and is available on a public repository under the Apache public licence.",null,"Proceedings - 24th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing, PDP 2016","Conference Paper","https:\/\/www.doi.org\/10.1109\/PDP.2016.22","2-s2.0-84968877334"],["2016-03-24","Vittorio Scarano","Fostering transparency and participation in the data-based society: A sustainable architecture for a social platform for Open Data","This paper focuses on innovative solutions to the problem of transparency in Public Administrations (PAs) by opening up public data and services so that citizens participation is facilitated and encouraged. We introduce the motivating principles and the architectural solutions to a Social Platform for Open Data, that is designed in order to provide a sustainable and re-usable framework to provide collaborative and social access to Open Data provided by PAs. Our overall objective is to propose a engage citizens by making them able to socially interact over Open Data, by forming or joining existing online communities that share common interest and discuss common issues of relevance to local policy, service delivery, and regulation. The proposed architectural solution is supporting the citizens in a collective relationship among them (as a network helping each other) and with PAs so that the information provided by the Public Administrations is shared, interpreted, personalized, made easier to understand and discussed to assess its meanings. The results and benefits of our approach, as well as potential impact in the pilot experiences that are planned, are also discussed.",null,"eChallenges e-2015 Conference Proceedings","Conference Paper","https:\/\/www.doi.org\/10.1109\/eCHALLENGES.2015.7441082","2-s2.0-84992247508"],["2016-03-13","Biagio Cosenza","An evaluation of current SIMD programming models for C++","SIMD extensions were added to microprocessors in the mid '90s to speed-up data-parallel code by vectorization. Unfortunately, the SIMD programming model has barely evolved and the most efficient utilization is still obtained with elaborate intrinsics coding. As a consequence, several approaches to write efficient and portable SIMD code have been proposed. In this work, we evaluate current programming models for the C++ language, which claim to simplify SIMD programming while maintaining high performance. The proposals were assessed by implementing two kernels: one standard floating-point benchmark and one real-world integerbasedc application, both highly data parallel. Results show that the proposed solutions perform well for the floating point kernel, achieving close to the maximum possible speed-up. For the real-world application, the programming models exhibit significant performance gaps due to data type issues, missing template support and other problems discussed in this paper. Copyright is held by the owner\/author(s).","C++ | Parallel programming | Programming model | SIMD | Vectorization","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/2870650.2870653","2-s2.0-84976539656"],["2016-02-27","Gennaro Cordasco","An architecture for social sharing and collaboration around open data visualisations","This paper introduces the DatalEt-Ecosystem Provider (DEEP), an open source, extensible, modular and pluggable architecture providing datalets, which are web-component visualisations of datasets content. DEEP enables the sharing and collaboration around data visualisations, supporting for instance communities in public deliberation around Open Data. Users can create, reconfigure, reuse and share interactive visualisations in any web-page and other systems.","Collaboration | Open Data | Sharing of visualisations","Proceedings of the ACM Conference on Computer Supported Cooperative Work, CSCW","Conference Paper","https:\/\/www.doi.org\/10.1145\/2818052.2869099","2-s2.0-84963516599"],["2016-01-01","Vittorio Scarano","Immersivity and playability evaluation of a game experience in cultural heritage","The introduction in the market of head-mounted displays (HDMs), originally used for gaming, opens the door to a wide set of application fields that could benefit of characteristics, such as immersivity, presence as well as a high degree of realism. In the field of Cultural Heritage, an immersive virtual experience can enhance playfulness and involvement in the fruition of a cultural experience, by determining a more efficient knowledge absorption and retention of the learnt content. In this work we introduce a prototype of a Serious Game in Cultural Heritage, named Hippocratica Civitas Game, designed and implemented to foster playfulness and learning effectiveness. We also performed an evaluation study to assess users\u2019 perceived immersivity and playability, as well as the effectiveness when analyzing the acquired knowledge about the archaeological site structure and the proposed learning goal.","Evaluation | Serious game technologies | Virtual reality in cultural heritage","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-48496-9_65","2-s2.0-84995407430"],["2016-01-01","Delfina Malandrino","An evolutionary composer for real-time background music","Systems for real-time composition of background music respond to changes of the environment by generating music that matches the current state of the environment and\/or of the user. In this paper we propose one such a system that we call EvoBack Music. EvoBackMusic is a multi-agent system that exploits a feedforward neural network and a multi-objective genetic algorithm to produce background music. The neural network is trained to learn the preferences of the user and such preferences are exploited by the genetic algorithm to compose the music. The composition process takes into account a set of controllers that describe several aspects of the environment, like the dynamism of both the user and the context, other physical characteristics, and the emotional state of the user. Previous system mainly focus on the emotional aspect. EvoBackMusic has been implemented in Java using Encog and JFugue, and it can be integrated in real and virtual environments. We have performed several tests to evaluate the system and we report the results of such tests. The tests aimed at analyzing the users\u0092 perception about the quality of the produced music compositions.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-31008-4_10","2-s2.0-84962505965"],["2016-01-01","Gennaro Cordasco","Recent advances in nonlinear speech processing: Directions and challenges","Humans have very high requirements and expectations when communicating through speech, other than simplicity, flexibility and easiness of interaction. This is because voice interactions do not require cognitive efforts, attention, and memory resources. Voice technologies are however still constrained to use cases and scenarios giving the existing limitations of speech synthesis and recognition systems. Which is the status of nonlinear speech processing techniques and the steps made for cross-fertilization among disciplines? This chapter will provide a short overview trying to answer the above question.","Nonlinear speech processing | Social and emotional speech features | Socially believable voice user interfaces | Sound changes","Smart Innovation, Systems and Technologies","Article","https:\/\/www.doi.org\/10.1007\/978-3-319-28109-4_2","2-s2.0-84955578158"],["2016-01-01","Gennaro Cordasco","Active spreading in networks","Identifying the most influential spreaders is an important issue for the study of the dynamics of information diffusion in complex networks. In this paper we analyze the following spreading model. Initially, a few nodes know a piece of information and are active spreaders of it. At subsequent rounds, spreaders communicate the information to their neighbors. Upon receiving the information, a node becomes aware of it but does not necessarily become a spreader; it starts spreading only if it gets the information from a sufficiently large number of its neighbors. We study the problem of choosing the smallest set of initial spreaders that guarantee that all the nodes become aware of the information. We provide hardness results and show that the problem becomes tractable on trees. In case of general graphs, we provide an efficient algorithm and validate its effectiveness (in terms of the solution size) on real-life networks.",null,"CEUR Workshop Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-85007560306"],["2016-01-01","Gennaro Cordasco","Evangelism in social networks","We consider a population of interconnected individuals that, with respect to a piece information, at each time instant can be subdivided into three (time-dependent) categories: agnostic, influenced, and evangelists.A dynamical process of information diffusion evolves among the individuals of the population according to the following rules.Initially, all individuals are agnostic.Then, a set of people is chosen from the outside and convinced to start evangelizing, i.e., to start spreading the information.When a number of evangelists, greater than a given threshold, communicate with an node v, the node v becomes influenced, whereas, as soon as the individual v is contacted by a sufficiently much larger number of evangelists, it is itself converted into an evangelist and consequently it starts spreading the information.The question is: How to choose a bounded cardinality initial set of evangelists so as to maximize the final number of influenced individuals? We prove that the problem is hard to solve, even in an approximate sense, and we present exact polynomial time algorithms for trees and complete graphs.For general graphs, we derive exact algorithms parameterized with respect to neighborhood diversity.We also study the problem when the objective is to select a minimum number of evangelists able of influencing the whole network.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-44543-4_8","2-s2.0-84984918727"],["2015-12-14","Vittorio Scarano","Visual and textual dataset exploration","ExploraTool is a tool to visually and textually explore, filter and select data within simulation repositories. The tool groups items together by their main attribute values. Groups are represented as nested ellipses. Drill-down and rollup operations are provided. In this paper, we extend by adding a textual based search facility that updates the visualisation, allowing at same time textual and visual queries. ExploraTool's features, challenges to face and future work have been discussed.",null,"Proceedings of IEEE Symposium on Visual Languages and Human-Centric Computing, VL\/HCC","Conference Paper","https:\/\/www.doi.org\/10.1109\/VLHCC.2015.7357241","2-s2.0-84959884877"],["2015-11-01","Biagio Cosenza","Spectral turning bands for efficient Gaussian random fields generation on GPUs and accelerators","A random field (RF) is a set of correlated random variables associated with different spatial locations. RF generation algorithms are of crucial importance for many scientific areas, such as astrophysics, geostatistics, computer graphics, and many others. Current approaches commonly make use of 3D fast Fourier transform (FFT), which does not scale well for RF bigger than the available memory; they are also limited to regular rectilinear meshes. We introduce random field generation with the turning band method (RAFT), an RF generation algorithm based on the turning band method that is optimized for massively parallel hardware such as GPUs and accelerators. Our algorithm replaces the 3D FFT with a lower-order, one-dimensional FFT followed by a projection step and is further optimized with loop unrolling and blocking. RAFT can easily generate RF on non-regular (non-uniform) meshes and efficiently produce fields with mesh sizes bigger than the available device memory by using a streaming, out-of-core approach. Our algorithm generates RF with the correct statistical behavior and is tested on a variety of modern hardware, such as NVIDIA Tesla, AMD FirePro and Intel Phi. RAFT is faster than the traditional methods on regular meshes and has been successfully applied to two real case scenarios: planetary nebulae and cosmological simulations.","astrophysics | FFT | GPGPU | GPU | non-regular mesh | non-uniform mesh | random field | spectral methods | turning band","Concurrency and Computation: Practice and Experience","Article","https:\/\/www.doi.org\/10.1002\/cpe.3550","2-s2.0-84944916782"],["2015-09-28","Vittorio Scarano","Simulation repository visualisation and exploration","This paper describes a tool called ExploraTool to visualise, explore and graphically query large repositories of simulations. Instead of starting with the empty list, ExploraTool provides an initial overview of the repository content, progressively grouping the simulations by their main attributes, such as brand, vehicle model, power source, engine type and so on. Users can interactively navigate the repository view through drill-down, roll-up and rearrangement operations. In this way, using the ExploraTool, simulation analysts can visualise, explore and filter large repository of simulations as well as select groups of simulations to compare their performances.","Data Exploration | Data Visualisation | Simulation","Proceeding - 2015 IEEE International Conference on Industrial Informatics, INDIN 2015","Conference Paper","https:\/\/www.doi.org\/10.1109\/INDIN.2015.7281844","2-s2.0-84949502796"],["2015-09-18","Delfina Malandrino","A color-based visualization approach to understand harmonic structures of musical compositions","Music expertise is the ability to understand the structural elements of music compositions by reading musical scores or even by simply listening to music performance. Although the most common way to learn music is through the study of musical scores, this approach is demanding in terms of learning ability, given the required implicit knowledge of music theoretical notations and concepts. In this work we define a two-level color-based approach, that exploits graphical visualization techniques to represent data structures of classical music, and to perform harmonic analysis of musical compositions. Our main goal is to make easier and very quick the study of classical notations (recognized as a tedious and difficult task in the field), by providing individuals with a mechanism that clarifies complex relationships in music using visual clues. We performed a preliminary study to evaluate the effectiveness of our approach as well as participants' perceptions about its usefulness and pleasantness. The results of the study provided us with overall positive feedback about the effectiveness of our approach as well as further directions to explore.","Evaluation | Harmonic music composition | Visualization","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/iV.2015.21","2-s2.0-84992240369"],["2015-08-25","Gennaro Cordasco","Influence propagation over large scale social networks","We study the influence diffusion problem in online social networks. Formally, given a network represented by a directed graph G = (V, E), we consider a process of influence diffusion in G that proceeds as follows: Initially only the vertices of a given S \u2286 V are influenced; subsequently, at each round, the set of influenced vertices is augmented by all the vertices in the network that have a sufficiently large number of already influenced incoming neighbors. The question is to find a small subset of vertices that can influence the whole network (target set). This is a widely studied problem that abstracts many phenomena in the social, economic, biological, and physical sciences. It is known to be hard to approximate within a factor of 2log1-e n, for any \u03f5 > 0, and n = |V|. Despite the above negative result, some efficient heuristics have been recently proposed in the literature. In this paper, we present a scalable, fast, and simple algorithm (MTS) for the influence diffusion problem. Experiments conducted over real-world social networks show that the proposed algorithm produces solutions that substantially outperform those obtained by previously published algorithms. Experiments also show that the performances of the analyzed algorithms (measured by the normalized target set size) correlates positively with the strength of communities of a network (measured by the network modularity). Such correlation is even stronger using the results provided by the MTS algorithm, showing that the proposed MTS algorithm better exploits situations in which the community structure of the networks allows some influence between different communities.",null,"Proceedings of the 2015 IEEE\/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2015","Conference Paper","https:\/\/www.doi.org\/10.1145\/2808797.2808888","2-s2.0-84962588136"],["2015-08-01","Gennaro Cordasco","An AREA-Oriented Heuristic for Scheduling DAGs on Volatile Computing Platforms","Many modern computing platforms - notably clouds and desktop grids - exhibit dynamic heterogeneity: the availability and computing power of their constituent resources can change unexpectedly and dynamically, even in the midst of a computation. We introduce a new quality metric, AREA, for schedules that execute computations having interdependent constituent chores (jobs, tasks, etc.) on such platforms. AREA measures the average number of chores that a schedule renders eligible for execution at each step of a computation. Even though the definition of AREA does not mention any properties of host platforms (such as volatility), intuition suggests that rendering chores eligible at a faster rate will have a benign impact on the performance of volatile platforms. We report on simulation experiments that support this intuition. Earlier work has derived the basic properties of the AREA metric and has shown how to efficiently craft AREA-maximizing (A-M) schedules for several classes of significant computations. Even though A-M schedules always exist for every computation, it is not always known how to derive such schedules efficiently. In response, the current study develops an efficient algorithm that produces AREA-Oriented (A-O) schedules, which aim to efficiently approximate the AREAs of A-M schedules on arbitrary computations. The simulation experiments reported on here suggest that, in common with A-M schedules, A-O schedules complete computations on volatile heterogeneous platforms faster than a variety of heuristics that range from lightweight ones to computationally intensive ones - albeit not to the same degree as A-M schedules do. Our experiments suggest that schedules having larger AREAs have smaller completion times - but no proof of that yet exists.","Cloud computing | DAG scheduling | Desktop grids | Scheduling for dynamically heterogeneous platforms | Volunteer computing","IEEE Transactions on Parallel and Distributed Systems","Article","https:\/\/www.doi.org\/10.1109\/TPDS.2014.2346189","2-s2.0-84937469194"],["2015-06-27","Gennaro Cordasco","Spread of influence in weighted networks under time and budget constraints","Given a network represented by a weighted directed graph G, we consider the problem of finding a bounded cost set of nodes S such that the influence spreading from S in G, within a given time bound, is as large as possible. The dynamics that governs the spread of influence is the following: initially only elements in S are influenced; subsequently at each round, the set of influenced elements is augmented by all nodes in the network that have a sufficiently large number of already influenced neighbors. We prove that the problem is NP-hard, even in simple networks like complete graphs and trees. We also derive a series of positive results. We present exact pseudo-polynomial time algorithms for general trees, that become polynomial time in case the trees are unweighted. This last result improves on previously published results. We also design polynomial time algorithms for general weighted paths and cycles, and for unweighted complete graphs.","Dynamic monopolies | Exact pseudo-polynomial time algorithms | Social networks | Spread of influence | Viral marketing","Theoretical Computer Science","Article","https:\/\/www.doi.org\/10.1016\/j.tcs.2015.02.032","2-s2.0-84945267664"],["2015-05-01","Vittorio Scarano","CONSRANK: A server for the analysis, comparison and ranking of docking models based on inter-residue contacts","Herein, we present CONSRANK, a web tool for analyzing, comparing and ranking protein-protein and protein-nucleic acid docking models, based on the conservation of inter-residue contacts and its visualization in 2D and 3D interactive contact maps.",null,"Bioinformatics","Article","https:\/\/www.doi.org\/10.1093\/bioinformatics\/btu837","2-s2.0-84938253300"],["2015-03-01","Delfina Malandrino","A tailorable infrastructure to enhance mobile seamless learning","The widespread use of mobile devices is leading towards their adoption in the learning process, even if some pedagogical challenges are still not fully addressed when integrating mobile-assisted activities into regular curricula activities. In this paper, we first define some guidelines to design a general, tailorable, and platform-independent mobile learning system. Second, we present the aCME system, a mobile infrastructure, developed by adhering to the defined guidelines, to provide a general-purpose system, easy to start up with and friendly to user, and finally, tailorable, i.e., that can be easily adapted to the needs of different learning environments. The aCME system has been implemented as a Web-based architecture, to provide content and functionalities for different contexts, accessible from any location and by using any communication device. Finally, we describe a tool, deployed into aCME, that allows responding to quiz-based questionnaires during learning activities. A preliminary evaluation was performed to analyze usability and user satisfaction when interacting with the system we developed. The paper is concluded with some comments and future research directions.","Mobile infrastructure | mobile learning | tailorability | usability | web-based systems","IEEE Transactions on Learning Technologies","Article","https:\/\/www.doi.org\/10.1109\/TLT.2014.2365026","2-s2.0-84926368459"],["2015-02-10","Delfina Malandrino","Mobile phone batteries draining: Is green web browsing the solution?","Providing mechanisms to improve energy efficiency of mobile devices is, in the past few years, one of the important objectives in the field of green computing and energy savings. Several studies have addressed this issue from different point of views, i.e., hardware, software, as well as by analyzing the energy drained by different mobile applications. On the other hand, the energy consumption of Web browsing activities has been poorly addressed, given the lack of analysis about users' real browsing sessions. We propose in this paper a new methodology that exploits an hardware-based instrumentation to measure energy savings in mobile devices when switching on\/off filtering techniques offered by a privacy-enhancing technology. We discuss an extensive experimental study that shows how privacy-preserving mechanisms can help users to protect their privacy, their personal information, and en passant efficiently reduce communication and computation overhead and thus battery consumption.",null,"2014 International Green Computing Conference, IGCC 2014","Conference Paper","https:\/\/www.doi.org\/10.1109\/IGCC.2014.7039152","2-s2.0-84924348391"],["2015-01-01","Gennaro Cordasco","On evaluating graph partitioning algorithms for distributed agent based models on networks","Graph Partitioning is a key challenge problem with application in many scientific and technological fields. The problem is very well studied with a rich literature and is known to be NP-hard. Several heuristic solutions, which follow diverse approaches, have been proposed, they are based on different initial assumptions that make them difficult to compare. An analytical comparison was performed based on an Implementation Challenge [3], however being a multi-objective problem (two opposing goals are for instance load balancing and edge-cut size), the results are difficult to compare and it is hard to foresee what can be the impact of one solution, instead of another, in a real scenario. In this paper we analyze the problem in a real context: the development of a distributed agent-based simulation model on a network field (which for instance can model social interactions). We present an extensive evaluation of the most efficient and effective solutions for the balanced k-way partitioning problem. We evaluate several strategies both analytically and on real distributed simulation settings (D-Mason). Results show that, a good partitioning strategy strongly influences the performances of the distributed simulation environment. Moreover, we show that there is a strong correlation between the edge-cut size and the real performances. Analyzing the results in details we were also able to discover the parameters that need to be optimized for best performances on networks in ABMs.","Agent-Based Simulation Models | D-Mason | Distributed systems | Graph partitioning | High performance Computing | Parallel computing","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-27308-2_30","2-s2.0-84952042092"],["2015-01-01","Gennaro Cordasco","A fast and effective heuristic for discovering small target sets in social networks","Given a network represented by a graph G=(V,E), we consider a dynamical process of influence diffusion in G that evolves as follows: Initially only the nodes of a given S\u2286V are influenced; subsequently, at each round, the set of influenced nodes is augmented by all the nodes in the network that have a sufficiently large number of already influenced neighbors. The question is to determine a small subset of nodes S (a target set) that can influence the whole network. This is a widely studied problem that abstracts many phenomena in the social, economic, biological, and physical sciences. It is known [6] that the above optimization problem is hard to approximate within a factor of 2log1\u2212\u03f5|V|, for any \u03f5>0. In this paper, we present a fast and surprisingly simple algorithm that exhibits the following features: (1) when applied to trees, cycles, or complete graphs, it always produces an optimal solution (i.e., a minimum size target set); (2) when applied to arbitrary networks, it always produces a solution of cardinality matching the upper bound given in [1], and proved therein by means of the probabilistic method; (3) when applied to real-life networks, it always produces solutions that substantially outperform the ones obtained by previously published algorithms (for which no proof of optimality or performance guarantee is known in any class of graphs).",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-26626-8_15","2-s2.0-84952042812"],["2015-01-01","Delfina Malandrino","ROUTE-TO-PA H2020 Project: Raising open and user-friendly transparency-enabling technologies for public administrations","In this short paper, we introduce ROUTE-TO-PA project, funded by European Union under the Horizon 2020 program, whose aim is to improve the transparency of Public Administration, by allowing citizens to make better use of Open Data, through collaboration and personalization.","Horizon 2020 project | Open data | Social network | Transparency | Transparencyenhancing tools","Communications in Computer and Information Science","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-27164-4_19","2-s2.0-84951949185"],["2015-01-01","Delfina Malandrino","Chorale music splicing system: An algorithmic music composer inspired by molecular splicing","Splicing systems are a formal model of a generative mechanism of words (strings of characters), inspired by a recombinant behavior of DNA. They are defined by a finite alphabet A, an initial set I of words and a set R of rules. Many of the studies about splicing systems focused on the properties of the generated languages and their theoretical computational power. In this paper we propose the use of splicing systems for algorithmic music composition. Although the approach is general and can be applied to many types of music, in this paper, we focus the attention to the algorithmic composition of 4-voice chorale-like music. We have developed a Java implementation of this approach and we have provided an evaluation of the music output by the system.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-16498-4_5","2-s2.0-84925238660"],["2015-01-01","Biagio Cosenza","Point distribution tensor computation on heterogeneous systems","Big data in observational and computational sciences impose increasing challenges on data analysis. In particular, data from light detection and ranging (LIDAR) measurements are questioning conventional methods of CPU-based algorithms due to their sheer size and complexity as needed for decent accuracy. These data describing terrains are natively given as big point clouds consisting of millions of independent coordinate locations from which meaningful geometrical information content needs to be extracted. The method of computing the point distribution tensor is a very promising approach, yielding good results to classify domains in a point cloud according to local neighborhood information. However, an existing KD-Tree parallel approach, provided by the VISH visualization framework, may very well take several days to deliver meaningful results on a real-world dataset. Here we present an optimized version based on uniform grids implemented in OpenCL that is able to deliver results of equal accuracy up to 24 times faster on the same hardware. The OpenCL version is also able to benefit from a heterogeneous environment and we analyzed and compared the performance on various CPU, GPU and accelerator hardware platforms. Finally, aware of the heterogeneous computing trend, we propose two low-complexity dynamic heuristics for the scheduling of independent dataset fragments in multi-device heterogenous systems.",null,"Procedia Computer Science","Conference Paper","https:\/\/www.doi.org\/10.1016\/j.procs.2015.05.217","2-s2.0-84939167275"],["2015-01-01","Vittorio Scarano","Euro-Par 2015: Parallel Processing Workshops: Euro-Par 2015 International Workshops Vienna, Austria, August 24-25, 2015 Revised Selected Papers",null,null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84951953648"],["2015-01-01","Biagio Cosenza","Automatic data layout optimizations for GPUs","Memory optimizations have became increasingly important in order to fully exploit the computational power of modern GPUs. The data arrangement has a big impact on the performance, and it is very hard for GPU programmers to identify a well-suited data layout. Classical data layout transformations include grouping together data fields that have similar access patterns, or transforming Array-of-Structures (AoS) to Structure-of-Arrays (SoA). This paper presents an optimization infrastructure to automatically determine an improved data layout for OpenCL programs written in AoS layout. Our framework consists of two separate algorithms: The first one constructs a graph-based model, which is used to split the AoS input struct into several clusters of fields, based on hardware dependent parameters. The second algorithm selects a good per-cluster data layout (e.g., SoA, AoS or an intermediate layout) using a decision tree. Results show that the combination of both algorithms is able to deliver higher performance than the individual algorithms. The layouts proposed by our framework result in speedups of up to 2.22, 1.89 and 2.83 on an AMD FirePro S9000, NVIDIA GeForce GTX 480 and NVIDIA Tesla k20m, respectively, over different AoS sample programs, and up to 1.18 over a manually optimized program.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-662-48096-0_21","2-s2.0-84944128564"],["2015-01-01","Biagio Cosenza","Behavioral spherical harmonics for long-range agents\u2019 interaction","We introduce behavioral spherical harmonic (BSH), a novel approach to efficiently and compactly represent the directional-dependent behavior of agent. BSH is based on spherical harmonics to project the directional information of a group of multiple agents to a vector of few coefficients; thus, BSH drastically reduces the complexity of the directional evaluation, as it requires only few agent-group interactions instead of multiple agent-agent ones. We show how the BSH model can efficiently model intricate behaviors such as long-range collision avoidance, reaching interactive performance and avoiding agent congestion on challenging multi-groups scenarios. Furthermore, we demonstrate how both the innate parallelism and the compact coefficient representation of the BSH model are well suited for GPU architectures, showing performance analysis of our OpenCL implementation.","Agent-based simulation | Behavioral model | Collision avoidance | GPGPU | Long-distance interaction | Spherical harmonics","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-27308-2_32","2-s2.0-84952031032"],["2015-01-01","Carmine Spagnuolo","Distributed agent-based simulation and GIS: An experiment with the dynamics of social norms","In the last decade, the investigation of the social complexity has witnessed the rise of Computational Social Science, a research paradigm that heavily relies upon data and computation to foster our understanding of social phenomena. In this field, a key role is played by the explanatory and predictive power of agent-based social simulations that are showing to take advantage of GIS, higher number of agents and real data. We focus GIS based distibuted ABMs. We observed that the density distribution of agents, over the field, strongly impact on the overall performances. In order to better understand this issue, we analyzes three different scenarios ranging from real positioning, where the citizens are positioned according to a real dataset to a random positioning where the agent are positioned uniformly at random on the field. Results confirm our hypothesis and show that an irregular distribution of the agents over the field increases the communication overhead. We provide also an analytic analysis which, in a 2-dimensional uniform field partitioning, is affected by several parameters (which depend on the model), but is also influenced by the density distribution of agents over the field. According to the presented results, we have that uniform space partitioning strategy does not scale on GIS based ABM characterized by an irregular distribution of agents.","ABM | D-Mason | Distributed agent-based social simulation | Distributed systems | GIS | GIS | Parallel computing","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-27308-2_31","2-s2.0-84952044891"],["2015-01-01","Gennaro Cordasco","Optimizing spread of influence in social networks via partial incentives","A widely studied process of influence diffusion in social networks posits that the dynamics of influence diffusion evolves as follows: Given a graph G=(V,E), representing the network, initially only the members of a given S\u2286V are influenced; subsequently, at each round, the set of influenced nodes is augmented by all the nodes in the network that have a sufficiently large number of already influenced neighbors. The general problem is to find a small initial set of nodes that influences the whole network. In this paper we extend the previously described basic model in the following ways: firstly, we assume that there are non negative values c(v) associated to each node v\u2208V, measuring how much it costs to initially influence node v, and the algorithmic problem is to find a set of nodes of minimum total cost that influences the whole network; successively, we study the consequences of giving incentives to member of the networks, and we quantify how this affects (i.e., reduces) the total costs of starting an influence diffusion process that influence the whole network. For the two above problems we provide both hardness results and algorithms. We also experimentally validate our algorithms via extensive simulations on real life networks.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-25258-2_9","2-s2.0-84950324358"],["2014-11-27","Biagio Cosenza","Kd-tree based N-body simulations with volume-mass heuristic on the GPU","N-body simulations represent an important class of numerical simulations in order to study a wide range of physical phenomena for which researchers demand fast and accurate implementations. Due to the computational complexity, simple brute-force methods to solve the long-distance interaction between bodies can only be used or small-scale simulations. Smarter approaches utilize neighbor lists, tree methods or other hierarchical data structures to reduce the complexity of the force calculations. However, such data structures have complex building algorithms which hamper their parallelization for GPUs. In this paper, we introduce a novel method to effectively parallelize N-body simulations for GPU architectures. Our method is based on an efficient, three-phase, parallel Kd-tree building algorithm and a novel volume-mass heuristic to reduce the simulation time and increase accuracy. Experiments demonstrate that our approach is the fastest monopole implementation with an accuracy that is comparable with state of the art implementations (GADGET-2). In particular, we are able to reach a simulation speed of up to 3 Mparticles\/s on a single GPU for the force calculation, while still having a relative force error below 0.4% for 99% of the particles. We also show competitive performance with existing GPU implementations, while our competitor shows worse accuracy behavior as well as a higher energy error during time integration.","GPGPU | Kd-tree | N-body","Proceedings - IEEE 28th International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2014","Conference Paper","https:\/\/www.doi.org\/10.1109\/IPDPSW.2014.141","2-s2.0-84918827004"],["2014-10-16","Vittorio Scarano","A platform to collaborate around CFD simulations","This paper describes Floasys, a web-based platform to foster the collaboration among Computational Fluid Dynamics analysts and to promote model reuse by centrally managing simulation data and providing metadata annotations and search functionality over them. In this way, CFD analysts access to simulation data and results performed by different engineers and are able to leverage on them to make the right design decisions.","CFD simulators integration | Data sharing | model sharing | simulation data version control | simulation search | simulation tagging | stakeholders communication | Tools integration | Web-based platform","Proceedings of the Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, WETICE","Conference Paper","https:\/\/www.doi.org\/10.1109\/WETICE.2014.49","2-s2.0-84908424042"],["2014-03-28","Gennaro Cordasco","The influence of positive and negative emotions on physiological responses and memory task scores","The present paper report results of a preliminary study devoted to investigate whether and how different induced emotional states influence physiological responses and memory task scores. Physiological responses, such as skin conductance (SCL) and heart rate (HR) values were measured from 32 university students, before, during and after they were elicited by video stimuli. The considered stimuli were able to induce positive, negative and neutral emotional states. The specific physiological activation patterns were identified and correlated with memory task scores, computed using the \"Anna Pesenti\" Story Recall Test (SRT). The results show significant changes in physiological values when positive (increase in HR values) and negative (increase in SCL values) emotional states are induced. Surprisingly, increased SCL values, associated to induced positive emotional states, affect the participant's memory task scores. \u00a9 Springer International Publishing Switzerland 2014.","Emotion | Memory task scores | Physiological activation","Smart Innovation, Systems and Technologies","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-04129-2_31","2-s2.0-84897896842"],["2014-01-23","Gennaro Cordasco","Assessing Voice User Interfaces: The vassist system prototype","This paper reports on the results of the first lab trials evaluating the vAssist (Voice Controlled Assistive Care and Communication Services for the Home) system prototype with Italian users. vAssist is an European Project aiming to provide specific voice controlled home care and communication services for elderly. An important vAssist objective is a multilingual Voice User Interface (VUI) in three different languages: Italian, French and German. Lab trials were foreseen in these three different countries to assess the vAssist VUI prototype on realistic user expectations and requirements. The assessment was made letting 43 Italian elderly interact with the VUI prototype in 4-5 defined scenarios, exploiting a Wizard-of-Oz (WoZ) paradigm and administering to them three questionnaires aimed to measure their perception of the system's usability, learnability and intuitivity. Qualitative and quantitative scores suggested that VUIs are very powerful communication interfaces and were greatly appreciated because of the simplification they provide in the elder everyday use of technological products, such as mobile phones, tablets, and computers.",null,"5th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2014 - Proceedings","Conference Paper","https:\/\/www.doi.org\/10.1109\/CogInfoCom.2014.7020425","2-s2.0-84946685910"],["2014-01-01","Gennaro Cordasco","Latency-bounded target set selection in social networks","Motivated by applications in sociology, economy and medicine, we study variants of the Target Set Selection problem, first proposed by Kempe, Kleinberg and Tardos. In our scenario one is given a graph G=(V, E), integer values t(v) for each vertex v (thresholds), and the objective is to determine a small set of vertices (target set) that activates a given number (or a given subset) of vertices of G within a prescribed number of rounds. The activation process in G proceeds as follows: initially, at round 0, all vertices in the target set are activated; subsequently at each round r\u2265 1 every vertex of G becomes activated if at least t(v) of its neighbors are already active by round r-1. It is known that the problem of finding a minimum cardinality Target Set that eventually activates the whole graph G is hard to approximate to a factor better than O(2log1-\u03b5|V|). In this paper we give exact polynomial time algorithms to find minimum cardinality Target Sets in graphs of bounded clique-width, and exact linear time algorithms for trees.","Monotone irreversible dynamic monopolies (dynamo) | Target set selection","Theoretical Computer Science","Article","https:\/\/www.doi.org\/10.1016\/j.tcs.2014.02.027","2-s2.0-84929165965"],["2014-01-01","Gennaro Cordasco","On scheduling series-parallel dags to maximize area","The AREA of a schedule for executing DAGs is the average number of DAG-chores that are eligible for execution at each step of the computation. AREA maximization is a new optimization goal for schedules that execute DAGs within computational environments, such as Internet-based computing, clouds, and volunteer computing projects, that are dynamically heterogeneous, in the sense that the environments' constituent computers can change their effective powers at times and in ways that are not predictable. This paper is motivated by the thesis that, within dynamically heterogeneous environments, DAG-schedules that have larger AREAs execute a computation-DAG with smaller completion time under many circumstances; this thesis is supported by preliminary simulation-based experiments. While every DAG admits an AREA-maximizing schedule, it is likely computationally difficult to find such a schedule for an arbitrary DAG. Earlier work has shown how to craft AREA-maximizing schedules efficiently for a number of families of DAGs whose structures are reminiscent of many scientific computations. The current paper extends this work by showing how to efficiently craft AREA-maximizing schedules for series-parallel DAGs, a family that models a multithreading computing paradigm. The techniques for crafting these schedules promise to apply also to other large families of recursively defined DAGs. Moreover, the ability to derive these schedules efficiently leads to an efficient AREA-oriented heuristic for scheduling arbitrary DAGs. \u00a9 World Scientific Publishing Company.","cloud computing | DAG-scheduling for dynamically heterogeneous platforms | desktop grids | Dynamically heterogeneous computing platforms | series-parallel DAGs | volunteer computing","International Journal of Foundations of Computer Science","Article","https:\/\/www.doi.org\/10.1142\/S0129054114500245","2-s2.0-84906335131"],["2014-01-01","Gennaro Cordasco","How to go viral: Cheaply and quickly","Given a social network represented by a graph G, we consider the problem of finding a bounded cardinality set of nodes S with the property that the influence spreading from S in G is as large as possible. The dynamics that govern the spread of influence is the following: initially only elements in S are influenced; subsequently at each round, the set of influenced elements is augmented by all nodes in the network that have a sufficiently large number of already influenced neighbors. While it is known that the general problem is hard to solve - even in the approximate sense - we present exact polynomial time algorithms for trees, paths, cycles, and complete graphs. \u00a9 2014 Springer International Publishing.","Dynamic Monopolies | Exact Polynomial Time Algorithms | Social Networks | Spread of Influence | Viral Marketing","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-07890-8_9","2-s2.0-84903697274"],["2014-01-01","Carmine Spagnuolo","Exploiting D-Mason on parallel platforms: A novel communication strategy","Agent-based simulation models are a powerful experimental tool for research and management in many scientific and technological fields.","Agent-based simulation models | D-Mason | Distributed Systems | High Performance Computing | Mason | MPI | Parallel Computing | Publish\/Subscribe","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-14325-5_35","2-s2.0-84917743993"],["2014-01-01","Carmine Spagnuolo","Communication strategies in distributed agent-based simulations: The experience with D-Mason","Agent-Based simulation Models (ABMs) are a very powerful experimental tool of analysis, used in many scientific and technological communities of researchers, to assess and predict the dynamic unfolding of a series of events or processes, according to the imposition of certain conditions, given by the analyst. The computing power usually represents a limit for such simulations and the traditional answer to the need for computing power is to invest in computer resources. D-Mason is a framework for parallelizing simulations developed on top of Mason toolkit. The goal of D-Mason is to exploit wasted computing power in a network of computers, eventually heterogeneous, as a research lab or a cluster of workstation. In this paper we present a novel communication strategy using Publish\/ Subscribe paradigm through a layer based on the MPI Standard. \u00a9 2014 Springer-Verlag Berlin Heidelberg.","Agent-based simulation models | D-Mason | Distributed Systems | High Performance Computing | Mason | MPI | Parallel Computing | Publish\/Subscribe","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-54420-0_52","2-s2.0-84958539488"],["2014-01-01","Biagio Cosenza","Random fields generation on the GPU with the spectral turning bands method","Random field (RF) generation algorithms are of paramount importance for many scientific domains, such as astrophysics, geostatistics, computer graphics and many others. Some examples are the generation of initial conditions for cosmological simulations or hydrodynamical turbulence driving. In the latter a new random field is needed every time-step. Current approaches commonly make use of 3D FFT (Fast Fourier Transform) and require the whole generated field to be stored in memory. Moreover, they are limited to regular rectilinear meshes and need an extra processing step to support non-regular meshes. In this paper, we introduce TBARF (Turning BAnd Random Fields), a RF generation algorithm based on the turning band method that is optimized for massively parallel hardware such as GPUs. Our algorithm replaces the 3D FFT with a lower order, one-dimensional FFT followed by a projection step, and is further optimized with loop unrolling and blocking. We show that TBARF can easily generate RF on non-regular (non uniform) meshes and can afford mesh sizes bigger than the available GPU memory by using a streaming, out-of-core approach. TBARF is 2 to 5 times faster than the traditional methods when generating RFs with more than 16M cells. It can also generate RF on non-regular meshes, and has been successfully applied to two real case scenarios: planetary nebulae and cosmological simulations. \u00a9 2014 Springer International Publishing Switzerland.","astrophysics | fft | gpgpu | gpu | non uniform mesh | non-regular mesh | random field | spectral methods | turning band","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-09873-9_55","2-s2.0-84958537263"],["2014-01-01","Gennaro Cordasco","Supporting the exploratory nature of simulations in D-Mason","Agent-Based Models (ABM) are a class of models which, by simulating the behaviors of multiple agents (i.e., independent actions, interactions and adaptation), aims to emulate and\/or predict complex phenomena. The \"emergence\" of such complex phenomena is often computation intensive and requires tools, libraries and frameworks, capable of speeding up and facilitate the design of complex simulations. In this paper we present new developments on that is a distributed version of a well-known and popular library for writing and running Agent-based Simulations. The new developments are: a) a tool that allows the parallel exploration of the behavior parameter space; b) an infrastructure that improves the management of distributed simulations in terms of easy deployment of new simulations, automatic update, versioning control and distributed logging. \u00a9 2014 Springer-Verlag Berlin Heidelberg.","Agent-Based Simulation | Distributed Systems | System Management","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-54420-0_54","2-s2.0-84958553198"],["2014-01-01","Biagio Cosenza","A uniform approach for programming distributed heterogeneous computing systems","Large-scale compute clusters of heterogeneous nodes equipped with multi-core CPUs and GPUs are getting increasingly popular in the scientific community. However, such systems require a combination of different programming paradigms making application development very challenging. In this article we introduce libWater, a library-based extension of the OpenCL programming model that simplifies the development of heterogeneous distributed applications. libWater consists of a simple interface, which is a transparent abstraction of the underlying distributed architecture, offering advanced features such as inter-context and inter-node device synchronization. It provides a runtime system which tracks dependency information enforced by event synchronization to dynamically build a DAG of commands, on which we automatically apply two optimizations: collective communication pattern detection and device-host-device copy removal. We assess libWater's performance in three compute clusters available from the Vienna Scientific Cluster, the Barcelona Supercomputing Center and the University of Innsbruck, demonstrating improved performance and scaling with different test applications and configurations.","Distributed computing | Heterogeneous computing | MPI | OpenCL | Programming model | Runtime system","Journal of Parallel and Distributed Computing","Article","https:\/\/www.doi.org\/10.1016\/j.jpdc.2014.08.002","2-s2.0-84910032554"],["2014-01-01","Vittorio Scarano","SLAM map application for tracking lights on car dashboards","Recent studies conducted by some insurance companies highlighted that the most part of drivers do not know the meaning of the dashboard lights. This leads drivers to be dangerous for others and themselves. Hence, the need to provide drivers with tools that support them to always be aware of the state of their cars. This paper proposes a system for mobile devices that uses augmented reality to be able to give information on a particular dashboard lights. The system is implemented by combining the use of Simultaneous Localization and Mapping (SLAM) maps with central moment computation widely used in computer vision. Preliminary research results show that the proposed system achieves its goal enables a a real-time visual feedback.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-319-13969-2_31","2-s2.0-84918536137"],["2014-01-01","Gennaro Cordasco","First workshop on parallel and distributed agent-based simulations (PADABS 2013)",null,null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Editorial","https:\/\/www.doi.org\/None","2-s2.0-84901318123"],["2014-01-01","Gennaro Cordasco","D-MASON: A short tutorial","D-Mason framework is a parallel version of the Mason library for writing and running Agent-based simulations. We briefly present Mason architecture, functionalities and some programming examples. Full documentation, additional tutorials and other material can be found at www.dmason.org where the framework can be downloaded. \u00a9 2014 Springer-Verlag Berlin Heidelberg.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-54420-0_48","2-s2.0-84958524140"],["2014-01-01","Delfina Malandrino","Simulation data sharing to foster teamwork collaboration","This paper introduces Floasys, a Web-based platform to foster the collaboration among engineers involved in Computational Fluid Dynamics (CFD) simulations. The platform has been designed around the simulation data, i.e., fostering and stimulating sharing, re-use and aggregation of models, simulation results and engineers annotations. Floasys requirements come directly from an extensive requirements study that we conducted with two different teams in Automobiles (FCA), geographically distributed, who daily perform an intense activity of CFD simulations to design vehicle products. Collaborative requirements were gathered through stakeholders' interviews and a user survey. We describe, first, Functional and Non-Functional requirements as suggested by relevant literature (both in scientific and industrial setting) and by the user survey performed within FCA teams. Then, we show Floasys functionalities and its architecture, that is based on a centrally managed repository of simulation data. By enriching the repository with metadata annotations, Floasys provides all the desired functionalities to allow CFD analysts an easy and immediate access to simulation data and results performed within the teams so that they can leverage them to make the right design decisions. In this paper, we were able to (1) identify key collaborative requirements for CFD design, (2) address each of them with an integrated, extensible and modular architecture, (3) implement a working industrial prototype (currently under testing and evaluation in a real setting like FCA), and (4) identify the possible extensions to different contexts (like aeronautic, rail and naval sectors).","CFD simulators integration | Collaboration | Data sharing | Model sharing | Simulation data version control | Simulation search | Simulation survey | Simulation tagging | Web-based simulation","Scalable Computing","Article","https:\/\/www.doi.org\/10.12694\/scpe.v15i4.1053","2-s2.0-84923856429"],["2014-01-01","Delfina Malandrino","How quiz-based tools can improve students' engagement and participation in the classroom","Student Response Systems exhibit a long usage history, begun with clickers and recently evolved toward Web-based systems. Several studies show that they improve students' engagement and participation, but also show some drawbacks (clickers costs, distraction and equity in Web-based systems). In this paper, we present our implementation of a Student Response System integrated within a collaborative application. Our approach does not require an Internet connection, has no cost, is flexible, and includes the possibility of arranging a Student Response Systems with a wide set of collaborative tools. We also present an evaluation study involving teachers and students from a high school. Results show improvements in students' participation and engagement. Finally we found some differences between the teachers and students groups with regard to user experience, usefulness, and long-term behaviors. \u00a9 2014 IEEE.","collaboration | engagement | Quiz-based Tools | Student Response Systems","2014 International Conference on Collaboration Technologies and Systems, CTS 2014","Conference Paper","https:\/\/www.doi.org\/10.1109\/CTS.2014.6867592","2-s2.0-84906221008"],["2014-01-01","Delfina Malandrino","BeeAdHocServiceDiscovery: A MANET service discovery algorithm based on bee colonies","In a mobile ad-hoc network, nodes are self-organized without any infrastructure support: they move arbitrarily causing the network to experience quick and random topology changes, have to act as routers as well as forwarding nodes, some of them do not communicate directly with each other. Routing, IP address autoconfiguration and Web service discovery are among the most challenging tasks in the MANET domain. Swarm Intelligence is a property of natural and artificial systems involving minimally skilled individuals that exhibit a collective intelligent behaviour derived from the interaction with each other by means of the environment. Colonies of ants and bees are the most prominent examples of swarm intelligence systems. Flexibility, robustness, and self-organization make swarm intelligence a successful design paradigm for difficult combinatorial optimization problems. This paper proposes BeeAdHocServiceDiscovery a new service discovery algorithm based on a bee swarm labour that may be applied to large scale MANET with low complexity, low communication overhead, and low latency. Eventually, future research directions are established.","MANET auto-configuration | Routing | Swarm intelligence | Web service discovery","ICINCO 2014 - Proceedings of the 11th International Conference on Informatics in Control, Automation and Robotics","Conference Paper","https:\/\/www.doi.org\/10.5220\/0005045902440251","2-s2.0-84910062965"],["2014-01-01","Delfina Malandrino","QoS-based web service discovery in mobile ad hoc networks using swarm strategies","Mobile ad hoc networks are noncentralised, multihop, wireless networks that lack a common infrastructure and hence require self-organisation. Their infrastructureless and dynamic nature entails the implementation of a new set of networking technologies in order to provide efficient end-to-end communication according to the principles of the standard TCP\/IP suite. Routing, IP address autoconfiguration and Web service discovery are among the most challenging tasks in the ad hoc network domain. Swarm intelligence is a relatively new approach to problem solving that takes inspiration from the social behaviours of insects, such as ants and bees. Self-organization, decentralization, adaptivity, robustness, and scalability make swarm intelligence a successful design paradigm for the above-mentioned problems. In this paper we propose BeeAdHocServiceDiscovery, a new service discovery algorithm based on the bee metaphor, which also takes into account quality metrics estimates. The protocol has been specifically designed to work in mobile ad hoc network scenarios operating with Beeadhoc, a well-known routing algorithm inspired by nature. We present both the protocol strategy and the formal evaluation of the discovery overhead and route optimality metrics showing that BeeAdHocServiceDiscovery guarantees valuable performances even in large scale ad hoc wireless networks. Eventually, future research suggestions are sketched.",null,"Journal of Computer Networks and Communications","Article","https:\/\/www.doi.org\/10.1155\/2014\/450194","2-s2.0-84912099197"],["2014-01-01","Biagio Cosenza","Ethylene glycol revisited: Molecular dynamics simulations and visualization of the liquid and its hydrogen-bond network","Molecular dynamics simulations of liquid ethylene glycol described by the OPLS-AA force field were performed to gain insight into its hydrogen-bond structure. We use the population correlation function as a statistical measure for the hydrogen-bond lifetime. In an attempt to understand the complicated hydrogen-bonding, we developed new molecular visualization tools within the Vish Visualization shell and used it to visualize the life of each individual hydrogen-bond. With this tool hydrogen-bond formation and breaking as well as clustering and chain formation in hydrogen-bonded liquids can be observed directly. Liquid ethylene glycol at room temperature does not show significant clustering or chain building. The hydrogen-bonds break often due to the rotational and vibrational motions of the molecules leading to an H-bond half-life time of approximately 1.5 ps. However, most of the H-bonds are reformed again so that after 50 ps only 40% of these H-bonds are irreversibly broken due to diffusional motion. This hydrogen-bond half-life time due to diffusional motion is 80.3 ps. The work was preceded by a careful check of various OPLS-based force fields used in the literature. It was found that they lead to quite different angular and H-bond distributions. \u00a9 2013 The Authors.","Ethylene glycol | Hydrogen-bonds | Molecular dynamics | OPLS-AA force fields | Visualization","Journal of Molecular Liquids","Article","https:\/\/www.doi.org\/10.1016\/j.molliq.2013.05.033","2-s2.0-84890564087"],["2013-12-09","Vittorio Scarano","Privacy awareness about information leakage: Who knows what about me?","The task of protecting users' privacy is made more difficult by their attitudes towards information disclosure without full awareness and the economics of the tracking and advertising industry. Even after numerous press reports and widespread disclosure of leakages on the Web and on popular Online Social Networks, many users appear not be fully aware of the fact that their information may be collected, aggregated and linked with ambient information for a variety of purposes. Past attempts at alleviating this problem have addressed individual aspects of the user's data collection. In this paper we move towards a comprehensive and efficient client-side tool that maximizes users' awareness of the extent of their information leakage. We show that such a customizable tool can help users to make informed decisions on controlling their privacy footprint. \u00a9 2013 ACM.","enhancing technologies | privacy-awareness\/leakage","Proceedings of the ACM Conference on Computer and Communications Security","Conference Paper","https:\/\/www.doi.org\/10.1145\/2517840.2517868","2-s2.0-84889022210"],["2013-12-09","Vittorio Scarano","An architecture for CFD Workflow management","Nowadays, to design product impacted by fluid flow, industries use Computational Fluid Dynamics (CFD) to get a better insight into product behaviour. In this paper, we present a system architecture design for CFD Workflow management. \u00a9 2013 IEEE.","Architecture | CFD | CFD Workflow | management","IEEE International Conference on Industrial Informatics (INDIN)","Conference Paper","https:\/\/www.doi.org\/10.1109\/INDIN.2013.6622909","2-s2.0-84889033157"],["2013-12-01","Delfina Malandrino","How increased awareness can impact attitudes and behaviors toward online privacy protection","People on the Web are generating and disclosing an ever-increasing amounts of data, often without full awareness of who is recording what about them, and who is aggregating and linking pieces of data with context information, for a variety of purposes. Awareness can help users to be informed about what silently happens during their navigation while learning from disclosure of personal information may help to discriminate potential harmful activities from daily and regular activities that can be performed online. Our main objective is to study whether a highly customized tool can help users to learn the value of privacy from their behaviors and make informed decisions to reduce their degree of exposure. To this aim, we present an evaluation study to analyze general perceptions, attitudes, and beliefs about privacy online, and to explore the resultant behaviors for two different groups of participants from an academic environment. Results show that users from the ICT field (Information and Communication Technology) are less concerned than non-ICT ones (i.e., not technological-oriented students), and that skill and expertise can influence the perception of the risks as well as the corresponding behaviors. Finally, students with less expertise in the ICT field learned more than the others, by showing greater willingness to adopt technologies to protect their privacy online. \u00a9 2013 IEEE.",null,"Proceedings - SocialCom\/PASSAT\/BigData\/EconCom\/BioMedCom 2013","Conference Paper","https:\/\/www.doi.org\/10.1109\/SocialCom.2013.15","2-s2.0-84893567211"],["2013-12-01","Delfina Malandrino","Social team awareness","Software that is meant to support collaboration is mostly developed \"ad hoc\", placing some additional overhead to users, that are required to integrate the common work practices, realized with the traditional software applications, with the new collaborative features offered by the new application. It has been argued that this is likely to inject lack of motivation on users, jeopardizing the positive effects of collaboration in workplace, since the time dedicated to collaboration is perceived as wasted. In this paper we present a generic mechanism to provide team awareness through the integration between a social platform and a work environment. The integration mechanism is, indeed, generic and the work environment potentially can be any kind of application usually adopted by team members. We illustrate the mechanism through the design and implementation of SocSVN, a proof-of-concept example in the scenario of collaboration support in software development. SocSVN integrates a social platform (Elgg, a well known open source social networking engine) with SVN, a source code versioning system widely used in software development. We also abstract the mechanism provided and show how it is easily generalizable to other software, providing a list of the requirements and the amount of work to be integrated in the architecture. \u00a9 2013 ICST.","CSCW | social platform | software development | team awareness","Proceedings of the 9th IEEE International Conference on Collaborative Computing: Networking, Applications and Worksharing, COLLABORATECOM 2013","Conference Paper","https:\/\/www.doi.org\/10.4108\/icst.collaboratecom.2013.254087","2-s2.0-84893623234"],["2013-10-04","Vittorio Scarano","Privacy leakage on the Web: Diffusion and countermeasures","Protecting privacy on the Web is becoming increasingly complicated because of the considerable amount of personal and sensitive information left by users in many locations during their Web browsing and the silent actions of third party sites that collect data, aggregate information and build personal profiles of Internet users in order to provide free and personalized services. On the other hand, most of people are unaware that their information may be collected online, and that, after their aggregation from multiple sources, could be used for secondary purposes, such as linked to allow identification, without user's notice. We present, in this paper, an empirical data study in order to describe how users' privacy can be undermined because of a variety of potential privacy threats on the Web, mainly perpetrated by third party entities against unaware users, and to quantify the penetration of these third party domain servers into their online activities. Moreover, we discuss our methods and findings to protect the individuals against invasions of their privacy and to limit the diffusion of personal and sensitive information during Web browsing. Specifically, we present a supportive, comprehensive and improved approach for privacy protection to allow users to be aware of the risks of their navigation and to give them full control on feasible actions to address the risk of several privacy threats. We envisioned a comprehensive approach to face privacy leakage by adding to the traditional URL-based filtering mechanism a new filtering method which allows to address privacy threats unprecedentedly not dealt with. Our approach is validated by a Firefox extension, named NoTrace, that brings together several existing techniques in this field but also implements new improved techniques that ensure better privacy protection. We used NoTrace to broadly analyze the Web in order to inspect the potential threats contained in the most popular Web sites and inform online users about both their risk and extent. This data set was also used to test the efficiency of NoTrace for effectiveness and performances which allows us to mark a definite improvement on privacy protection for users while navigating the Web. \u00a9 2013 Elsevier B.V. All rights reserved.","Online privacy leakage and threats | Privacy enhancing technologies | Web navigation","Computer Networks","Article","https:\/\/www.doi.org\/10.1016\/j.comnet.2013.06.013","2-s2.0-84883228835"],["2013-08-01","Biagio Cosenza","Automatic problem size sensitive task partitioning on heterogeneous parallel systems","In this paper we propose a novel approach which automatizes task partitioning in heterogeneous systems. Our framework is based on the Insieme Compiler and Runtime infrastructure [1]. The compiler translates a single-device OpenCL program into a multi-device OpenCL program. The runtime system then performs dynamic task partitioning based on an offline-generated prediction model. In order to derive the prediction model, we use a machine learning approach that incorporates static program features as well as dynamic, input sensitive features. Our approach has been evaluated over a suite of 23 programs and achieves performance improvements compared to an execution of the benchmarks on a single CPU and a single GPU only. Copyright is held by the author\/owner(s).","Code analysis | Compilers | GPU | Heterogeneous computing | Machine learning | Runtime system | Task partitioning","ACM SIGPLAN Notices","Conference Paper","https:\/\/www.doi.org\/10.1145\/2517327.2442545","2-s2.0-84885233085"],["2013-07-26","Gennaro Cordasco","Latency-bounded target set selection in social networks","We study variants of the Target Set Selection problem, first proposed by Kempe et al. In our scenario one is given a graph G = (V,E), integer values t(v) for each vertex v, and the objective is to determine a small set of vertices (target set) that activates a given number (or a given subset) of vertices of G within a prescribed number of rounds. The activation process in G proceeds as follows: initially, at round 0, all vertices in the target set are activated; subsequently at each round r \u2265 1 every vertex of G becomes activated if at least t(v) of its neighbors are active by round r - 1. It is known that the problem of finding a minimum cardinality Target Set that eventually activates the whole graph G is hard to approximate to a factor better than O(2 log1-\u2208|V|). In this paper we give exact polynomial time algorithms to find minimum cardinality Target Sets in graphs of bounded clique-width, and exact linear time algorithms for trees. \u00a9 2013 Springer-Verlag.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-39053-1_8","2-s2.0-84880431945"],["2013-07-11","Biagio Cosenza","An automatic input-sensitive approach for heterogeneous task partitioning","Unleashing the full potential of heterogeneous systems, consisting of multi-core CPUs and GPUs, is a challenging task due to the difference in processing capabilities, memory availability, and communication latencies of different computational resources. In this paper we propose a novel approach that automatically optimizes task partitioning for different (input) problem sizes and different heterogeneous multi-core architectures. We use the Insieme source-to-source compiler to translate a single-device OpenCL program into a multi-device OpenCL program. The Insieme Runtime System then performs dynamic task partitioning based on an offline-generated prediction model. In order to derive the prediction model, we use a machine learning approach based on Artificial Neural Networks (ANN) that incorporates static program features as well as dynamic, input sensitive features. Principal component analysis have been used to further improve the task partitioning. Our approach has been evaluated over a suite of 23 programs and respectively achieves a performance improvement of 22% and 25% compared to an execution of the benchmarks on a single CPU and a single GPU which is equal to 87.5% of the optimal performance. \u00a9 2013 ACM.","code analysis | compilers | gpu | heterogeneous computing | machine learning | runtime system | task partitioning","Proceedings of the International Conference on Supercomputing","Conference Paper","https:\/\/www.doi.org\/10.1145\/2464996.2465007","2-s2.0-84879828287"],["2013-07-11","Biagio Cosenza","LibWater: Heterogeneous distributed computing made easy","Clusters of heterogeneous nodes composed of multi-core CPUs and GPUs are increasingly being used for High Performance Computing (HPC) due to the benefits in peak performance and energy efficiency. In order to fully harvest the computational capabilities of such architectures, application developers often employ a combination of different parallel programming paradigms (e.g. OpenCL, CUDA, MPI and OpenMP), also known in literature as hybrid programming, which makes application development very challenging. Furthermore, these languages offer limited support to orchestrate data and computations for heterogeneous systems. In this paper, we present libWater, a uniform approach for programming distributed heterogeneous computing systems. It consists of a simple interface, compliant with the OpenCL programming model, and a runtime system which extends the capabilities of OpenCL beyond single platforms and single compute nodes. libWater enhances the OpenCL event system by enabling inter-context and inter-node device synchronization. Furthermore, libWater's runtime system uses dependency information enforced by event synchronization to dynamically build a DAG of enqueued commands which enables a class of advanced runtime optimizations. The detection and optimization of collective communication patterns is an example which, as shown by experimental results, improves the efficiency of the libWater runtime system for several application codes. \u00a9 2013 ACM.","distributed computing | heterogeneous computing | opencl, mpi | programming model | runtime system","Proceedings of the International Conference on Supercomputing","Conference Paper","https:\/\/www.doi.org\/10.1145\/2464996.2465008","2-s2.0-84879817919"],["2013-06-11","Carmine Spagnuolo","Designing computational steering facilities for distributed agent based simulations","Agent-Based Models (ABMs) are a class of models which, by simulating the behavior of multiple agents (i.e., ndependent actions, interactions and adaptation), aim to emulate and\/or predict complex phenomena. One of the general features of ABM simulations is their experimental capacity, that requires a viable and reliable infrastructure to interact with a running simulation, monitoring its behaviour, as it proceeds, and applying changes to the configurations at run time, (the computational steering) in order to study \"what if\" scenarios. A common approach for improving the efficiency and the effectiveness of ABMs as a research tool is to distribute the overall computation on a number of machines, which makes the computational steering of the simulation particularly challenging. In this paper, we present the principles and the architecture design of the management and control infrastructure that is available in D-Mason, a framework for implementing distributed ABM simulations. Together with an efficient parallel distribution of the simulation tasks, D-Mason offers a number of facilities to support the computational steering of a simulation, i.e. monitoring and interacting with a running distributed simulation. \u00a9 2013 ACM.","agent-based simulation | computational steering | distributed systems | visualization of distributed models","SIGSIM-PADS 2013 - Proceedings of the 2013 ACM SIGSIM Principles of Advanced Discrete Simulation","Conference Paper","https:\/\/www.doi.org\/10.1145\/2486092.2486147","2-s2.0-84878644426"],["2013-05-29","Biagio Cosenza","GPU cost estimation for load balancing in parallel ray tracing","Interactive ray tracing has seen enormous progress in recent years. However, advanced rendering techniques requiring many million rays per second are still not feasible at interactive speed, and are only possible by means of highly parallel ray tracing. When using compute clusters, good load balancing is crucial in order to fully exploit the available computational power, and to not suffer from the overhead involved by synchronization barriers. In this paper, we present a novel GPU method to compute a cost map: a per-pixel cost estimate of the ray tracing rendering process. We show that the cost map is a powerful tool to improve load balancing in parallel ray tracing, and it can be used for adaptive task partitioning and enhanced dynamic load balancing. Its effectiveness has been proven in a parallel ray tracer implementation tailored for a cluster of workstations.","GPU | Image-based techniques | Parallel rendering | Ray tracing","GRAPP 2013 IVAPP 2013 - Proceedings of the International Conference on Computer Graphics Theory and Applications and International Conference on Information Visualization Theory and Applications","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84878160351"],["2013-03-25","Biagio Cosenza","Automatic problem size sensitive task partitioning on heterogeneous parallel systems","In this paper we propose a novel approach which automatizes task partitioning in heterogeneous systems. Our framework is based on the Insieme Compiler and Runtime infrastructure. The compiler translates a single-device OpenCL program into a multi-device OpenCL program. The runtime system then performs dynamic task partitioning based on an offline-generated prediction model. In order to derive the prediction model, we use a machine learning approach that incorporates static program features as well as dynamic, input sensitive features. Our approach has been evaluated over a suite of 23 programs and achieves performance improvements compared to an execution of the benchmarks on a single CPU and a single GPU only. \u00a9 2013 Authors.","code analysis | compilers | gpu | heterogeneous computing | machine learning | runtime system | task partitioning","Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPOPP","Conference Paper","https:\/\/www.doi.org\/10.1145\/2442516.2442545","2-s2.0-84875205000"],["2013-01-01","Gennaro Cordasco","Bringing together efficiency and effectiveness in distributed simulations: The experience with D-Mason","Agent-based simulation models are an increasingly popular tool for research and management in many fields. In executing such simulations \u201cspeed\u201d is one of the most general and important issues because of the size and complexity of simulations. But another important issue is the effectiveness of the solution, which consists of how easily usable and portable the solutions are for the users, i.e. the programmers of the distributed simulation. Our study, then, is aimed at efficient and effective distribute simulations by adopting a framework-level approach, with our design and implementation of a framework, D-Mason, which is a parallel version of the Mason library for writing and running simulations of agent-based simulation models. In particular, besides the efficiency due to workload distribution with small overhead, D-Mason at a framework level proves itself effective since it enables the scientists that use the framework (domain expert but with limited knowledge of distributed programming) only minimally aware of the fact that the simulation is running on a distributed environment. Then, we present tests that compare D-Mason against Mason in order to assess the improved scalability and D-Mason capability to exploit heterogeneous distributed hardware. Our tests also show that several massive simulations that are impossible to execute on Mason (e.g. because of CPU and\/or memory requirements) can be easily performed using D-Mason. \u00a9 2013, The Society for Modeling and Simulation International. All rights reserved.","Agent-based simulation | distributed Systems | load-balancing | performance evaluation | visualization of distributed models","SIMULATION","Article","https:\/\/www.doi.org\/10.1177\/0037549713489594","2-s2.0-84887120392"],["2013-01-01","Gennaro Cordasco","Youtube emotional database: How to acquire user feedback to build a database of emotional video stimuli","Feedbacks are an important tool for interacting within a social environment where our daily actions are continuously dictated and influenced by others as well as, of course, our actions influence others' choices. \u00a9 2013 IEEE.","Emotional feedback | Social navigation | Tagging | Video stimuli","4th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2013 - Proceedings","Conference Paper","https:\/\/www.doi.org\/10.1109\/CogInfoCom.2013.6719275","2-s2.0-84894172725"],["2012-11-02","Gennaro Cordasco","Minimum weight dynamo and fast opinion spreading (Extended Abstract)","We consider the following multi-level opinion spreading model on networks. Initially, each node gets a weight from the set {0,\u22ef,k\u2208-\u22081}, where such a weight stands for the individuals conviction of a new idea or product. Then, by proceeding to rounds, each node updates its weight according to the weights of its neighbors. We are interested in the initial assignments of weights leading each node to get the value k\u2208-\u22081 -e.g. unanimous maximum level acceptance- within a given number of rounds. We determine lower bounds on the sum of the initial weights of the nodes under the irreversible simple majority rules, where a node increases its weight if and only if the majority of its neighbors have a weight that is higher than its own one. Moreover, we provide constructive tight upper bounds for some class of regular topologies: rings, tori, and cliques. \u00a9 2012 Springer-Verlag Berlin Heidelberg.","information spreading | linear threshold models | multicolored dynamos","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-34611-8_26","2-s2.0-84868035241"],["2012-10-26","Gennaro Cordasco","Enhancing the performances of D-MASON: A motivating example","Agent-based simulation models are an increasingly popular tool for research and management in many, different and diverse fields. In executing such simulations the \"speed\" is one of the most general and important issues and the traditional answer to this issue is to invest resources in deploying a dedicated installation of dedicated computers, with highly specialized parallel applications, devoted to the purpose of achieving extreme computational performances. In this paper we present our experience with a distributed framework, D-MASON, that is a distributed version of MASON, a well-known and popular library for writing and running Agent-based simulations. D-MASON introduces the parallelization at framework level so that scientists that use the framework (domain expert but with limited knowledge of distributed programming) can be only minimally aware of such distribution. The framework allowed only a static decomposition of the work among workers, and was not able to cope with load unbalance among them, therefore incurring in serious performance degradation where, for example, many of the agents were concentrate on one specific part of the space. We elaborated two strategies for ameliorate the balancing and enhance the synchronization among workers. We present their design principles and the experimental tests that validate our approach.","Agent-based simulation | Load-balancing | Performance evaluation | Visualization of distributed models","SIMULTECH 2012 - Proceedings of the 2nd International Conference on Simulation and Modeling Methodologies, Technologies and Applications","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84867712512"],["2012-10-08","Delfina Malandrino","Face-to-face vs. computer-mediated: Analysis of collaborative programming activities and outcomes","In this paper we present the analysis of a laboratory experiment designed to understand the effect of two communication environments, that is, face-to-face or computed-mediated, on group achievements when participants are involved in programming tasks, within an academic computer science course. Results show better students' performances in the computer-mediated setting, as stated by a statistically significant difference between the two approaches when considering the quality of the produced projects, in terms of the teacher's evaluation to pass the final exam. Our analysis shows that the integration of a collaborative instrument in a development environment helps students to achieve better results. \u00a9 2012 IEEE.","collaborative learning | computer-mediated communication | Web Services","Proceedings of the 12th IEEE International Conference on Advanced Learning Technologies, ICALT 2012","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICALT.2012.139","2-s2.0-84867008659"],["2012-10-01","Gennaro Cordasco","On scheduling dag s for volatile computing platforms: Area-maximizing schedules","Many modern computing platforms - notably clouds and desktop grids - exhibit dynamic heterogeneity: the availability and computing power of their constituent resources can change unexpectedly and dynamically, even in the midst of a computation. We introduce a new quality metric, area, for schedules that execute computations having interdependent constituent chores (jobs, tasks, etc.) on such platforms. Area measures the average number of tasks that a schedule renders eligible for execution at each step of a computation. Even though the definition of area does not mention and properties of host platforms (such as volatility), intuition suggests that rendering tasks eligible at a faster rate will have a benign impact on the performance of volatile platforms - and we report on simulation experiments that support this intuition. We derive the basic properties of the area metric and show how to efficiently craft area-maximizing (A-M) schedules for several classes of significant computations. Simulations that compare A-M scheduling against heuristics ranging from lightweight ones (e.g., FIFO) to computationally intensive ones suggest that A-M schedules complete computations on volatile heterogeneous platforms faster than their competition, by percentages that vary with computation structure and platform behavior - but are often in the double digits. \u00a9 2012 Elsevier Inc. All rights reserved.","Cloud computing | dag scheduling | Desktop grids | Scheduling for dynamically heterogeneous platforms | Volunteer computing","Journal of Parallel and Distributed Computing","Article","https:\/\/www.doi.org\/10.1016\/j.jpdc.2012.06.007","2-s2.0-84865063121"],["2012-03-01","Vittorio Scarano","A novel intermediary framework for dynamic edge service composition","Multimedia content, user mobility and heterogeneous client devices require novel systems that are able to support ubiquitous access to the Web resources. In this scenario, solutions that combine flexibility, efficiency and scalability in offering edge services for ubiquitous access are needed. We propose an original intermediary framework, namely Scalable Intermediary Software Infrastructure (SISI), which is able to dynamically compose edge services on the basis of user preferences and device characteristics. The SISI framework exploits a per-user profiling mechanism, where each user can initially set his\/her personal preferences through a simple Web interface, and the system is then able to compose at run-time the necessary components. The basic framework can be enriched through new edge services that can be easily implemented through a programming model based on APIs and internal functions. Our experiments demonstrate that flexibility and edge service composition do not affect the system performance. We show that this framework is able to chain multiple edge services and to guarantee stable performance. \u00a9 2012 Springer Science+Business Media, LLC & Science Press, China.","Edge service | Intermediary framework | Performance | Service flow | Ubiquitous Web","Journal of Computer Science and Technology","Article","https:\/\/www.doi.org\/10.1007\/s11390-012-1223-2","2-s2.0-84861636834"],["2012-01-01","Vittorio Scarano","FunEuler: An euler diagram based interface enhanced with region-based functionalities","Euler Diagrams are an accessible means of representing non hierarchical set-based relationships which have recently been used in resource management interfaces to facilitate user categorisation. We develop a novel, extensible Euler diagram based interface, called FunEuler, which integrates the concepts of visual classification, spatial arrangements and functional application, thereby greatly extending the power of such Euler diagram based interfaces by enabling fast application of a collection of predefined functions to collections of categorised resources. To demonstrate the principle, we provide several functionalities such as file zipping or creating playlists within the application, whilst also providing a mechanism to extend the functionality to facilitate end user development. Preliminary user testing suggests that the Euler diagram concept is easily comprehensible for resource categorisation purposes, the concept and application of functions can be understood and applied successfully, and that users perceived the addition of functions increased the usefulness of the application for repetitive tasks.",null,"CEUR Workshop Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84892575353"],["2012-01-01","Vittorio Scarano","A framework for distributing agent-based simulations","Agent-based simulation models are an increasingly popular tool for research and management in many, different and diverse fields. In executing such simulations the \"speed\" is one of the most general and important issues. The traditional answer to this issue is to invest resources in deploying a dedicated installation of dedicated computers. In this paper we present a framework that is a parallel version of the Mason, a library for writing and running Agent-based simulations. \u00a9 2012 Springer-Verlag Berlin Heidelberg.","Agent-based simulation | Distributed Systems | Heterogeneous Computing | Load-Balancing","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-29737-3_51","2-s2.0-84878637675"],["2012-01-01","Gennaro Cordasco","The online abstraction problem for Euler diagrams","A Euler diagrams are an accessible and effective visualisation of data involving simple set-theoretic relationships. Efficient algorithms to quickly compute the abstract regions of an Euler diagram upon curve addition and removal have been developed, but a strict set of drawing conventions (called wellformed-ness conditions) were enforced, meaning that some abstract diagrams are not representable as concrete diagrams. We present a variation and extension of the methodology which enables region computations for Euler diagrams under the relaxation of several drawing conventions. We provide complexity analysis and compare with the previous methodology. The algorithms are presented for generic curves, allowing for specialisations such as utilising fixed geometric shapes for curves that often occur in applications.",null,"CEUR Workshop Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84892573213"],["2011-12-01","Delfina Malandrino","Supportive, comprehensive and improved privacy protection for web browsing","Protecting users privacy on the Web is becoming increasingly complicated because of the silent actions of third party sites that spy, collect data, aggregate information and build profiles, transparently to end users, to provide targeted advertising. On the Web, users are loudly concerned about the large amount of information left in many locations during their navigation and claim more protection to safely conduct their online activities. We present, in this paper, a supportive, comprehensive and improved approach for privacy protection to allow users to be aware of the risks of their navigation and to give them full control on effective actions to address online privacy threats. Our approach is validated by a Mozilla Firefox extension, NoTrace, that provides the feasibility of the techniques, and whose efficiency is thoroughly tested on an extensive data set for effectiveness, impact on users experience and performances. \u00a9 2011 IEEE.",null,"Proceedings - 2011 IEEE International Conference on Privacy, Security, Risk and Trust and IEEE International Conference on Social Computing, PASSAT\/SocialCom 2011","Conference Paper","https:\/\/www.doi.org\/10.1109\/PASSAT\/SocialCom.2011.77","2-s2.0-84856204709"],["2011-10-01","Vittorio Scarano","COCOMAPS: A web application to analyze and visualize contacts at the interface of biomolecular complexes","Herein we present COCOMAPS, a novel tool for analyzing, visualizing and comparing the interface in protein-protein and protein-nucleic acids complexes. COCOMAPS combines traditional analyses and 3D visualization of the interface with the effectiveness of intermolecular contact maps. \u00a9 The Author 2011. Published by Oxford University Press. All rights reserved.",null,"Bioinformatics","Note","https:\/\/www.doi.org\/10.1093\/bioinformatics\/btr484","2-s2.0-80053998922"],["2011-09-26","Vittorio Scarano","An interactive bio-inspired approach to clustering and visualizing datasets","In this work, we present an interactive visual clustering approach for the exploration and analysis of datasets using the computational power of Graphics Processor Units (GPUs). The visualization is based on a collective behavioral model that enables cognitive amplification of information visualization. In this way, the workload of understanding the representation of information moves from the cognitive to the perceptual system. The results enable a more intuitive, interactive approach to the discovery of knowledge. The paper illustrates this behavioral model for clustering data, and applies it to the visualization of a number of real and synthetic datasets. \u00a9 2011 IEEE.","behavioral model | GPU | highdimensional datasets | visual clustering","Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV.2011.16","2-s2.0-80053037911"],["2011-09-08","Gennaro Cordasco","Assessing the computational benefits of AREA-oriented DAG-scheduling","Many modern computing platforms, including \"aggressive\" multicore architectures, proposed exascale architectures, and many modalities of Internet-based computing are \"task hungry\"-their performance is enhanced by always having as many tasks eligible for allocation to processors as possible. The AREA-Oriented scheduling (AO-scheduling) paradigm for computations with intertask dependencies-modeled as dags-was developed to address the \"hunger\" of such platforms, by executing an input dag so as to render tasks eligible for execution quickly. AO-scheduling is a weaker, but more robust, successor to IC-scheduling. The latter renders tasks eligible for execution maximally fast-a goal that is not achievable for many dag s. AO-scheduling coincides with IC-scheduling on dags that admit optimal IC-schedules-and optimal AO-scheduling is possible for all dag s. The computational complexity of optimal AO-scheduling is not yet known; therefore, this goal is replaced here by a multi-phase heuristic that produces optimal AO-schedules for series-parallel dags but possibly suboptimal schedules for general dags. This paper employs simulation experiments to assess the computational benefits of AO-scheduling in a variety of scenarios and on a range of dags whose structure is reminiscent of ones encountered in scientific computing. The experiments pit AO-scheduling against a range of heuristics, from lightweight ones such as FIFO scheduling to computationally more intensive ones that mimic IC-scheduling's local decisions. The observed results indicate that AO-scheduling does enhance the efficiency of task-hungry platforms, by amounts that vary according to the availability patterns of processors and the structure of the dag being executed. \u00a9 2011 Springer-Verlag.","Area-oriented dag-scheduling | Scheduling for task-hungry platforms","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-23400-2_18","2-s2.0-80052365291"],["2011-08-11","Vittorio Scarano","A GPU-based interactive bio-inspired visual clustering","In this work, we present an interactive visual clustering approach for the exploration and analysis of vast volumes of data. Our proposed approach is a bio-inspired collective behavioral model to be used in a 3D graphics environment. Our paper illustrates an extension of the behavioral model for clustering and a parallel implementation, using Compute Unified Device Architecture to exploit the computational power of Graphics Processor Units (GPUs). The advantage of our approach is that, as data enters the environment, the user is directly involved in the data mining process. Our experiments illustrate the effectiveness and efficiency provided by our approach when applied to a number of real and synthetic data sets. \u00a9 2011 IEEE.",null,"IEEE SSCI 2011: Symposium Series on Computational Intelligence - CIDM 2011: 2011 IEEE Symposium on Computational Intelligence and Data Mining","Conference Paper","https:\/\/www.doi.org\/10.1109\/CIDM.2011.5949300","2-s2.0-79961191210"],["2011-07-11","Gennaro Cordasco","Personalised resource categorisation using Euler Diagrams","The categorisation of information is a very common practice. Often, the user may need to use multiple hierarchies or require multiple characterisations to be active at the same time, or they may wish to define cross-cutting groups for special purposes. The work developed in this paper is aimed at providing a flexible, seamless management of various ways of organising the required information. The concept of a set is adopted as the fundamental notion of information organisation, and, in particular, the familiar visual representation of sets and their relationships in terms of Euler Diagrams is used. We facilitate the visualisation of sets, enabling the application of functions to items presented in regions of the diagram corresponding to set, or category, intersections. We present a system that realises this novel concept, together with rationale for the choices made in its development, as well as a simple scenario of use. \u00a9 2011 Springer-Verlag.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-21530-8_22","2-s2.0-79959998512"],["2011-04-26","Vittorio Scarano","Distributed load balancing for parallel agent-based simulations","We focus on agent-based simulations where a large number of agents move in the space, obeying to some simple rules. Since such kind of simulations are computational intensive, it is challenging, for such a contest, to let the number of agents to grow and to increase the quality of the simulation. A fascinating way to answer to this need is by exploiting parallel architectures. In this paper, we present a novel distributed load balancing schema for a parallel implementation of such simulations. The purpose of such schema is to achieve an high scalability. Our approach to load balancing is designed to be lightweight and totally distributed: the calculations for the balancing take place at each computational step, and inluences the successive step. To the best of our knowledge, our approach is the first distributed load balancing schema in this context. We present both the design and the implementation that allowed us to perform a number of experiments, with up-to 1, 000, 000 agents. Tests show that, in spite of the fact that the load balancing algorithm is local, the workload distribution is balanced while the communication overhead is negligible. \u00a9 2011 IEEE.","Behavioral Simulations | Distributed Computing | Parallel Algorithms","Proceedings - 19th International Euromicro Conference on Parallel, Distributed, and Network-Based Processing, PDP 2011","Conference Paper","https:\/\/www.doi.org\/10.1109\/PDP.2011.22","2-s2.0-79955018893"],["2011-03-01","Gennaro Cordasco","On clustering DAGs for task-hungry computing platforms","Many modern computing platforms are \"task-hungry\": Their performance is enhanced by always having as many tasks available for execution as possible. IC-scheduling, a master-worker framework for executing static computations that have intertask dependencies (modeled as dags), was developed with precisely the goal of rendering a computation-dag's tasks eligible for execution at the maximum possible rate. The current paper addresses the problem of enhancing IC-scheduling so that it can accommodate the varying computational resources of different workers, by clustering a computation-dag's tasks, while still producing eligible (now, clustered) tasks at the maximum possible rate. The task-clustering strategies presented exploit the structure of the computation being performed, ranging from a strategy that works for any dag, to ones that build increasingly on the explicit structure of the dagbeing scheduled.","scheduling dags | scheduling for heterogeneous computing platforms | scheduling for task-hungry computing platforms","Open Computer Science","Article","https:\/\/www.doi.org\/10.2478\/s13537-011-0002-4","2-s2.0-84984834954"],["2011-01-01","Gennaro Cordasco","Efficient on-line algorithms for Euler diagram region computation","Euler diagrams are an accessible and effective visualisation of data involving simple set-theoretic relationships. Sets are represented by closed curves in the plane and often have wellformedness conditions placed on them in order to enhance comprehensibility. The theoretical underpinning for tool support has usually focussed on the problem of generating an Euler diagram from an abstract model. However, the problem of efficient computation of the abstract model from the concrete diagram has not been addressed before, despite this computation being a necessity for computer interpretations of user drawn diagrams. This may be used, together with automated manipulations of the abstract model, for purposes such as semantic information presentation or diagrammatic theorem proving. Furthermore, in interactive settings, the user may update diagrams \"on-line\" by adding and removing curves, for example, in which case a system requirement is the update of the abstract model (without the necessity of recomputation of the entire abstract model). We define the notion of marked Euler diagrams, together with a method for associating marked points on the diagram with regions in the plane. Utilising these, we provide on-line algorithms which quickly compute the abstract model of a weakly reducible wellformed Euler diagram (constructible as a sequence of additions or removals of curves, keeping a wellformed diagram at each step), and quickly updates both the set of curves in the plane as well as the abstract model according to the on-line operations. Efficiency is demonstrated by comparison with a common, naive algorithm. Furthermore, the methodology enables a straightforward implementation which has subsequently been realised as an application for the user classification domain. \u00a9 2010 Elsevier B.V. All rights reserved.","Diagram generation | Euler diagrams | Region computation","Computational Geometry: Theory and Applications","Article","https:\/\/www.doi.org\/10.1016\/j.comgeo.2010.07.003","2-s2.0-77956228856"],["2011-01-01","Vittorio Scarano","Collaborative diagram drawing: A case study on scaffolding self-regulated behaviors","In this paper we present a case study of collaborative diagram drawing involving 36 students in Computer Science. Their task was to collaboratively draw a Use Case Diagram about the scenarios provided at the begin of the experiment. As students of a Software Engineering course, they had a general knowledge of such type of diagrams and related terminology, but they were not experts and had not real and practical experiences in diagram drawing. The tools used were a synchronous collaborative drawing tool integrated with a chat tool to support communication among the participants. Moreover, the experiment has been structured following the 'think, pair, share' method. The analysis of the collaboration process outlines a twofold result: first, a significant equal participation of all the students and second, an implicit and recurrent self-regulatory behavior employed by the students to create and refine the diagram and to reach agreement about the final result.",null,"CEUR Workshop Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84891072915"],["2010-12-07","Vittorio Scarano","BehaveRT: A GPU-based library for autonomous characters","In this work, we present a GPU-based library, called BehaveRT, for the definition, real-time simulation, and visualization of large communities of individuals. We implemented a modular flexible and extensible architecture based on a plug-in infrastructure that enables the creation of a behavior engine system core. We used Compute Unified Device Architecture to perform parallel programming and specific memory optimization techniques to exploit the computational power of commodity graphics hardware, enabling developers to focus on the design and implementation of behavioral models. This paper illustrates the architecture of BehaveRT, the core plug-ins, and some case studies. In particular, we show two high-level behavioral models, picture and shape flocking, that generate images and shapes in 3D space by coordinating the positions and color-coding of individuals. We, then, present an environment discretization case study of the interaction of a community with generic virtual scenes such as irregular terrains and buildings. \u00a9 2010 Springer-Verlag Berlin Heidelberg.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-16958-8_19","2-s2.0-78649674621"],["2010-12-03","Gennaro Cordasco","Improved load balancing on distributed massive simulation environments","In this paper, we report the findings we gathered in designing and implementing a system that provides a distributed massive simulation environment. Massive Battle is a system capable of simulating historical battles for the purpose of learning and to carry out historical researches (e.g. what-if scenarios). We present a distributed implementation of Massive Battle and some early tests. We report and discuss some analysis of the problems related to the workload distribution in this particular environment. We report how is possible to measure a better load balancing by adopting a more general scheme of computation that generalize the assignments that each peer has to complete together with simulation. \u00a9 2010 Springer-Verlag Berlin Heidelberg.","Load Balancing | Massive Simulation | Peer-to-Peer systems","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-16961-8_78","2-s2.0-78649498809"],["2010-12-01","Gennaro Cordasco","Experiences with a P2P infrastructure for massive simulations","Massive Multiuser Virtual Environments (MMVEs) are rapidly expanding both in the number of users and complexity of interactions. Their needs of computational resources offer new challenges for the computer scientists. In this paper we present an implementation and some early tests of a Massive Simulation Environments, a particular MMVE, distributed over a Peer-to-Peer infrastructure. We provide some analysis of the problems related to the workload distribution in this environment. Simulation tests show a good grade of scalability and the communication overhead, due to the peers interaction, is dominated by the computational power provided by them. Copyright \u00a9 IARIA, 2010.","Load Balancing | Massive Simulation | Peer-to-Peer","AP2PS 2010 - 2nd International Conference on Advances in P2P Systems","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84882958184"],["2010-12-01","Gennaro Cordasco","Community detection via semi-synchronous label propagation algorithms","A recently introduced novel community detection strategy is based on a label propagation algorithm (LPA) which uses the diffusion of information in the network to identify communities. Studies of LPAs showed that the strategy is effective in finding a good community structure. Label propagation step can be performed in parallel on all nodes (synchronous model) or sequentially (asynchronous model); both models present some drawback, e.g., algorithm termination is nor granted in the first case, performances can be worst in the second case. In this paper, we present a semi-synchronous version of LPA which aims to combine the advantages of both synchronous and asynchronous models. We prove that our models always converge to a stable labeling. Moreover, we experimentally investigate the effectiveness of the proposed strategy comparing its performance with the asynchronous model both in terms of quality, efficiency and stability. Tests show that the proposed protocol does not harm the quality of the partitioning. Moreover it is quite efficient; each propagation step is extremely parallelizable and it is more stable than the asynchronous model, thanks to the fact that only a small amount of randomization is used by our proposal. \u00a9 2010 IEEE.",null,"2010 IEEE International Workshop on Business Applications of Social Network Analysis, BASNA 2010","Conference Paper","https:\/\/www.doi.org\/10.1109\/BASNA.2010.5730298","2-s2.0-79953745000"],["2010-11-19","Gennaro Cordasco","Area-maximizing schedules for series-parallel DAGs","Earlier work introduced a new optimization goal for dag schedules: the \"AREA\" of the schedule. AREA-maximizing schedules are intended for computational environments - such as Internet-based computing and massively multicore computers - that benefit from dag-schedules that produce execution-eligible tasks as fast as possible. The earlier study of AREA-maximizing schedules showed how to craft such schedules efficiently for dags that have the structure of trees and other, less well-known, families of dags. The current paper extends the earlier work by showing how to efficiently craft AREA-maximizing schedules for series-parallel dags, a family that arises, e.g., in multi-threaded computations. The tools that produce the schedules for series-parallel dags promise to apply also to other large families of computationally significant dags. \u00a9 2010 Springer-Verlag.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-15291-7_35","2-s2.0-78249255184"],["2010-11-08","Vittorio Scarano","Argumentation tools in a collaborative development environment","In the field of Computer Supported Collaborative Work several studies have explored the possibility to improve the collaboration in software development teams by integrating into IDEs tools to support the coordination and sharing of common resources. Similar studies have emphasized the need of integrating into IDEs collaboration and communication functionalities to improve the building of a shared knowledge. In this paper we describe how we enhanced Rational Team Concert (an IBM CDVE built on Eclipse and Jazz) with structured communication tools by integrating a collaborative platform named CoFFEE, that was developed for structured argumentation and discussion in an educational setting. \u00a9 2010 Springer-Verlag Berlin Heidelberg.","Collaborative IDE | CSCW | structured communication tools","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-16066-0_6","2-s2.0-78049364462"],["2010-11-08","Vittorio Scarano","Free-riding in collaborative diagrams drawing","In this paper, we study the issue of free-riding in collaborative learning. Free-riding occurs when a part of the students lean on the efforts of the rest of their team and do not contribute much to the team work. It impacts negatively on performances of the whole team [1]. We present an experiment of collaborative diagram drawing (through a synchronous collaborative drawing tool, called Shared Drawing tool) in a Software Engineering course, that shows a significant equal participation and suggests that students employ some self-regulatory behaviors that results in fruitful collaboration. \u00a9 2010 Springer-Verlag Berlin Heidelberg.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-16020-2_37","2-s2.0-78049355017"],["2010-05-01","Vittorio Scarano","MIMOSA: Context-aware adaptation for ubiquitous web access","The ubiquitous computing scenario is characterized by heterogeneity of devices used to access services, and by frequent changes in the user's context. Hence, adaptation according to the user's context and the used devices is necessary to allow mobile users to efficiently exploit Internet-based services. In this paper, we present a distributed framework, named MIMOSA, that couples a middleware for context-awareness with an intermediary-based architecture for content adaptation. MIMOSA provides an effective and efficient solution for the adaptation of Internet services on the basis of a comprehensive notion of context, by means of techniques for aggregating context data from distributed sources, deriving complex contextual situations from raw sensor data, evaluating adaptation policies, and solving possible conflicts. The middleware allows programmers to modularly build complex adaptive services starting from simple ones, and includes tools for assisting the user in declaring her preferences, as well as mechanisms for detecting incorrect system behaviors due to a wrong choice of adaptation policies. The effectiveness and efficiency of MIMOSA are shown through the development of a prototype adaptive service, and by extensive experimental evaluations. \u00a9 2009 Springer-Verlag London Limited.","Adaptation | Context-awareness | Transcoding","Personal and Ubiquitous Computing","Article","https:\/\/www.doi.org\/10.1007\/s00779-009-0232-9","2-s2.0-77957130110"],["2010-03-01","Gennaro Cordasco","Extending IC-scheduling via the Sweep Algorithm","A key challenge when scheduling computations over the Internet is temporal unpredictability: remote \"workers\" arrive and depart at unpredictable times and often provide unpredictable computational resources; the time for communication over the Internet is impossible to predict accurately. In response, earlier research has developed the underpinnings of a theory of how to schedule computations having intertask dependencies in a way that renders tasks eligible for execution at the maximum possible rate. Simulation studies suggest that such scheduling: (a) utilizes resource providers' computational resources well, by enhancing the likelihood of having work to allocate to an available client; (b) lessens the likelihood of a computation's stalling for lack of tasks that are eligible for execution. The applicability of the current version of the theory is limited by its demands on the structure of the dag that models the computation being scheduled-namely, that the dag be decomposable into connected bipartite \"building-block\" dags. The current paper extends the theory by developing the Sweep Algorithm, which takes a significant step toward removing this restriction. The resulting augmented suite of scheduling algorithms allows one to craft optimal schedules for a large range of dags that the earlier framework could not handle. Most of the newly optimally scheduled dags presented here are artificial but \"close\" in structure to dags that arise in real computations; one of the new dags is a component of a large dag that arises in a functional Magnetic Resonance Imaging application. \u00a9 2009 Elsevier Inc.","Global computing | Grid computing | IC-scheduling | IC-scheduling theory | Internet-based computing | Scheduling dags | Theory","Journal of Parallel and Distributed Computing","Article","https:\/\/www.doi.org\/10.1016\/j.jpdc.2009.11.001","2-s2.0-74449085283"],["2010-01-01","Vittorio Scarano","Learning computer supported collaborative problem solving: A case study in postgraduate education","The paper presents a case study about the first introduction of the collaborative environment CoFFEE and its educational approach within the DAOSan Masters course in Leadership in Health-care Services. First, the pedagogical and technological aspects of CoFFEE-supported activities are presented. Then, the context of the DAOSan problem-solving-based approach is described. The case study of a training scenario is discussed, in order to draw a methodology fostering reflexivity, collaboration and situated learning in management training. \u00a9 Springer-Verlag 2010.",null,"Management of the Interconnected World - ItAIS: The Italian Association for Information Systems","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-7908-2404-9_53","2-s2.0-84901649569"],["2010-01-01","Delfina Malandrino","Introducing collaboration in single-user applications through the centralized control architecture","In this paper we describe a novel Model-View-Controller based architecture, Centralized Control, that introduces collaboration in single-users applications. The architecture is able to add collaboration with no need to modify the source code of the original single-user application, and providing also the capability to introduce group semantics into the new, collaborative application that is obtained. The architecture is shown in practice, by introducing CollabXMind, a collaborative mind map tool, that is based on a well-known single-user tool, XMind. \u00a9 2010 ICST.",null,"Proceedings of the 6th International Conference on Collaborative Computing: Networking, Applications and Worksharing, CollaborateCom 2010","Conference Paper","https:\/\/www.doi.org\/10.4108\/icst.collaboratecom.2010.19","2-s2.0-79957860678"],["2010-01-01","Vittorio Scarano","Theory and algorithms for parallel computation","Parallelism concerns all levels of current computing systems, from single CPU machines to large server farms. Effective use of parallelism relies crucially on the availability of suitable models of computation for algorithm design and analysis, and of efficient strategies for the solution of key computational problems on prominent classes of platforms, as well as of good models of the way the different components are interconnected. With the advent of multicore parallel machines, new models and paradigms are needed to allow parallel programming to advance into mainstream computing.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-15291-7_33","2-s2.0-85037716773"],["2009-12-01","Vittorio Scarano","An efficient GPU implementation for large scale individual-based simulation of collective behavior","In this work we describe a GPU implementation for an individual-based model for fish schooling. In this model each fish aligns its position and orientation with an appropriate average of its neighbors positions and orientations. This carries a very high computational cost in the so-called nearest neighbors search. By leveraging the GPU processing power and the new programming model called CUDA we implement an efficient framework which permits to simulate the collective motion of high-density individual groups. In particular we present as a case study a simulation of motion of millions of fishes. We describe our implementation and present extensive experiments which demonstrate the effectiveness of our GPU implementation.","gpu | Individual-based model | Simulation","HiBi09 - 2009 International Workshop on High Performance Computational Systems Biology","Conference Paper","https:\/\/www.doi.org\/10.1109\/HiBi.2009.11","2-s2.0-73449092839"],["2009-12-01","Gennaro Cordasco","Interactive visual classification with Euler diagrams","We present the theoretical foundation, the design and the implementation of a library, called EulerVC to interactively handle Euler diagrams for the purposes of resource management. Fast on-line algorithms to interpret wellformed diagrams have been developed utilising a new notion of marked points to keep track of the zone sets. The interface allows the construction of overlapping ellipses to represent categories together with the drag and drop of resources in order to categorise them. A visual indicator can be used to show if the diagram under construction is not wellformed to assist in reducing user mistakes, and sets of tags can be assigned to resources upon export. The generic approach is demonstrated via an integration with the bookmarking site del.icio.us. \u00a92009 IEEE.",null,"2009 IEEE Symposium on Visual Languages and Human-Centric Computing, VL\/HCC 2009","Conference Paper","https:\/\/www.doi.org\/10.1109\/VLHCC.2009.5295265","2-s2.0-73449085134"],["2009-12-01","Gennaro Cordasco","Some considerations on the design of a P2P infrastructure for massive simulations","Massive Multiuser Virtual Environments (MMVEs) are rapidly expanding both in the number of users and complexity of interactions. Their needs of computational resources offer new challenges for the computer scientists. In this paper we present some ideas on the implementation of a Massive Simulation Environments, a particular MMVE, distributed over a Peer-to-Peer infrastructure. We analyze some of the problems related to the workload balancing on such distributed environments. In particular we discuss an hybrid Peer-to-Peer architecture in order to provide an efficient load balancing strategy. By some assumptions on temporal and spatial coherence, we use a predictor component which exploits previous phase workload as an estimate for next phase workload for load balancing purposes. \u00a9 2009 IEEE.","Load balancing | Massive simulation | Peer-to-peer","2009 International Conference on Ultra Modern Telecommunications and Workshops","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICUMT.2009.5345386","2-s2.0-74549186390"],["2009-11-27","Vittorio Scarano","Computer-Supported webquests","WebQuests are among the most popular techniques to enhance collaboration in learning; they are an inquiry-based activity, grounded on constructivist learning theory, where the information that learners interact with is mostly found on the Internet. We present here a system that offers computer-support during a WebQuest, by offering a structured discussion and debate space, besides the navigation and resource sharing. We integrate the WebQuest design process with an operational design phase and describe how our system can completely support the design of a computer-supported WebQuest. \u00a9 2009 Springer Berlin Heidelberg.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-642-04636-0_73","2-s2.0-70450215232"],["2009-11-26","Gennaro Cordasco","On scheduling dags to maximize area","A new quality metric, called area, is introduced for schedules that execute dags, i.e., computations having intertask dependencies. Motivated by the temporal unpredictability encountered when computing over the Internet, the goal under the new metric is to maximize the average number of tasks that are eligible for execution at each step of a computation. Area-maximization is a weakening of ICoptimality, which strives to maximize the number of eligible tasks at every step of the computation. In contrast to IC-optimal schedules, area-maximizing schedules exist for every dag. For dags that admit IC-optimal schedules, all area-maximizing schedules are IC-optimal, and vice versa. The basic properties of this metric are derived in this paper, and tools for efficiently crafting area-maximizing schedules for large classes of computationally significant dags are developed. Several of these results emerge from a close connection between area-maximizing scheduling and the MAX Linear-Arrangement Problem for Dags. \u00a9 2009 IEEE.",null,"IPDPS 2009 - Proceedings of the 2009 IEEE International Parallel and Distributed Processing Symposium","Conference Paper","https:\/\/www.doi.org\/10.1109\/IPDPS.2009.5160983","2-s2.0-70450212119"],["2009-11-25","Vittorio Scarano","Relaxed-2-Chord: Efficiency, flexibility and provable stretch","Several proposals have been presented to supplement the traditional measure of routing efficiency in P2P networks, i.e. the (average) number of hops for lookup operations, with measures of the latency incurred in the underlying network. So far, no solution has been presented to this \"latency\" problem without incurring in extra and heavy management costs. We propose Relaxed-2-Chord, a new design of the traditional Chord protocol, that is able to fit the routing tables with low latency nodes, doing a parasitic measurement of nodes' latency without adding any overhead. The solution that we present is a Distributed Hash Table system whose aim is to combine the routing efficiency and flexibility of the Chord protocol - i.e. a good degree\/diameter tradeoff - and a provable optimal hop by hop latency. Our work is inspired by the recent Lookup-parasitic random sampling (LPRS) strategies which allow to improve the network stretch, that is, the ratio between the latency of two nodes on the overlay network and the unicast latency between those nodes. Relaxed-2-Chord reaches the same results as LPRS without introducing any overhead. \u00a9 2009 IEEE.",null,"IPDPS 2009 - Proceedings of the 2009 IEEE International Parallel and Distributed Processing Symposium","Conference Paper","https:\/\/www.doi.org\/10.1109\/IPDPS.2009.5160951","2-s2.0-70449823666"],["2009-11-06","Gennaro Cordasco","Navigable Small-World networks with few random bits","Westudy Small-World graphs in the perspective of their use in the development of efficient as well as easy to implement network infrastructures. Our analysis starts from the Small- World model proposed by Kleinberg: a grid network augmented with directed long-range random links. The choices of the long-range links are independent from one node to another. In this setting greedy routing and some of its variants have been analyzed and shown to produce paths of polylogarithmic expected length. We start from asking whether all the randomness, used in Kleinberg's model for establishing the long-range contacts of the nodes, is indeed necessary to assure the existence of short paths. In order to deal with the above question, we impose (stringent) restrictions on the choice of long-range links and we show that such restrictions do not increase the average path length of greedy routing and its variations. We are able to decrease the number of random bits, required to establish each node's long-range link, from .log n\/ to O.log log n\/ on a network of size n. Diminishing the randomness in the choice of random links has several benefits; in particular, it implies an increase in the clustering of the graph, thus increasing the resilience of the network. \u00a9 2009 Elsevier B.V. All rights reserved.","Complex networks | Greedy routing | Kleinberg's model | Small-World networks","Theoretical Computer Science","Article","https:\/\/www.doi.org\/10.1016\/j.tcs.2009.07.050","2-s2.0-84858702231"],["2009-06-01","Gennaro Cordasco","Degree-optimal routing for P2P systems","We define a family of Distributed Hash Table systems whose aim is to combine the routing efficiency of randomized networks-e.g. optimal average path length O(log\u22082 n\/\u03b4log\u2208\u03b4) with \u03b4 degree-with the programmability and startup efficiency of a uniform overlay-that is, a deterministic system in which the overlay network is transitive and greedy routing is optimal. It is known that \u03a9(log\u2208n) is a lower bound on the average path length for uniform overlays with O(log\u2208n) degree (Xu et al., IEEE J. Sel. Areas Commun. 22(1), 151-163, 2004). Our work is inspired by neighbor-of-neighbor (NoN) routing, a recently introduced variation of greedy routing that allows us to achieve optimal average path length in randomized networks. The advantage of our proposal is that of allowing the NoN technique to be implemented without adding any overhead to the corresponding deterministic network. We propose a family of networks parameterized with a positive integer c which measures the amount of randomness that is used. By varying the value c, the system goes from the deterministic case (c=1) to an \"almost uniform\" system. Increasing c to relatively low values allows for routing with asymptotically optimal average path length while retaining most of the advantages of a uniform system, such as easy programmability and quick bootstrap of the nodes entering the system. We also provide a matching lower bound for the average path length of the routing schemes for any c. \u00a9 2007 Springer Science+Business Media, LLC.","Greedy routing | Overlay network | Peer-to-peer","Theory of Computing Systems","Article","https:\/\/www.doi.org\/10.1007\/s00224-007-9074-x","2-s2.0-65549116094"],["2009-05-01","Vittorio Scarano","SambVca: A web application for the calculation of the buried volume of N-heterocyclic carbene ligands","We present a free web application for the calculation of theburied volume (%VBur) of NHC ligands. The web applicationprovides a graphic and user-friendly interface to theSambVca program, developed for the calculation of %VBurvalues not only of NHC ligands but also of other classic orga-nometallic ligands such as, for example, phosphanes and cy-clopentadienyl-based ligands. To provide a reliable procedure for the calculation of %VBur values we tested our ap-proach in the interpretation of the binding energies of NHCligands in Cp*Ru (NHC)Cl complexes in terms of steric andelectronic parameters. \u00a9 Wiley-VCH Verlag GmbH & Co. KGaA, 69451 Weinheim, Germany, 2009.","Buriedvolumes | Carbene ligands | Density functional calculations | Homogeneous catalysis | Ligand effects | N-Heterocyclic carbenes | Steric hindrance","European Journal of Inorganic Chemistry","Article","https:\/\/www.doi.org\/10.1002\/ejic.200801160","2-s2.0-66149192545"],["2009-01-01","Vittorio Scarano","Experiences with mesh-like computations using prediction binary trees","In this paper we aim at exploiting the temporal coherence among successive phases of a computation, in order to implement a load-balancing technique in mesh-like computations to be mapped on a cluster of processors. A key concept, on which the load balancing schema is built on, is the use of a Predictor component that is in charge of providing an estimation of the unbalancing between successive phases. By using this information, our method partitions the computation in balanced tasks through the Prediction Binary Tree (PBT). At each new phase, current PBT is updated by using previous phase computing time for each task as next-phase's cost estimate. The PBT is designed so that it balances the load across the tasks as well as reduces dependency among processors for higher performances. Reducing dependency is obtained by using rectangular tiles of the mesh, of almost-square shape (i. e. one dimension is at most twice the other). By reducing dependency, one can reduce inter-processors communication or exploit local dependencies among tasks (such as data locality). Furthermore, we also provide two heuristics which take advantage of data-locality. Our strategy has been assessed on a significant problem, Parallel Ray Tracing. Our implementation shows a good scalability, and improves performance in both cheaper commodity cluster and high performance clusters with low latency networks. We report different measurements showing that tasks granularity is a key point for the performances of our decomposition\/mapping strategy.","Load balancing | Mesh-like computation | Performance evaluation | Performance prediction | Scheduling","Scalable Computing","Article","https:\/\/www.doi.org\/None","2-s2.0-74549125874"],["2008-12-01","Gennaro Cordasco","On estimating the effectiveness of temporal and spatial coherence in parallel ray tracing","In this paper we estimate the effectiveness of exploiting coherence in Parallel Ray Tracing. We present a loadbalancing technique which divides the original rendering problem in balanced subtasks and distribute them to independent processors through a Prediction Binary Tree (PBT). Furthermore the PBT allows to exploit temporal coherence among successive image frames. At each new frame, it updates the current PBT using a cost function which uses the previous rendering time as cost estimate. We also provide two heuristics which take advantage of data-locality. We assess the effectiveness of the proposed solution by running two experiments. The first one aims to investigate the accurancy of predictions made using the PBT. Results show that such predictions are quite accurate even considering a heavily unbalanced scene and a fast moving camera. The second experiment evaluates the two locality-aware heuristics showing a modest improvement. \u00a9 The Eurographics Association 2008.",null,"6th Eurographics Italian Chapter Conference 2008 - Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84878186915"],["2008-12-01","Gennaro Cordasco","F-Chord: Improved uniform routing on chord","We propose a family of novel Chord-based P2P schemes retaining all positive aspects that made Chord a popular topology for routing in P2P networks. The schemes, based on the Fibonacci number system, allow to simultaneously improve on the maximum\/average number of hops for lookups and the routing table size per node. \u00a9 2008 Wiley Periodicals, Inc.","Fibonacci numbers | Greedy routing | Overlay network | Peer-to-peer | Uniform routing","Networks","Article","https:\/\/www.doi.org\/10.1002\/net.20253","2-s2.0-56749156300"],["2008-12-01","Biagio Cosenza","A survey on exploiting grids for ray tracing","Grid is one of the first data structure introduced at the very beginning of computer graphics. Grids are used in several applications of computer graphics, especially in rendering algorithms. Lately, in ray tracing dynamic scenes, grid has received attention for its appealing linear time building time. In this paper, we aim to survey several aspects behind the use of grids in ray tracing. In particular we investigate grid traversal algorithms, building techniques and several approaches for hierarchical grids. \u00a9 The Eurographics Association 2008.",null,"6th Eurographics Italian Chapter Conference 2008 - Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-80355138063"],["2008-12-01","Gennaro Cordasco","Load balancing in mesh-like computations using Prediction Binary Trees","We present a load-balancing technique that exploits the temporal coherence, among successive computation phases, in mesh-like computations to be mapped on a cluster of processors. Our method partitions the computation in balanced tasks and distributes them to independent processors through the Prediction Binary Tree (PBT). At each new phase, current PBT is updated by using previous phase computing time (for each task) as (next phase) cost estimate. The PBT is designed so that it balances the load across the tasks as well as reduce dependency among processors for higher performances. Reducing dependency is obtained by using rectangular tiles of the mesh, of almost-square shape (i.e. one dimension is at most twice the other). By reducing dependency, one can reduce inter-processors communication or exploit local dependencies among tasks (such as data locality). Our strategy has been assessed on a significant problem, Parallel Ray Tracing. Our implementation shows a good scalability, and improves over coherence-oblivious implementations. We report different measurements showing that granularity of tasks is a key point for the performances of our decomposition\/mapping strategy. \u00a9 2008 IEEE.",null,"Proceedings of the 7th International Symposium on Parallel and Distributed Computing, ISPDC 2008","Conference Paper","https:\/\/www.doi.org\/10.1109\/ISPDC.2008.24","2-s2.0-60349091540"],["2008-12-01","Vittorio Scarano","Preface",null,null,"6th Eurographics Italian Chapter Conference 2008 - Proceedings","Editorial","https:\/\/www.doi.org\/None","2-s2.0-84878207418"],["2008-12-01","Vittorio Scarano","Fractal compression approach for efficient interactive terrain rendering on the GPU","This paper describes an efficient technique for the rendering of large terrain surfaces. The technique is based on a simple rings structure: a sequence of concentric rings at different resolutions andcenteredon the viewer's position. Each ring is represented by a set of patches at identical resolutions. Rings near the viewer have a finer resolution than the rings further from the viewer. At runtime, the patches within the rings change resolution based on the viewer's position. The GPU decodes in real time height maps encoded by a fractal compressor from which sample the height component of the terrain. Since adjacent patches of different rings can disagree on the resolution of common edge GPU stitches the meshes in order to avoid any cracks or degenerate triangles. The rendered meshes ensure the absence of cracks that may cause the appearance of visual artifacts. In addition, a tile manager support is evaluated in order to maintain terrain datasets on disk storage avoiding a costly load of the entire datasets into the memory. \u00a9 The Eurographics Association 2008.",null,"6th Eurographics Italian Chapter Conference 2008 - Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84878170994"],["2008-11-26","Vittorio Scarano","Face to face cooperation with CoFFEE","Co-located collaboration in classroom is the topic we tackle in this paper. In particular we will describe how CoFFEE implements this kind of collaboration. CoFFEE is an extensible platform on which to implement different collaborative tools. Every tool renders a different kind cooperation between users. In this paper we will also provide further details in about the newly implemented tools for collaboration, the Repository, the Positionometer and the Co-Writer. \u00a9 2008 Springer-Verlag Berlin Heidelberg.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-540-87605-2_6","2-s2.0-56449090860"],["2008-11-26","Vittorio Scarano","A flexible and tailorable architecture for scripts in F2F collaboration","In this paper we introduce the architecture of the script engine of a collaborative co-located discussion support system, named CoFFEE, and, in particular, we describe its extendibility and flexibility as a macro-script engine for CSCL activities [7]. \u00a9 2008 Springer-Verlag Berlin Heidelberg.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/978-3-540-87605-2_45","2-s2.0-56449098597"],["2008-11-18","Gennaro Cordasco","On clustering tasks in IC-optimal dags","Strategies are developed for \"fattening\" the tasks of computation-dags so as to accommodate the heterogeneity of remote clients in Internet-based computing (IC). Earlier work has developed the underpinnings of IC-Scheduling theory, an algorithmic framework for scheduling computations having intertask dependencies for 1C. The theory's schedules strive to render tasks eligible for execution at the maximum possible rate, so as to: (a) utilize remote clients' computational resources well, by enhancing the likelihood of having work to allocate to an available client; (b) lessen the likelihood of a computation's stalling for lack of tasks that are eligible for allocation. The current study begins to enhance IC-Scheduling theory so that it can accommodate the varying computational resources of remote clients. The techniques developed here render a dag multi-granular by clustering its tasks. Several clustering strategies are developed: one works for any dag but produces only a limited variety of \"fattened\" tasks; others exploit the detailed structure of the dag being scheduled but allow a broad range of \"fattened\" tasks. \u00a9 2008 IEEE.",null,"Proceedings of the International Conference on Parallel Processing","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICPP.2008.14","2-s2.0-55949092062"],["2008-09-26","Vittorio Scarano","Proceedings - International Conference Visualisation, VIS 2008, Visualisation in Built and Rural Environments: Preface",null,null,"Proceedings - International Conference Visualisation, VIS 2008, Visualisation in Built and Rural Environments","Editorial","https:\/\/www.doi.org\/10.1109\/VIS.2008.4","2-s2.0-52249102451"],["2008-07-22","Gennaro Cordasco","Extending IC-scheduling via the sweep algorithm","Earlier work has developed the rudiments of a scheduling theory for computations having intertask dependencies-modeled via dags-for Internet-based computing. The goal of the schedules produced is to render tasks eligible for execution as fast as possible, with the aim of: (a) utilizing clients' computational resources well, by always having work to allocate to an available client; (b) lessening the likelihood of a computation's stalling for lack of eligible tasks. Simulation studies suggest that this goal does accelerate computation over the Internet. The theory crafts a schedule for a dag G by \"parsing\" G (if possible) into connected building-block dags that one can \"compose\" to form G and then analyzing the scheduling dependencies among these building blocks. The current paper extends the theory by developing the Sweep Algorithm, a tool that allows one to: (1) schedule using building blocks that are not necessarily connected, and (2) craft schedules that inter-leave the execution of subdags that have no interdependencies. The augmented scheduling algorithms allow one to craft optimal schedules for previously unschedulable dags. Examples presented include artificial dags that are \"close\" to ones arising in real computations, as well as a component of a dag that arises in a functional MRI application. \u00a9 2008 IEEE.",null,"Proceedings of the 16th Euromicro Conference on Parallel, Distributed and Network-Based Processing, PDP 2008","Conference Paper","https:\/\/www.doi.org\/10.1109\/PDP.2008.16","2-s2.0-47349085708"],["2008-04-25","Vittorio Scarano","Optimizing the finger tables in Chord-like DHTs","The Chord protocol is the best known example of implementation of logarithmic complexity routing for structured peer-to-peer networks. Its routing algorithm, however, does not provide an optimal trade-off between resources exploited (the size of the 'finger table') and performance (the average or worst-case number of hops to reach destination). Cordasco et al. showed that a finger table based on Fibonacci distances provides lower number of hops with fewer table entries. In this paper we generalize this result, showing how to construct an improved finger table when the objective is to reduce the number of hops, possibly at the expense of an increased size of the finger table. Our results can also be exploited to guarantee low routing time in case a fraction of nodes fails. Copyright \u00a9 2007 John Wiley & Sons, Ltd.","Analytic evaluation | Efficient protocol implementation | Monte Carlo simulation | Peer-to-peer overlay networks | Routing efficiency and fault-tolerance","Concurrency and Computation: Practice and Experience","Article","https:\/\/www.doi.org\/10.1002\/cpe.1243","2-s2.0-41849112332"],["2007-12-14","Delfina Malandrino","Measuring privacy loss and the impact of privacy protection in web browsing","Various bits of information about users accessing Web sites. some of which are private, have been gathered since the inception of the Web. Increasingly the gathering, aggregation, and processing has been outsourced to third parties. The goal of this work is to examine the effectiveness of specific techniques to limit this diffusion of private information to third parties. We also examine the impact of these privacy protection techniques on the usability and quality of the Web pages returned. Using objective measures for privacy protection and page quality we examine their tradeoffs for different privacy protection techniques applied to a collection of popular Web sites as well as a focused set of sites with significant privacy concerns. We study privacy protection both at a browser and at a proxy.","Privacy | Web","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/1280680.1280688","2-s2.0-36849012525"],["2007-12-01","Vittorio Scarano","Face2Face social bookmarking with recommendations: WebQuests in the classrooms","In this paper we present SynCoBook, a distributed system that offers the functionalities of a face-to-face cooperative bookmarking system and of a recommendation system. Our overall objective was to design and realize a practical tool that can be used in project-based learning, in the classroom, to participate in the WebQuests [12] or to cooperatively build an annotated Webliography, i.e., a set of URLs, organized and scaffolded with group annotations. Moreover, our system also offers advanced awareness tools as well as recommendations based on the items in the Webliography and their Google-related pages.",null,"Proceedings of the 3rd International Conference on Collaborative Computing: Networking, Applications and Worksharing, CollaborateCom 2007","Conference Paper","https:\/\/www.doi.org\/10.1109\/COLCOM.2007.4553834","2-s2.0-51349114597"],["2007-12-01","Vittorio Scarano","CoFFEE: Cooperative Face2Face educational environment","Co-located collaboration in classroom is the topic we tackle in this paper. We present CoFFEE a tailorable collaborative environment that is designed for interactive, colocated (i.e. Face2Face) collaboration in classroom. We present the requirements for tailorability that have driven our design, CoFFEE architecture, some tools that have been deployed and discuss the latecomer management issue that is offered by the core of our architecture to all the tools that can be developed within the framework.",null,"Proceedings of the 3rd International Conference on Collaborative Computing: Networking, Applications and Worksharing, CollaborateCom 2007","Conference Paper","https:\/\/www.doi.org\/10.1109\/COLCOM.2007.4553836","2-s2.0-51349110022"],["2007-12-01","Delfina Malandrino","Visualizing processes on the web","In this paper, we describe 3WPS, a framework to build distributed systems that are able to monitor and interact with a process through a 3D interface that is accessible via the World Wide Web (WWW). The 3WPS is easily configurable, easily adaptable to different processes with high reuse of its software components and its distributed architecture leverages on off-the-shelf components of the WWW infrastructure such as Java applets and Virtual Reality Modeling Language (VRML) browsers. We describe the characteristics of 3WPS framework by mainly focusing on the issue of programmability and by contextually providing an example tour of its usage. \u00a9 2006 Elsevier Ltd. All rights reserved.","Monitoring | Visualization systems | VRML","Journal of Visual Languages and Computing","Article","https:\/\/www.doi.org\/10.1016\/j.jvlc.2006.07.001","2-s2.0-36349010119"],["2007-12-01","Vittorio Scarano","Real positioning in virtual environments using game engines","Immersive virtual environments offer a natural setting for educational and instructive experiences for users, and game engine technology offers an interesting, cost-effective and efficient solution for building them. In this paper we describe an ongoing project whose goal is to provide a virtual environment where the \"real\" location of the user is used to position the user's avatar into the virtual environment. \u00a9 The Eurographics Association 2007.",null,"5th Eurographics Italian Chapter Conference 2007 - Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84878192833"],["2007-11-01","Vittorio Scarano","Personalizable edge services for Web accessibility","Web Content Accessibility guidelines by W3C (W3C Recommendation, May 1999. http:\/\/www.w3.org\/TR\/WCAG10\/) provide several suggestions for Web designers regarding how to author Web pages in order to make them accessible to everyone. In this context, this paper proposes the use of edge services as an efficient and general solution to promote accessibility and breaking down the digital barriers that inhibit users with disabilities to actively participate to any aspect of society. The idea behind edge services mainly affect the advantages of a personalized navigation in which contents are tailored according to different issues, such as client's devices capabilities, communication systems and network conditions and, finally, preferences and\/or abilities of the growing number of users that access the Web. To meet these requirements, Web designers have to efficiently provide content adaptation and personalization functionalities mechanisms in order to guarantee universal access to the Internet content. The so far dominant paradigm of communication on the WWW, due to its simple request\/response model, cannot efficiently address such requirements. Therefore, it must be augmented with new components that attempt to enhance the scalability, the performances and the ubiquity of the Web. Edge servers, acting on the HTTP data flow exchanged between client and server, allow on-the-fly content adaptation as well as other complex functionalities beyond the traditional caching and content replication services. These value-added services are called edge services and include personalization and customization, aggregation from multiple sources, geographical personalization of the navigation of pages (with insertion\/emphasis of content that can be related to the user's geographical location), translation services, group navigation and awareness for social navigation, advanced services for bandwidth optimization such as adaptive compression and format transcoding, mobility, and ubiquitous access to Internet content. This paper presents Personalizable Accessible Navigation (PAN) that is a set of edge services designed to improve Web pages accessibility, developed and deployed on top of a programmable intermediary framework. The characteristics and the location of the services, i.e., provided by intermediaries, as well as the personalization and the opportunities to select multiple profiles make (PAN) a platform that is especially suitable for accessing the Web seamlessly also from mobile terminals. \u00a9 Springer-Verlag 2007.","Disability | Programma bleedge servers | Universal access | Web accessibility","Universal Access in the Information Society","Conference Paper","https:\/\/www.doi.org\/10.1007\/s10209-007-0091-y","2-s2.0-35448958782"],["2007-11-01","Gennaro Cordasco","Advances in IC-Scheduling Theory: Scheduling expansive and reductive DAGs and scheduling DAGs via duality","Earlier work has developed the underpinnings of IC-Scheduling Theory, a framework for scheduling computations having intertask dependencies - modeled via dags - for Internet-based computing. The goal of the schedules produced is to render tasks eligible for execution at the maximum possible rate, with the dual aim of: (a) utilizing remote clients' computational resources well, by always having work to allocate to an available client; (b) lessening the likelihood of a computation's stalling for lack of eligible tasks. The dags handled by the Theory thus far are those that can be decomposed into a given collection of bipartite building-block dags via the operation of dag-decomposition. A basic tool in constructing schedules is a relation \u25b7, which allows one to \"prioritize\" the scheduling of a complex dag's building blocks. The current paper extends IC-Scheduling Theory in two ways: by expanding significantly the repertoire of dags that the Theory can schedule optimally, and by allowing one sometimes to shortcut the algorithmic process required to find optimal schedules. The expanded repertoire now allows the Theory to schedule optimally, among other dags, a large range of dags that are either \"expansive,\" in the sense that they grow outward from their sources, or \"reductive,\" in the sense that they grown inward toward their sinks. The algorithmic shortcuts allow one to \"read off\" an optimal schedule for a dag from a given optimal schedule for the dag's dual, which is obtained by reversing all arcs (thereby exchanging the roles of sources and sinks). \u00a9 2007 IEEE.","Global computing | Grid computing | IC-Scheduling Theory | Internet-based computing | Scheduling DAGs | Theory","IEEE Transactions on Parallel and Distributed Systems","Article","https:\/\/www.doi.org\/10.1109\/TPDS.2007.1067","2-s2.0-34248162626"],["2007-10-23","Vittorio Scarano","An infrastructure for remote virtual exploration on PDAs","In this paper we present a prototyped system to enable the virtual exploration of a complex virtual environment. Our approach exploits Quest3D as main rendering engine, its output is conveyed toward users PDAs to allow them to explore using the PDA as a (mobile) interface to the virtual environment. An important aspect of the system is that it relies on an off-the-shelf PC and low end wireless network. Some early results showed that the prototype is able to easily manage 5 PDAs. Suggested fields of use of our system are virtual cultural heritage, educational virtual environments, videogames. \u00a9 2007 IEEE.",null,"Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV.2007.25","2-s2.0-35348861478"],["2007-09-24","Gennaro Cordasco","PON: Exploiting proximity on overlay networks","We define a proximity overlay network (PON) which allow to realize DHT systems whose aim is to combine routing efficiency - i.e. an optimal degree\/diameter tradeoff - and proximity awareness. The proposed systems is parameterized with a positive integer s which measures the amount of flexibility offered by the network. Varying the value of s the system goes from a quite rigid network (s = 2) which offer an optimal degree\/diameter tradeoff. Increasing s to relatively low values allows to increase the flexibility of the network and consequently improves the stretch, that is, the ratio between the latency of two nodes on the overlay network and the unicast latency between those nodes. We are able to reconcile the conflict between the load balancing and proximity relationship by proving the efficiency of the main performance metrics. In particular we analytically prove that our system can result in lookup latencies proportional to the maximum latency of the underlying physical network, provided that the physical network has a power law latency expansion. \u00a92007 IEEE.",null,"Proceedings - 21st International Parallel and Distributed Processing Symposium, IPDPS 2007; Abstracts and CD-ROM","Conference Paper","https:\/\/www.doi.org\/10.1109\/IPDPS.2007.370659","2-s2.0-34548786338"],["2007-09-24","Gennaro Cordasco","Applying IC-scheduling theory to familiar classes of computations","Earlier work has developed the underpinnings of IC-Scheduling theory, an algorithmic framework for scheduling computations having intertask dependencies for Internet-based computing (IC). The Theory aims to produce schedules that render tasks eligible for execution at the maximum possible rate, so as to: (a) utilize remote clients' computational resources well, by always having work available for allocation; (b) lessen the likelihood that a computation will stall for lack of tasks that are eligible for execution. The current paper reconnects the Theory, which models computations abstractly, with a variety of significant real computations and computational paradigms, by illustrating how to schedule these computations optimally. \u00a9 2007 IEEE.",null,"Proceedings - 21st International Parallel and Distributed Processing Symposium, IPDPS 2007; Abstracts and CD-ROM","Conference Paper","https:\/\/www.doi.org\/10.1109\/IPDPS.2007.370673","2-s2.0-34548758118"],["2007-07-01","Gennaro Cordasco","Bounded-collision memory-mapping schemes for data structures with applications to parallel memories","Techniques are developed for mapping structured data to an ensemble of parallel memory modules in a way that limits the number of conflicts, i.e., simultaneous accesses by distinct processors to the same memory module. The techniques determine, for any given conflict tolerancec, the smallest ensemble that allows one to store any n-node data structure \"of type X\" in such a way that no more than c nodes of a structure are stored on the same module. This goal is achieved by determining the smallest c-perfect universal graphs for data structures \"of type X.\" Such a graph is the smallest graph that contains a homomorphic image of each n-node structure \"of type X\" with each node of the image holding \u2264 c nodes of the structure. In the current paper, \"type X\" refers to rooted binary trees and three array-like structures: Chaotic arrays, ragged arrays, and rectangular arrays. For each of these families of data structures, the number of memory modules needed to achieve conflict tolerance c is determined to within constant factors. \u00a9 2007 IEEE.","Bounded-conflict parallel memory access | Data mapping | Data structures | Data structures for parallel systems | Graph labeling | Parallel architectures | Parallel memory systems | Parallel systems","IEEE Transactions on Parallel and Distributed Systems","Article","https:\/\/www.doi.org\/10.1109\/TPDS.2007.1024","2-s2.0-34250373695"],["2006-12-01","Delfina Malandrino","Peer-to-peer face-to-face collaboration","In this paper, we present a proof of concept application of a technique that is designed explicitly for face to face collaboration software architectures. The objective is to minimize the impact on the installation and deployment of the application, that, while internally keeping a client-server architecture (in order to allow the centralize coordination and monitoring), presents to the user (both teacher and learners) as uniform work environment, integrating client and server components in one piece of software. In order to further limit the impact on the configuration, we define a start and play protocol, to start-up the application with no network configuration; the start and play protocol takes advantage from the particular conditions of the face to face context i.e. LAN setting. The application is built on the Eclipse core (Rich Client Platform), and inherits its plug-in based architecture and its advanced tailoring features.",null,"CEUR Workshop Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84884644514"],["2006-12-01","Delfina Malandrino","Personalizable edge services for web accessibility","Web Content Accessibility guidelines by W3C [29] provide several suggestions for Web designers on how to author Web pages in order to make them accessible to everyone. In this context, we are proposing the use of edge services as an efficient and general solution to promote accessibility and breaking down the digital barriers that inhibit users with disabilities to actively participate to any aspect of our society. To this aim, we present in this paper PAN: Personalizable Accessible Navigation, that is a set of edge services designed to improve Web pages accessibility, developed and deployed on top of a programmable intermediary framework [8]. The characteristics and the location of the services, i.e. provided by intermediaries, as well as the personalization and the opportunities to select multiple profiles make PAN a platform that is especially suitable in accessing the Web seamlessly also from mobile terminals. Copyright 2006 ACM.","Disability | Programmable edge servers | Universal access | Web accessibility","ACM International Conference Proceeding Series","Conference Paper","https:\/\/www.doi.org\/10.1145\/1133219.1133224","2-s2.0-34250702740"],["2006-12-01","Delfina Malandrino","Efficient edge-services for colorblind users",null,"Colorblindness | Edge services | Vision | Web accessibility","Proceedings of the 15th International Conference on World Wide Web","Conference Paper","https:\/\/www.doi.org\/10.1145\/1135777.1135944","2-s2.0-34250643197"],["2006-12-01","Gennaro Cordasco","On scheduling expansive and reductive dags for internet-based computing","Earlier work has developed the underpinnings of a theory of scheduling computations having intertask dependencies - modeled via dags - for Internet-based computing. The goal of the schedules produced is to render tasks eligible for execution at the maximum possible rate. This goal aims: (a) to utilize remote clients' computational resources well, by always having work to allocate to an available client; (b) to lessen the likelihood of the \"grid-lock\" that ensues when a computation stalls for lack of eligible tasks. The dags handled by the theory thus far are those that can be constructed from a given collection of bipartite building-block dags via the operation of dag-composition. The current paper extends the range of applicability of the theory by significantly expanding the repertoire of building-block dags that the scheduling algorithms can handle. Thereby, the theory can now schedule large classes of \"expansive\" and \"reductive\" dags optimally. \u00a9 2006 IEEE.",null,"Proceedings - International Conference on Distributed Computing Systems","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICDCS.2006.58","2-s2.0-33947663566"],["2006-12-01","Gennaro Cordasco","How much independent should individual contacts be to form a small-world?","We study Small-World graphs in the perspective of their use in the development of efficient as well as easy to implement network infrastructures. Our analysis starts from the Small-World model proposed by Kleinberg: a grid network augmented with directed long-range random links. The choices of the long-range links are independent from one node to another. In this setting greedy routing and some of its variants have been analyzed and shown to produce paths of polylogarithmic expected length. We start from asking whether all the independence assumed in the Kleinberg's model among long-range contacts of different nodes is indeed necessary to assure the existence of short paths. In order to deal with the above question, we impose (stringent) restrictions on the choice of long-range links and we show that such restrictions do not increase the average path length of greedy routing and of its variations. Diminishing the randomness in the choice of random links has several benefits; in particular, it implies an increase in the clustering of the graph, thus increasing the resilience of the network. \u00a9 2006 Springer-Verlag Berlin\/Heidelberg.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/11940128_34","2-s2.0-77249126510"],["2006-12-01","Vittorio Scarano","Some real experiences in developing virtual environments","The paper presents some experiences in developing a virtual environment using a videogame engine. It provides the details and the caveats met during development, with particular attentions to the architectural reconstruction problem, the textures resolution and the programmability. Some considerations are also reported from an historical point of view, emphasizing the importance of virtual reconstructions, and from a psychological point of view stressing how a narrative context enhances the learning process. \u00a9 2006 IEEE.",null,"Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV.2006.98","2-s2.0-45149114641"],["2006-12-01","Vittorio Scarano","An architecture for distributed behavioral models with GPUs","We describe an architecture for massive simulation of a distributed behavioral model using graphics hardware. By leveraging on the recent programmable capabilities of GPUs we implemented the model capable of managing a large aggregate motion of birds in a virtual environment that can avoid both static and dynamic obstacles. We demonstrate the effectiveness of our GPU implementation by comparing the results to a CPU implementation and, emphasize the modularity of the proposed architecture that favors reusability in several contexts. \u00a9 2006 The Eurographics Association.",null,"4th Eurographics Italian Chapter Conference 2006 - Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84878030424"],["2006-12-01","Vittorio Scarano","Introduction: Exploring the potentials of networked-computing support for face-to-face collaborative learning",null,null,"CEUR Workshop Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84884656186"],["2006-10-31","Delfina Malandrino","Context-aware provision of advanced Internet services","The pervasive and mobile computing scenario is characterized by the heterogeneity of devices used to access services, and by frequent changes in the user's context. This paper presents the integration of two existing frameworks into a context-aware content provisioning system oriented to mobile users. External Web contents can be automatically tailored according to a wide range of context data, including device capabilities, available bandwidth, location, user preferences. The tailoring process is human intervention free. In order to demonstrate the feasibility of our solution, we have developed a prototype location-based service that takes advantage of this architecture. \u00a9 2006 IEEE.",null,"Proceedings - Fourth Annual IEEE International Conference on Pervasive Computing and Communications Workshops, PerCom Workshops 2006","Conference Paper","https:\/\/www.doi.org\/10.1109\/PERCOMW.2006.34","2-s2.0-33750339694"],["2006-10-01","Vittorio Scarano","A scalable cluster-based infrastructure for edge-computing services","In this paper we present a scalable and dynamic intermediary infrastructure, SEcS (acronym of \"Scalable Edge computing Services\"), for developing and deploying advanced Edge computing services, by using a cluster of heterogeneous machines. Our goal is to address the challenges of the next-generation Internet services: scalability, high availability, fault-tolerance and robustness, as well as programmability and quick prototyping. The system is written in Java and is based on IBM's Web Based Intermediaries (WBI) [71] developed at IBM Almaden Research Center. \u00a9 Springer Science + Business Media, LLC 2006.","Edge Services | Intermediary systems | Personalized and mobile services | Proxy servers | World Wide Web","World Wide Web","Article","https:\/\/www.doi.org\/10.1007\/s11280-006-8559-x","2-s2.0-33749000286"],["2006-07-14","Vittorio Scarano","Tackling Web dynamics by programmable proxies","Web services are becoming increasingly complex as users become more experienced in their requests to access an ever growing collection of information on the Web. In this paper we review the state of the art in programmable HTTP proxies. We discuss and present the evolution of HTTP proxies and present some of the environments that were proposed to support the design and implementation of proxy-based services. Then, we present a new computational model, called collateral-push, that is well suited for several proxy applications whose goal is to cope with the dynamics of the Web. Finally, after presenting existing examples of the collateral-push services in the literature, we present some new examples that were quickly prototyped using two programmable proxy environments. \u00a9 2005 Elsevier B.V. All rights reserved.","Dynamic Web content | HTTP proxies | Push\/pull paradigms | Web intermediaries","Computer Networks","Article","https:\/\/www.doi.org\/10.1016\/j.comnet.2005.10.019","2-s2.0-33747810134"],["2006-01-01","Gennaro Cordasco","Optimizing the finger table in Chord-like DHTs","The Chord protocol is the best known example of implementation of logarithmic complexity routing for structured peer-to-peer networks. Its routing algorithm, however, does not provide an optimal trade-off between resources exploited (the size of the \"finger table\") and performance (the average or worst-case number of hops to reach destination). Cordasco et al. showed that a finger table based on Fibonacci distances provides lower number of hops with fewer table entries. In this paper we generalize this result, showing how to construct an improved finger table when the objective is to reduce the number of hops, possibly at the expense of an increased size of the finger table. Our results can also be exploited to guarantee low routing time in case a fraction of nodes is assumed to fail. \u00a9 2006 IEEE.","Analytic evaluation | Efficient protocol implementation | Montecarlo simulation | Peer-to-peer overlay networks | Routing efficiency and fault-tolerance","20th International Parallel and Distributed Processing Symposium, IPDPS 2006","Conference Paper","https:\/\/www.doi.org\/10.1109\/IPDPS.2006.1639707","2-s2.0-33847154704"],["2005-12-01","Delfina Malandrino","A scalable framework for the support of advanced edge services","The Ubiquitous Web requires novel programming paradigms and distributed architectures for the support of advanced services to a multitude of user devices and profiles. In this paper we describe a Scalable Intermediary Software Infrastructure (SISI) that aims at efficiently providing content adaptation and combinations of other complex functionalities at edge servers on the WWW. SISI adopts different user profiles to achieve automatic adaptation of the content according to the capabilities of the target devices and users. We demonstrate SISI efficiency by comparing its performance against another framework for content adaptation at edge servers. \u00a9 Springer-Verlag Berlin Heidelberg 2005.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/11557654_114","2-s2.0-33646390654"],["2005-12-01","Delfina Malandrino","SEcS: Scalable Edge-computing services","We present the architecture of a scalable and dynamic intermediary infrastructure for developing and deploying advanced Edge computing services, by using a cluster of heterogeneous machines. Our main goal is to address the challenges of the next-generation Internet services: scalability, high availability, fault-tolerance and robustness. Moreover, SEcS offers an easy, \"on-the-fly\" and per-user configuration of services. The architecture is based on IBM's Web Based Intermediaries (WBI) [8, 9]. Copyright 2005 ACM.","Edge Services | Intermediary Systems | Personalized and Mobile Services | Proxy Servers | World Wide Web","Proceedings of the ACM Symposium on Applied Computing","Conference Paper","https:\/\/www.doi.org\/10.1145\/1066677.1067063","2-s2.0-33644529058"],["2005-12-01","Gennaro Cordasco","Overlay networks with class","We define a family of Distributed Hash Table systems whose aim is to combine routing efficiency of the randomized networks - i.e. average path length O (log n\/ log log n) vs. the O(log n) average path length of the deterministic system - with the programmability and startup efficiency of a uniform system - that is a system in which the overlay network is transitive, and greedy routing is optimal. It is known that \u03a9(log n) is a lower bound to the average path length for uniform systems with O(log n) degree. The proposed family is parameterized with a positive integer c which measures the amount of randomness that is used. Indeed, edges are partitioned into c equivalence classes. Varying the value c, the system goes from the deterministic case (c = 1) to an \"almost uniform\" system. Increasing c to relatively low values allows routing with optimal average path length while retaining most of the advantages of a uniform system, such as easy programmability and quick bootstrap of the nodes entering the system. We also provide a matching lower bound for the average path length of the family of routing schemes for any c. Moreover, we show how to extend the result to other overlay networks. \u00a9 2005 IEEE.",null,"Proceedings of the International Symposium on Parallel Architectures, Algorithms and Networks, I-SPAN","Conference Paper","https:\/\/www.doi.org\/10.1109\/ISPAN.2005.66","2-s2.0-33846963778"],["2005-12-01","Gennaro Cordasco","2-Chord Halved","We present 2-Chord Halved, a distributed peer-to-peer lookup protocol. Our proposal is based on Chord [24] exhibit the following advantages: i) We show a stabilization procedure that eliminates the fixfinger procedure of Chord protocol. Our strategy allows to inform each node on the ring that is interested to a topological change. Fixfinger in Chord costs O(log2 N) messages when it is ran on all finger table entries even if the finger table is up to date, contrariwise our stabilization procedure, that has the same cost, is ran only if there are join or leave operations and only on the interested nodes. ii) We present a new strategy to implement the join\/leave operations using the predecessor's finger table of joined node and exploiting the fingers of predecessor as start point searching new fingers. This procedure costs O(log N log log N) w.h.p., contrariwise to Chord within join\/leave operation cost O(log2 N) w.h.p.. iii) We show a new routing strategy that has a moderate improvement on average path length. The improvements are obtained with no harm to the operational efficiency (e.g. stability, scalability, fault-tolerance, node congestion) of the Chord systems. \u00a9 2005 IEEE.",null,"Proceedings - Second International Workshop on Hot Topics in Peer-to-Peer Systems, HOT-P2P 2005","Conference Paper","https:\/\/www.doi.org\/10.1109\/HOT-P2P.2005.1","2-s2.0-33749389906"],["2005-12-01","Vittorio Scarano","Interactive 3D Environments by using videogame engines","In this paper we study state-of-the-art technologies to design interactive and cooperative 3D environments that are based on videogame 3D engines. We provide, first, a categorization of videogame 3D engines from the point of view of their usage in creating interactive 3D worlds and show a comparison of the most important characteristics. Then, we show an example of how we used a commercial videogame engine to create an interactive an enjoyable visit to an archaeological site. \u00a9 2005 IEEE.",null,"Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV.2005.64","2-s2.0-33749060408"],["2005-12-01","Vittorio Scarano","A taxonomy of programmable HTTP proxies for advanced edge services","In this paper, we present the state of the art in the field of programmability in HTTP proxies. In particular, we first deal with programmability and show how it is a crucial requirement to easily realize and assemble edge services that can enhance the quality and the user perception of the navigation into a crowded and confusing World Wide Web. Then, we compare some of the most used HTTP proxies to provide an analysis of their programmability and, finally, show some evidence of successful edge services realized on top of existing programmable HTTP proxy frameworks.","Edge services | HTTP proxy | Programmable proxy","WEBIST 2005 - 1st International Conference on Web Information Systems and Technologies, Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-46749084128"],["2005-11-10","Vittorio Scarano","Degree-optimal deterministic routing for P2P systems","We propose routing schemes that optimize the average number of hops for lookup requests in Peer-to-Peer (P2P) systems without adding any overhead to the system. Our work is inspired by the recently introduced variation of greedy routing, called neighbor-of-neighbor (NoN), which allows to get optimal average path length with respect to the degree. Our proposal has the advantage of first \"limiting \" and then \"eliminating \" the use of randomization. As a consequence, the NoN technique can be implemented with our schemes without adding any overhead. Analyzed networks include several popular topologies: Chord, Hypercube based networks, Symphony, Skip-Graphs. Theoretical results and extensive simulations show that the proposed simplifications (while maintaining the original node degree) do not increase the average path length of the networks, which is often improved in practice. The improvement is obtained with no harm to the operational efficiency (e.g. stability, ease of programming, scalability, fault-tolerance) of the considered systems. \u00a9 2005 IEEE.",null,"Proceedings - IEEE Symposium on Computers and Communications","Conference Paper","https:\/\/www.doi.org\/10.1109\/ISCC.2005.45","2-s2.0-27544455744"],["2005-06-01","Vittorio Scarano","A system for virtual directories using Euler diagrams","In this paper, we describe how to use Euler Diagrams to represent virtual directories. i.e. collection of files that are computed on demand and satisfy a number of constraints. We, then, briefly describe the state of VennFS project that is currently modified to include this new capability. In particular, we show a data structure designed to answer queries about a given Euler Diagram and its sets. The data structure EulerTree described here is based on the R-Tree (see [Pankaj K. Agarwal, Mark de Berg, Joachim Gudmundsson, Mikael Hammar and Herman J. Haverkort, Box-trees and R-trees with near-optimal query time, in: Symposium on Computational Geometry, 2001, pp. 124-133]), a data structure designed for answering range queries over a family of shapes in the 2-dimensional space. \u00a9 2005 Elsevier B.V. All rights reserved.","Euler Diagrams | EulerTree | File Systems | HFS | R-Tree","Electronic Notes in Theoretical Computer Science","Conference Paper","https:\/\/www.doi.org\/10.1016\/j.entcs.2005.02.019","2-s2.0-18844382149"],["2005-01-01","Delfina Malandrino","An intermediary software infrastructure for edge services","We describe the goals and architecture of a new framework that aims at facilitating the deployment of adaptation services running on intermediate edge servers. The main goal is to guarantee robustness and quick prototyping of functions that should integrate mobile\/fixed-network services. Moreover, we intend to design a distributed architecture with the purpose of guaranteeing efficient delivery.",null,"Proceedings - International Conference on Distributed Computing Systems","Conference Paper","https:\/\/www.doi.org\/10.1109\/ICDCSW.2005.38","2-s2.0-34848815379"],["2005-01-01","Delfina Malandrino","Mobile-web services via programmable proxies","Our goal, in this paper, is to present the effectiveness of an inteimediary framework to provide mobile-oriented services via edge services. To this end we developed services for device independence in such a way that content is adapted according to the capabilities of the target devices. \u00a9 2005 by International Federation for Information Processing.","Device independence | Programmable proxies | Ubiquitous web","IFIP Advances in Information and Communication Technology","Conference Paper","https:\/\/www.doi.org\/10.1007\/0-387-31166-1_10","2-s2.0-33750363159"],["2004-12-01","Vittorio Scarano","Architecture of a P2P distributed adaptive directory","A system that offers a distributed, co-operative and adaptive environment for bookmark sharing, was described. The system represents a 'pure' peer-to-peer (P2P) application for managing communities of users that want to share the resources that they found, being supported by an adaptive mechanism and by a highly tunable ranking mechanism. The system is structured on three separate layers. The architecture of the system is not based on client-server architecture and offer a distributed framework where the load of managing and storing the bookmarks is equally distributed among peers. The goal is to provide dynamically adaptive navigation\/content to users in such as way that their interaction with the WWW is tailored to personal inclinations.","Adaptivity | Bookmark sharing | Peer to Peer","Thirteenth International World Wide Web Conference Proceedings, WWW2004","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-19944417621"],["2004-12-01","Gennaro Cordasco","Non-uniform deterministic routing on F-Chord(\u03b1)","In this paper, we present a family of novel P2P routing schemes based on Chord (and its variation F-Chord(\u03b1)) that trades off uniformity with efficiency without using any additional overhead. We prove that H-F-Chord(\u03b1)'s routing is more efficient than in F-Chord(\u03b1) in terms of its average path length that is O(log n\/ log log n). We also show, by simulations, that H-F-Chord(\u03b1) is more efficient than the corresponding F-Chord(\u03b1) by a percentage that goes from 15% to 22% even for small n. \u00a9 2005 IEEE.",null,"Proceedings of the First International Workshop on Hot Topics in Peer-to-Peer Systems, HOT-P2P '04","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-24644509638"],["2004-12-01","Vittorio Scarano","c-perfect hashing schemes for binary trees, with applications to parallel memories (extended abstract)","We study the problem of mapping tree-structured data to an ensemble of parallel memory modules. We are given a \"conflict tolerance\" c, and we seek the smallest ensemble that will allow us to store any nvertex rooted binary tree with no more than c tree-vertices stored on the same module. Our attack on this problem abstracts it to a search for the smallest c-perfect universal graph for complete binary trees. We construct such a graph which witnesses that only O (c(1-1\/c) \u00b7 2(n+1)\/(c+1)) memory modules are needed to obtain the required bound on conflicts, and we prove that \u03a9( 2(n+1)\/(c+1)) memory modules are necessary. These bounds are tight to within constant factors when c is fixed - as it is with the motivating application. \u00a9 Springer-Verlag 2003.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Article","https:\/\/www.doi.org\/None","2-s2.0-35048856077"],["2004-12-01","Vittorio Scarano","A visual adaptive interface to file systems","In this paper we present our experience in building a visual file manager, VennFS2, that offers to users an adaptive interface toward access to files. Our file manager was originally designed to overcome some of limitations of hierarchical file systems, since it allows users to categorize files in such a way that files may belong multiple categories at once. Based on the past history of the files that were opened and modified by the user, VennFS2 graphically presents the user a small number of choices of the next file the user will modify. Some preliminary testing with interesting hints are also reported. \u00a9 2004 ACM.","Adaptivity | Set | User interfaces | Venn","Proceedings of the Workshop on Advanced Visual Interfaces AVI","Conference Paper","https:\/\/www.doi.org\/10.1145\/989863.989926","2-s2.0-18844450320"],["2004-10-11","Delfina Malandrino","AMIFAST: An architecture for MIDI flows as sonification tools","We describe a framework in Java to create sonification applications with minimum effort from the programmer and musician. Our tool, AMIFAST, offers a set of modules that can be easily assembled to produce sonification of off-line as well as on-line (i.e. real-time) applications. Moreover, the programmer can easily add new functionalities In AMIFaST, we included a sonification technique that we introduce here, Markov Chain Perturbation.",null,"Proceedings of the International Conference on Information Visualization","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-4644250160"],["2004-05-19","Vittorio Scarano","Architecture of a P2P distributed adaptive directory","Bookmarks are, nowadays, an important aid to navigation since they represent an easy way to reduce the cognitive load of managing and typing URLs. All the browsers have always provided, since the very beginning of the WWW, friendly ways of managing bookmarks. In this paper we deal with the problem of enriching this supportive framework for bookmarks (as provided by the browsers) by adding collaboration and (group) adaptation with a P2P system. In this paper, we describe a system that offers a distributed, cooperative and adaptive environment for bookmark sharing. DAD (Distributed Adaptive Directory) offers an adaptive environment since it provides suggestions about the navigation based on (a) the bookmarks, (b) the feedback implicitly provided by users and (c) the structure of the Web. DAD is fully scalable because of its peerto- peer architecture and provides, also, an infrastructure to build easily P2P overlay networks.","Adaptivity | Bookmark sharing | Peer to peer","Proceedings of the 13th International World Wide Web Conference on Alternate Track, Papers and Posters, WWW Alt. 2004","Conference Paper","https:\/\/www.doi.org\/10.1145\/1013367.1013436","2-s2.0-85027873329"],["2004-01-01","Gennaro Cordasco","A P2P distributed adaptive directory","We describe a P2P system that offers a distributed, cooperative and adaptive environment for bookmark sharing. DAD offers an adaptive environment since it provides suggestions about the navigation based on (a) the bookmarks, (b) the feedback implicitly provided by users and (c) the structure of the Web. Our system is fully scalable because of its peer-to-peer architecture and provides, also, an infrastructure to build easily P2P overlay networks. \u00a9 Springer-Verlag 2004.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Article","https:\/\/www.doi.org\/10.1007\/978-3-540-27780-4_8","2-s2.0-35048852635"],["2004-01-01","Gennaro Cordasco","F-Chord: Improved uniform routing on Chord (extended abstract)","We propose a family of novel schemes based on Chord retaining all positive aspects that made Chord a popular topology for routing in P2P networks. The schemes, based on the Fibonacci number system, allow to improve on the maximum\/average number of hops for lookups and the routing table size per node. \u00a9 Springer-Verlag Berlin Heidelberg 2004.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Article","https:\/\/www.doi.org\/10.1007\/978-3-540-27796-5_9","2-s2.0-35048822479"],["2004-01-01","Vittorio Scarano","Massive simulation using GPU of a distributed behavioral model of a flock with obstacle avoidance","In this work, we present a massive simulation of a behavioral model using graphics hardware. In particular we took a well established model to simulate complex flocks and we focused our attention on its implementation using techniques to manage efficiently large amount of data. Using the recent programmability of GPUs and recent extensions of computer graphics programming, we implemented on the graphics hardware the model capable of managing a large aggregate motion of birds in a virtual environment as well as to avoiding both static and dynamic obstacles. We demonstrated the effectiveness of our GPU implementation when compared with CPU according to recent trends that show graphics hardware capable of also working outside of its natural application field.",null,"Vision, Modeling and Visualization 2004, VMV 2004 - Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-84962511142"],["2003-01-01","Vittorio Scarano","VennFS: A Venn-diagram file manager","In this paper we present a prototypal file manager, VennFS, that is designed to overcome some of the limitations of the current desktop interfaces, that are strongly based on hierarchical file systems. VennFS allows users to place documents and categories on a plane so that files may belong to multiple categories at once, where proximity on the plane can represent similarity and time filtering is allowed.",null,"Proceedings of the International Conference on Information Visualisation","Conference Paper","https:\/\/www.doi.org\/10.1109\/IV.2003.1217967","2-s2.0-84992290246"],["2003-01-01","Delfina Malandrino","\"Common\" Web Paths in a Group Adaptive System","In this paper we describe how we use a group of users' accesses and interactions with web pages to discover and recommend relevant common navigation paths to other users. We collect data using a social navigation environment called GAS (Group Adaptive System) that we developed and are currently integrating the common path navigation tool into the system. The goal is to use the common path of a subset of users in the system as a recommendation for other users.","Adaptive Hypermedia | Recommendation Systems","Proceedings of the ACM Conference on Hypertext","Conference Paper","https:\/\/www.doi.org\/10.1145\/900051.900099","2-s2.0-1142293070"],["2002-12-01","Vittorio Scarano","Test++: An adaptive training system on the Internet","We present an adaptive system for training and teaching. Our system integrates an adaptive training environment and a cooperative environment for exams both accessible via Internet by standard Java-enabled browsers. In this paper we present details on the architecture, describe the project with regard to the adaptive self-training part, and report on an experiment that demonstrates the effectiveness of the strategy: to draw attention of students to the topics they need to study. We experimented the system in a real case study with students attending a first year course, \u00abLaboratorio di Informatica\u00bb of the Laurea degree in computer science in our University. \u00a9 2002 IEEE.",null,"Proceedings - IEEE Symposium on Computers and Communications","Conference Paper","https:\/\/www.doi.org\/10.1109\/ISCC.2002.1021683","2-s2.0-84883870045"],["2002-07-01","Vittorio Scarano","Multimodal monitoring of web servers","A multimodal real-time monitoring system called MMM was presented. It described server activity by multimodal representation and supplemented traditional ways of conveying sonification and peripheral information to webmasters. A prototype and plugin was also described that MMM's three-level distributed architecture implemented. The server architecture was displayed through a floating toolbar that contains the icons.",null,"IEEE Multimedia","Article","https:\/\/www.doi.org\/10.1109\/MMUL.2002.1022857","2-s2.0-0036649405"],["2002-04-01","Vittorio Scarano","Optimal tree access by elementary and composite templates in parallel memory systems","In this paper, we study efficient strategies for mapping onto parallel memory systems complete trees that are accessed by fixed templates (like complete subtrees, paths, or any combinations their of). These mappings are evaluated with respect to the following criteria: 1) the largest number of data items that can be accessed in parallel without memory conflicts; 2) the number of memory conflicts that can occur when accessing templates of size equal to the number of available memory modules, thereby exploiting the full parallelism of the system; 3) the complexity of the memory addressing scheme, i.e., the cost of retrieving the module where a given data item is mapped. We show that there exist trade-offs between these three criteria and the performance of different mapping strategies depends on the emphasis given on each of these criteria. More specifically, we describe an algorithm for mapping complete binary trees of height H onto M memory modules and prove that it achieves the following performance results: 1) conflict-free access to complete subtrees of size K and paths of size N such that N + K - \u2308log K\u2309 \u2265 M; 2) at most 1 conflict in accessing complete subtrees and paths of size M; 3) O(K\/M + c) conflicts when accessing a composite template of K nodes consisting of c disjoint subsets, each subset being a complete subtree, or a path or a set of consecutive nodes in a level of the tree. Furthermore, we show that an existing mapping algorithm results in a larger number, namely O(K\/\u221aM log M + c), of conflicts when accessing a composite template. However, such an algorithm maps each single node in O(1) time, while the new algorithm requires O(H\/N - log K) time.","Complete trees | Composite templates | Conflict-free access | Elementary templates | Mapping scheme | Parallel memory system","IEEE Transactions on Parallel and Distributed Systems","Article","https:\/\/www.doi.org\/10.1109\/71.995820","2-s2.0-0036530167"],["2002-01-01","Delfina Malandrino","3WPS : A 3D web-based process visualization framework","In this paper, we describe 3WPS, a framework to build distributed systems that are able to monitor and interact with a process via a 3D interface that is accessible via the World Wide Web. 3WPS is easily configurable, easily adaptable to different processes with high reuse of its software components and its distributed architecture leverages on off-the-shelf components of the WWW infrastructure such as Java applets and VRML browsers.",null,"Proceedings - 1st International Symposium on 3D Data Processing Visualization and Transmission, 3DPVT 2002","Conference Paper","https:\/\/www.doi.org\/10.1109\/TDPVT.2002.1024038","2-s2.0-84992260381"],["2002-01-01","Vittorio Scarano","GAS: Group adaptive system","This paper describes an ongoing research project to design a Group Adaptive System (GAS) for collaborative navigation on the web. Our objective is to provide information that adapts to web users based on automatically determined, dynamic user groups. To do this, our approach takes into account the structure of the web (using the CLEVER algorithm [16]) and user interactions when navigating the web (gathered by our collaborative environment) to offer users in a consistent information space determined by their interests and activities. In the end, our system, GAS, enables users to perform asynchronous collaborative navigation by combining resources discovered by a group of users and suggestions discovered by the CLEVER algorithm to provide recommendations to the group. \u00a9 2002 Springer-Verlag Berlin Heidelberg.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/3-540-47952-x_7","2-s2.0-84874925401"],["2001-12-01","Vittorio Scarano","Web-based visualization of processes: Applications","Several web-based visualizations of processes obtained using a 3WPS were described. 3WPS is a distributed framework to build systems that monitor and interact with a process by a three dimensional interface accessible via world wide web. 3WPS is designed to offer an easily configurable and adaptable framework to provide three dimensional dynamic monitoring and interaction with software processes.",null,"2001 IEEE Fourth Workshop on Multimedia Signal Processing","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-0035790893"],["2001-01-01","Vittorio Scarano","Optimal tree access by elementary and composite templates in parallel memory systems","In this paper we study strategies for mapping complete tree data structures, that are accessed by fixed templates, onto parallel memory systems. These mappings are evaluated with respect to the following three different criteria: (i) the number of memory conflicts that can occur in a parallel access to the data structure; (ii) the largest number of elements that can be accessed in parallel without memory conflicts; (iii) the complexity of the memory addressing scheme. We show that there exist trade-offs between these criteria. We describe an algorithm COLOR for mapping complete trees onto EA memory modules and prove that it achieves the following performance: (i) conflict-free access to complete subtrees of size K and paths of size N, for M\u2265N+K-[log K]; (ii) at most 1 conflict when accessing complete subtrees and paths of size M; (iii) O((K\/M)+c) conflicts when accessing a composite template of K nodes consisting of c disjoint subsets, each being a complete subtree, a path or a set of consecutive nodes in a level of the tree.",null,"Proceedings - 15th International Parallel and Distributed Processing Symposium, IPDPS 2001","Conference Paper","https:\/\/www.doi.org\/10.1109\/IPDPS.2001.924972","2-s2.0-84981214766"],["2001-01-01","Vittorio Scarano","JSEB (Java Scalable Services Builder): Scalable systems for clusters of workstations","A report on Java Scalable Service Builder (JSEB) is presented. It offers programmers a tool that can be efficiently used to add fault-tolerance and scalability to replicated service in clusters of workstations. It can efficiently deal with three-level architectures by allowing to scale and monitor DBMS and WWW services at once.",null,"IEEE Symposium on Computers and Communications - Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-0034875261"],["2000-01-01","Vittorio Scarano","Teach++: A cooperative distance learning and teaching environment","In this paper we present the key principles of the architecture of Teach++. a cooperative environment specialized for distance learning, and its implementation as a didactic instrument for teaching programming languages. Our system is designed to be multi-user, distributed, scalable and cooperative. The goal is to integrate collaboration in a virtual classroom over shared resources by using a common browser enabled with a Java Virtual Machine. The collaboration can be during a lesson, during a one-to-one (possibly remote) tutoring and during the (cooperative) authoring phase. The system provides, among other features, a cooperative editor and a shared cooperative remote login (teInet) session.",null,"Proceedings of the ACM Symposium on Applied Computing","Conference Paper","https:\/\/www.doi.org\/10.1145\/335603.335718","2-s2.0-84897417382"],["2000-01-01","Vittorio Scarano","Adaptive testing by Test++","We present the adaptive features of Test++, an adaptive system for training and teaching on the Internet. The system integrates an adaptive training environment for personalized training and a cooperative environment for exams both accessible via Internet and a standard Java-enabled browser.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/3-540-44595-1_25","2-s2.0-70450060579"],["1999-12-01","Vittorio Scarano","On the sizes of Extended Fibonacci Cubes","Hypercube is a popular interconnection network whose size must be a power of 2. Several interconnection networks have been proposed that do not suffer this limitation. Among them the Extended Fibonacci Cubes [13] are based on the same sequence of the Fibonacci Cubes and share many appealing structural properties. In this paper, we show how Extended Fibonacci Cubes can be seen as (Cartesian) product graphs whose components are hypercubes and Fibonacci Cubes. By exposing this property, we prove a conjecture in [13] that there are no distinct Extended Fibonacci Cubes (except the trivial ones) with the same number of nodes. Our result further validates the motivations behind the proposal of this interconnection network as a flexible alternative to hypercubes.",null,"IEEE Transactions on Parallel and Distributed Systems","Article","https:\/\/www.doi.org\/10.1109\/71.780869","2-s2.0-0033362736"],["1999-01-01","Vittorio Scarano","WEBSLIDE: A \"Virtual\" Slide Projector Based on World Wide Web","We present here the design key concepts of WEBSLIDE, a software project whose objective is to provide a simple, cheap and efficient solution for showing slides during lessons in computer labs. In fact, WEBSLIDE allows the video monitors of several client machines (the \"STUDENTS\") to be synchronously updated by the actions of a particular client machine, called the \"INSTRUCTOR.\" The system is based on the World Wide Web and the software components of WEBSLIDE mainly consists in a WWW server, browsers and small CGI-BIN scripts. What makes WEBSLIDE particularly appealing for small educational institutions is that WEBSLIDE is built with \"off the shelf\" products: it does not involve using a specifically designed program but any Netscape browser, one of the most popular browsers available on the market, is sufficient. Another possible use is to use our system to implement \"guided automatic tours\" through several pages or Intranets internal news bulletins: the company Web server can broadcast to all employees relevant information on their browser. \u00a9 1999 Plenum Publishing Corporation.","Cgi programming | Intranet applications | Synchronous world wide web navigation","Journal of Science Education and Technology","Article","https:\/\/www.doi.org\/10.1023\/A:1009477420811","2-s2.0-53149094718"],["1998-02-25","Vittorio Scarano","Multiple Templates Access of Trees in Parallel Memory Systems","We study the problem of mapping theNnodes of a data structure onMmemory modules so that they can be accessed in parallel bytemplates, i.e., distinct sets of nodes. In literature several algorithms are available for arrays (accessed by rows, columns, diagonals, and subarrays) and trees (accessed by subtrees, root-to-leaf paths, levels, etc.). Although some mapping algorithms for arrays allow conflict-free access to several templates at once (for example rows and columns), no mapping algorithm is known for efficiently accessing subtree, path and level templates in complete binary trees. In our paper, we first prove that any mapping algorithm that is conflict-free for tree\/level template has \u03a9(M\/logM) conflicts when access is done according to path template and vice versa. Therefore, no mapping algorithm can be found that is conflict-free on both path and tree (or path and level) templates. Our main result is an algorithm for mapping complete binary trees withN= 2M- 1 nodes onMmemory modules in such a way that: the number of conflicts for accessing an-node subtree,adjacent nodes in the same level, orconsecutive nodes of a root-to-leaf path is(), the load (i.e., the ratio between the maximum and minimum number of data items mapped on each module) is 1 + o(1), the time complexity for retrieving the module where a given data item is stored is(1), if a preprocessing phase of space and time complexity(log) is executed, or(log log), if no preprocessing is allowed. The algorithm can be easily generalized to complete binary trees of any size. \u00a9 1998 Academic Press.",null,"Journal of Parallel and Distributed Computing","Article","https:\/\/www.doi.org\/10.1006\/jpdc.1998.1426","2-s2.0-0002435314"],["1998-01-01","Vittorio Scarano","Symmetric adaptive customer modeling for electronic commerce in a distributed environment","Electronic Commerce involves more than simple online transactions, it also deals with several other fields such as market research, customers care, document exchange and customer modeling. Our paper deals with the customer modeling issue, first introduced in the companion paper [4], where a model is presented of a system that can adapt its response to customers. We present here the necessary extension to the model so that it can be used on a distributed system for EC on the World Wide Web. The extensions presented are simple, easy to implement, not computationally expensive, and preserve the privacy of all the actors in an EC distributed system, while ensuring the adaptive behaviour.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/bfb0053398","2-s2.0-84949208025"],["1998-01-01","Vittorio Scarano","Toward a universal mapping algorithm for accessing trees in parallel memory systems","We study the problem of mapping the N nodes of a complete t-ary tree on M memory modules so that they can be accessed in parallel by templates, i.e. distinct sets of nodes. Typical templates for accessing trees are subtrees, root-to-leaf paths, or levels which will be referred to as elementary templates. In this paper, we first propose a new mapping algorithm for accessing both paths and subtrees of size M with an optimal number of conflicts (i.e., only one conflict) when the number of memory modules is limited to M. We also propose another mapping algorithm for a composite template, say \u03bd (as versatile), such that its size is not fixed and an instance of \u03bd is composed of any combination of c instances of elementary templates. The number of conflicts for accessing an S-node instance of template \u03bd is O(S\/\u221aM log M+c) and the memory load is 1+o(1) where load is defined as the ratio between the maximum and minimum number of data items mapped onto each memory module.",null,"Proceedings of the International Parallel Processing Symposium, IPPS","Conference Paper","https:\/\/www.doi.org\/10.1109\/IPPS.1998.669955","2-s2.0-0031701133"],["1998-01-01","Vittorio Scarano","Symmetric adaptive customer modeling in an electronic store","Electronic Commerce (EC) is currently one of the fastest growing and most practically relevant application areas of distributed systems technologies. It is based on the economic aspects of commercial trading patterns combined with distributed computing systems technology. It is a market environment that is characterized by low transaction costs, a large number of market participants, and easy online access to services and goods offered. It also implies a set of rules and policies for the successful organization of business transactions. EC involves more than simple online transactions, it encompasses diverse activities as conducting market research, identifying opportunities and partners, cultivating relationships with customers and suppliers, document exchange and customer modeling. Our paper deals with the latter aspect of EC. We introduce here a model for developing a symmetric adaptive system for EC on the World Wide Web. Our main contribution is that the model is, by all means, symmetric: we model both customers and goods and make both their profiles change as a consequence of a customer buying a certain product. The symmetry in our model greatly simplifies the approach and the queries, giving some insights on the formalization of the allowed queries that were, in way, unexpected. Furthermore, the model itself can provide an easy-to-evaluate measure for the confidence in adapting its response to any given customer and is able to provide useful feedback to the manager, then allowing, so to speak, \u00bbmanual adjustment\u00bb that can help the behaviour of the system in the future.",null,"Proceedings - 3rd IEEE Symposium on Computers and Communications, ISCC 1998","Conference Paper","https:\/\/www.doi.org\/10.1109\/ISCC.1998.702545","2-s2.0-84947971769"],["1998-01-01","Vittorio Scarano","Toward a universal mapping algorithm for accessing trees in parallel memory systems","We study the problem of mapping the N nodes of a complete t-ary tree on M memory modules so that they can be accessed in parallel by templates, i.e. distinct sets of nodes. Typical templates for accessing trees are subtrees, root-to-leaf paths, or levels which will be referred to as elementary templates. In this paper, we first propose a new mapping algorithm for accessing both paths and subtrees of size M with an optimal number of conflicts (i.e., only one conflict) when the number of memory modules is limited to M. We also propose another mapping algorithm for a composite template, say \u03bd (as versatile,), such that its size is not fixed and an instance of \u03bd is composed of any combination of c instances of elementary templates. The number of conflicts for accessing an S-node instance of template \u03bd is O (\u221aM log M\/s + c) and the memory load is 1 + o(1) where load is defined as the ratio between the maximum and minimum number of data items mapped onto each memory module.",null,"Proceedings of the 1st Merged International Parallel Processing Symposium and Symposium on Parallel and Distributed Processing, IPPS\/SPDP 1998","Conference Paper","https:\/\/www.doi.org\/10.1109\/IPPS.1998.669955","2-s2.0-85044921299"],["1997-12-01","Vittorio Scarano","The reconfigurable ring of processors: Fine-grain tree-structured computations","We study fine-grain computation on the Reconfigurable Ring of Processors (RRP), a parallel architecture whose processing elements (PEs) are interconnected via a multiline reconfigurable bus, each of whose lines has one-packet width and can be configured, independently of other lines, to establish an arbitrary PE-to-PE connection. We present a \"cooperative\" message-passing protocol that will, in the presence of suitable implementation technology, endow an RRP with message latency that is logarithmic in the number of PEs a message passes over in transit. Our study focuses on the computational consequences of such latency in such an architecture. Our main results prove that: 1) an N-PE RRP can execute a sweep up or down an N-leaf complete binary tree in time proportional to log N log log N; 2) a broad range of N-PE architectures, including N-PE RRPs, require time proportional to log N log log N to perform such a sweep. \u00a9 1997 IEEE.","Communication protocols | Dynamically reconfigurable parallel architectures | Fine-grain parallel computing | Rings of processors | Tree-sweep algorithms","IEEE Transactions on Computers","Article","https:\/\/www.doi.org\/10.1109\/12.628396","2-s2.0-0031377209"],["1997-01-01","Vittorio Scarano","Multiple templates access of trees in parallel memory systems","The problem of mapping the N nodes of a data structure on M memory modules so that they can be accessed in parallel by templates is studied. It has been proven that any mapping algorithm that is conflict-free for one of the two templates (subtree and root-to-leaf path) has \u03a9(M\/logM) conflicts on the other. So, no conflict-free mapping algorithm can be found for both templates. An algorithm for mapping complete binary trees on M memory modules is presented.",null,"Proceedings of the International Parallel Processing Symposium, IPPS","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-0030642792"],["1997-01-01","Vittorio Scarano","CHEOPS: Adaptive hypermedia on world wide web","Because of stateless characteristics of HTTP, it is not possible for HTTP servers to adapt responses on the basis of previous interactions with the same user. Although efficient, this is a limiting aspect of the protocol, particularly for Web documents that are directed toward a broad audience, including experts and novices and an adaptive response would be helpful in providing information with the right style. We present here the key concepts of CHEOPS, a system that is being developed as a tool that can be used by hyperdocument designers to provide their document with adaptivity and navigational aids. Version 0.9 of CHEOPS, actually available, is implemented by several CGI-BIN scripts that enables an HTTP server to interact with a user and follow her on the \u201cPath to Knowledge\u201d. Solution is transparent to the user and to the client, and has a moderate impact on server performances. Further directions of the work toward version 1.0 is also presented.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/bfb0000353","2-s2.0-67649868905"],["1995-01-01","Vittorio Scarano","Brief Contributions Embedding Graphs onto the Supercube","In this paper we consider the Supercube, a new interconnection network derived from the Hypercube. The Supercube, introduced by Sen in [10], has the same diameter and connectivity as a Hypercube but can be realized for any number of nodes, not only powers of 2. We study the Supercube's ability to execute parallel programs, using graph-embedding techniques. We show that complete binary trees and bidimensional meshes (with a side length power of 2) are spanning subgraphs of the Supercube. We then prove that the Supercube is Hamiltonian and, when the number of nodes is not a power of 2, it contains all cycles of length greater than 3 as subgraphs. \u00a9 1995 IEEE","Cycles | graph embedding | Hamiltonian cycle | parallel architectures | Supercube","IEEE Transactions on Computers","Article","https:\/\/www.doi.org\/10.1109\/12.376173","2-s2.0-0029291728"],["1995-01-01","Vittorio Scarano","Fast execution of irregularly structured programs with low communication frequency on the hypercube","In this paper we study the problem of efficiently executing a parallel program composed of N tasks on a 0(N)-node hypercube assuming that (a) communications between tasks are irregular i.e. any pair of tasks may want to communicate at any step of the program and (b) communications between any two tasks occur with a low frequency, i.e. frequency formula Presented. Our probabilistic technique emulates such programs with slowdown 0(log log N) with high probability. The problem can be also seen as the problem of emulating a CRCW PRAM program on a distributed memory parallel machine whose interconnection network is the hypercube and our result can be equivalently stated in this model. As a part of the emulation technique, we develop a Distributed Recombination Algorithm that has independent interest being an efficient way of clustering homogenous information on a hypercube.",null,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Conference Paper","https:\/\/www.doi.org\/10.1007\/3-540-60321-2_4","2-s2.0-84957685500"],["1994-12-01","Vittorio Scarano","Reconfigurable ring of processors: fine-grained tree-structured computations","A fine-grained parallel computation on RRPs assumed to be implemented so that the latency for transmitting messages is logarithmic in the number of processors the message passes over in transit was studied. An algorithm that allows an N-processor RRP with w lines to perform the broadcast operation in time at most was presented. The performance of the algorithm was optimized. A fundamental, architecture-independent limitation imposed by the logarithmic communication latency model was also considered. It was shown that for a broad range of parallel architectures, including any N-processor RRP, any operation that requires one processor to receive information, directly or indirectly from all other processors, requires time proportional to log N log log N.",null,"IEEE Symposium on Parallel and Distributed Processing - Proceedings","Conference Paper","https:\/\/www.doi.org\/None","2-s2.0-0028712625"]]}